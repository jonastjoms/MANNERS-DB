{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/IPython/core/magics/pylab.py:160: UserWarning: pylab import has clobbered these variables: ['datetime']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    }
   ],
   "source": [
    "import sys,os,argparse,time\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "from tabulate import tabulate\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "# Script to clean and structure the full dataset ready for training.\n",
    "import random\n",
    "import numpy as np\n",
    "# Pandas used for loading and manipulating .csv files\n",
    "import pandas as pd\n",
    "# plotting using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# seaborn for fancy plotting (builds on top of matplotlib)\n",
    "import seaborn as sn\n",
    "sn.set()\n",
    "from IPython.display import display\n",
    "import os\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets,transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Arguments =\n",
      "\tseed: 0\n",
      "\tdevice: cuda:0\n",
      "\texperiment: 2 task groups\n",
      "\tapproach: lul\n",
      "\tdata_path: data_cleaning/data.csv\n",
      "\toutput: \n",
      "\tcheckpoint_dir: ../checkpoints_2_tasks\n",
      "\tn_epochs: 100\n",
      "\tbatch_size: 64\n",
      "\tlr: 0.001\n",
      "\thidden_size: 800\n",
      "\tparameter: \n",
      "\tMC_samples: 10\n",
      "\trho: -3.0\n",
      "\tsigma1: 0.0\n",
      "\tsigma2: 6.0\n",
      "\tpi: 0.25\n",
      "\tresume: no\n",
      "\tsti: 1\n",
      "\tfff: /root/.local/share/jupyter/runtime/kernel-739deb97-39fc-48c8-878e-6c6fc00f2258.json\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Arguments\n",
    "parser=argparse.ArgumentParser(description='xxx')\n",
    "parser.add_argument('--seed',               default=0,              type=int,     help='(default=%(default)d)')\n",
    "parser.add_argument('--device',             default='cuda:0',          type=str,     help='gpu id')\n",
    "parser.add_argument('--experiment',         default='2 task groups',       type =str,    help='Mnist or dissertation')\n",
    "parser.add_argument('--approach',           default='lul',          type =str,    help='Method, always Lifelong Uncertainty-aware learning')\n",
    "parser.add_argument('--data_path',          default='data_cleaning/data.csv',     type=str,     help='gpu id')\n",
    "\n",
    "# Training parameters\n",
    "parser.add_argument('--output',             default='',             type=str,     help='')\n",
    "parser.add_argument('--checkpoint_dir',     default='../checkpoints_2_tasks',    type=str,   help='')\n",
    "parser.add_argument('--n_epochs',           default=100,              type=int,     help='')\n",
    "parser.add_argument('--batch_size',         default=64,             type=int,     help='')\n",
    "parser.add_argument('--lr',                 default=0.001,           type=float,   help='')\n",
    "parser.add_argument('--hidden_size',        default=800,           type=int,     help='')\n",
    "parser.add_argument('--parameter',          default='',             type=str,     help='')\n",
    "\n",
    "# UCB HYPER-PARAMETERS\n",
    "parser.add_argument('--MC_samples',         default='10',           type=int,     help='Number of Monte Carlo samples')\n",
    "parser.add_argument('--rho',                default='-3',           type=float,   help='Initial rho')\n",
    "parser.add_argument('--sigma1',             default='0.0',          type=float,   help='STD foor the 1st prior pdf in scaled mixture Gaussian')\n",
    "parser.add_argument('--sigma2',             default='6.0',          type=float,   help='STD foor the 2nd prior pdf in scaled mixture Gaussian')\n",
    "parser.add_argument('--pi',                 default='0.25',         type=float,   help='weighting factor for prior')\n",
    "\n",
    "parser.add_argument('--resume',             default='no',           type=str,     help='resume?')\n",
    "parser.add_argument('--sti',                default= 1,              type=int,     help='starting task?')\n",
    "\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "args=parser.parse_args()\n",
    "utils.print_arguments(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "2 task groups_lul\n",
      "Results will be saved in  ../checkpoints_2_tasks/2 task groups_lul\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seed for stable results\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Check if Cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"Using device:\", args.device)\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = utils.make_directories(args)\n",
    "args.checkpoint = checkpoint\n",
    "print()\n",
    "\n",
    "# MNIST with two tasks:\n",
    "from data_cleaning import social_approp as dataloader\n",
    "\n",
    "# Import Lifelong Uncertainty-aware Learning approach:\n",
    "#from bayesian_model.lul import Lul\n",
    "from bayesian_model.lul_2 import Lul\n",
    "\n",
    "# Import model used:\n",
    "#from bayesian_model.bayesian_network import BayesianNetwork\n",
    "from bayesian_model.bayesian_network_2 import BayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Input size = [1, 29] \n",
      "Task info = [(0, 16), (1, 16)]\n",
      "Number of data samples:  4400\n"
     ]
    }
   ],
   "source": [
    "# Load data:\n",
    "print(\"Loading data...\")\n",
    "data, task_outputs, input_size = dataloader.get(data_path=args.data_path)\n",
    "print(\"Input size =\", input_size, \"\\nTask info =\", task_outputs)\n",
    "print(\"Number of data samples: \", len(data[0]['train']['x']))\n",
    "args.num_tasks = len(task_outputs)\n",
    "args.input_size = input_size\n",
    "args.task_outputs = task_outputs\n",
    "data = pickle.load(open( \"structured_data/data.p\", \"rb\" ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing network...\n",
      "Initialize Lifelong Uncertainty-aware Learning\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Initialize Bayesian network\n",
    "print(\"Initializing network...\")\n",
    "model = BayesianNetwork(args).to(args.device)\n",
    "\n",
    "# Initialize Lul approach\n",
    "print(\"Initialize Lifelong Uncertainty-aware Learning\")\n",
    "approach = Lul(model, args=args)\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Load stored model:\n",
    "checkpoint = torch.load(os.path.join(args.checkpoint, 'model_{}.pth.tar'.format(args.sti)))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device=args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arrow\n",
    "arrow = 1\n",
    "\n",
    "# Do 100 MC samples:\n",
    "mean_arrow = np.zeros((data[arrow]['test']['x'].detach().numpy().shape[0], 8))\n",
    "log_var_arrow = np.zeros((data[arrow]['test']['x'].detach().numpy().shape[0], 8))\n",
    "    \n",
    "for sample in range(100):\n",
    "    mean_arrow = np.dstack((mean_arrow, model(data[arrow]['test']['x'][:,1:].type(torch.float32).to(args.device), sample = True)[arrow].cpu().detach().numpy()[:,0:8]))\n",
    "    log_var_arrow = np.dstack((log_var_arrow, model(data[arrow]['test']['x'][:,1:].type(torch.float32).to(args.device), sample = True)[arrow].cpu().detach().numpy()[:,8:]))\n",
    "\n",
    "mean_arrow = mean_arrow[:,:,1:]\n",
    "log_var_arrow = log_var_arrow[:,:,1:]\n",
    "\n",
    "Aleatoric_arrow = np.mean(np.exp(log_var_arrow), axis = 2)\n",
    "Epistemic_arrow = np.mean(np.square(mean_arrow), axis = 2) - np.square(np.mean(mean_arrow, axis = 2))\n",
    "total_Aleatoric_arrow = np.mean(Aleatoric_arrow, axis = 0)\n",
    "total_Epistemic_arrow = np.mean(Epistemic_arrow, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Circle\n",
    "arrow = 0 \n",
    "# Do 100 MC samples:\n",
    "mean_circle = np.zeros((data[arrow]['test']['x'].detach().numpy().shape[0], 8))\n",
    "log_var_circle = np.zeros((data[arrow]['test']['x'].detach().numpy().shape[0], 8))\n",
    "    \n",
    "for sample in range(100):\n",
    "    mean_circle = np.dstack((mean_circle, model(data[arrow]['test']['x'][:,1:].type(torch.float32).to(args.device), sample = True)[arrow].cpu().detach().numpy()[:,0:8]))\n",
    "    log_var_circle = np.dstack((log_var_circle, model(data[arrow]['test']['x'][:,1:].type(torch.float32).to(args.device), sample = True)[arrow].cpu().detach().numpy()[:,8:]))\n",
    "\n",
    "mean_circle = mean_circle[:,:,1:]\n",
    "log_var_circle = log_var_circle[:,:,1:]\n",
    "\n",
    "Aleatoric_circle = np.mean(np.exp(log_var_circle), axis = 2)\n",
    "Epistemic_circle = np.mean(np.square(mean_circle), axis = 2) - np.square(np.mean(mean_circle, axis = 2))\n",
    "total_Aleatoric_circle = np.mean(Aleatoric_circle, axis = 0)\n",
    "total_Epistemic_circle = np.mean(Epistemic_circle, axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for Circle (100 MC samples): \n",
      "| Action                             |   Aleatoric uncertainty |   Epistemic uncertainty |\n",
      "|------------------------------------+-------------------------+-------------------------|\n",
      "| Vacuum cleaning                    |                 3.86458 |                0.922785 |\n",
      "| Mopping the floor                  |                 1.39885 |                0.954169 |\n",
      "| Carry warm food                    |                 2.12648 |                0.868348 |\n",
      "| Carry cold food                    |                 2.81509 |                0.807286 |\n",
      "| Carry drinks                       |                 3.17648 |                0.964357 |\n",
      "| Carry small objects (plates, toys) |                 1.37683 |                1.11442  |\n",
      "| Carry big objects (tables, chairs) |                 2.00792 |                0.868637 |\n",
      "| Cleaning (Picking up stuff)        |                 1.94297 |                0.904964 |\n",
      "| Sum                                |                18.7092  |                7.40496  |\n",
      "\n",
      "Results for arrow (100 MC samples): \n",
      "| Action                             |   Aleatoric uncertainty |   Epistemic uncertainty |\n",
      "|------------------------------------+-------------------------+-------------------------|\n",
      "| Vacuum cleaning                    |                 2.88938 |                0.951499 |\n",
      "| Mopping the floor                  |                 2.66961 |                1.02486  |\n",
      "| Carry warm food                    |                 3.40255 |                0.882403 |\n",
      "| Carry cold food                    |                 2.82443 |                1.03526  |\n",
      "| Carry drinks                       |                 3.63643 |                0.913237 |\n",
      "| Carry small objects (plates, toys) |                 2.95608 |                0.825355 |\n",
      "| Carry big objects (tables, chairs) |                 3.15944 |                0.896553 |\n",
      "| Cleaning (Picking up stuff)        |                 2.26374 |                1.05677  |\n",
      "| Sum                                |                23.8017  |                7.58594  |\n"
     ]
    }
   ],
   "source": [
    "questions = [['Vacuum cleaning', 'Mopping the floor', 'Carry warm food', 'Carry cold food', 'Carry drinks', 'Carry small objects (plates, toys)', 'Carry big objects (tables, chairs)', 'Cleaning (Picking up stuff)'], ['Vacuum cleaning', 'Mopping the floor', 'Carry warm food', 'Carry cold food', 'Carry drinks', 'Carry small objects (plates, toys)', 'Carry big objects (tables, chairs)', 'Starting conversation']]\n",
    "# Circle\n",
    "i = 0\n",
    "table = []\n",
    "for question in questions[0]:\n",
    "    table.append([question, total_Aleatoric_circle[i], total_Epistemic_circle[i]])\n",
    "    i += 1\n",
    "table.append(['Sum', np.sum(total_Aleatoric_circle), np.sum(total_Epistemic_circle)])\n",
    "print(\"Results for Circle (100 MC samples): \")\n",
    "print(tabulate(table, headers= ['Action', 'Aleatoric uncertainty', 'Epistemic uncertainty'], tablefmt='orgtbl'))\n",
    "# Arrow\n",
    "i = 0\n",
    "table = []\n",
    "for question in questions[0]:\n",
    "    table.append([question, total_Aleatoric_arrow[i], total_Epistemic_arrow[i]])\n",
    "    i += 1\n",
    "table.append(['Sum', np.sum(total_Aleatoric_arrow), np.sum(total_Epistemic_arrow)])\n",
    "print()\n",
    "print(\"Results for arrow (100 MC samples): \")\n",
    "print(tabulate(table, headers= ['Action', 'Aleatoric uncertainty', 'Epistemic uncertainty'], tablefmt='orgtbl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene number:  380\n",
      "| Action                             |   Prediction |   Epistemic uncertainty |   Aleatoric uncertainty |\n",
      "|------------------------------------+--------------+-------------------------+-------------------------|\n",
      "| Vacuum cleaning                    |      3.35935 |                0.943675 |                 2.39409 |\n",
      "| Mopping the floor                  |      2.74605 |                1.03374  |                 2.68451 |\n",
      "| Carry warm food                    |      2.16947 |                0.974298 |                 2.14604 |\n",
      "| Carry cold food                    |      2.76839 |                1.26106  |                 1.45407 |\n",
      "| Carry drinks                       |      1.26532 |                0.940074 |                 5.70631 |\n",
      "| Carry small objects (plates, toys) |      2.37212 |                0.881459 |                 4.77986 |\n",
      "| Carry big objects (tables, chairs) |      1.52982 |                0.937367 |                 5.70828 |\n",
      "| Starting conversation              |      3.33257 |                1.18944  |                 2.63989 |\n",
      "Scene number:  667\n",
      "| Action                             |   Prediction |   Epistemic uncertainty |   Aleatoric uncertainty |\n",
      "|------------------------------------+--------------+-------------------------+-------------------------|\n",
      "| Vacuum cleaning                    |      2.90421 |                0.954152 |                 3.9231  |\n",
      "| Mopping the floor                  |      2.51448 |                0.745632 |                 1.13018 |\n",
      "| Carry warm food                    |      2.91279 |                0.742628 |                 2.65858 |\n",
      "| Carry cold food                    |      3.54634 |                0.683556 |                 2.69831 |\n",
      "| Carry drinks                       |      3.03122 |                0.907874 |                 3.28795 |\n",
      "| Carry small objects (plates, toys) |      3.49242 |                1.08007  |                 1.28159 |\n",
      "| Carry big objects (tables, chairs) |      2.39288 |                0.853697 |                 2.01411 |\n",
      "| Cleaning (Picking up stuff)        |      3.58795 |                0.738769 |                 2.28907 |\n"
     ]
    }
   ],
   "source": [
    "# Prediction and uncertainty for some scenes:\n",
    "scene_number = 400\n",
    "# Arrow\n",
    "arrow = 1\n",
    "stamp_arrow = data[arrow]['test']['x'][scene_number,0].cpu().detach().numpy()\n",
    "Prediction_arrow = np.mean(mean_arrow, axis = 2)[scene_number]\n",
    "Aleatoric_arrow = np.mean(np.exp(log_var_arrow), axis = 2)[scene_number]\n",
    "Epistemic_arrow = (np.mean(np.square(mean_arrow), axis = 2) - np.square(np.mean(mean_arrow, axis = 2)))[scene_number]\n",
    "i = 0\n",
    "table = []\n",
    "for question in questions[arrow]:\n",
    "    table.append([question, Prediction_arrow[i], Epistemic_arrow[i], Aleatoric_arrow[i]])\n",
    "    i += 1\n",
    "print(\"Scene number: \", int(stamp_arrow))\n",
    "print(tabulate(table, headers= ['Action', 'Prediction', 'Epistemic uncertainty', 'Aleatoric uncertainty'], tablefmt='orgtbl'))\n",
    "# circle\n",
    "arrow = 0\n",
    "stamp_circle = data[arrow]['test']['x'][scene_number,0].cpu().detach().numpy()\n",
    "Prediction_circle = np.mean(mean_circle, axis = 2)[scene_number]\n",
    "Aleatoric_circle = np.mean(np.exp(log_var_circle), axis = 2)[scene_number]\n",
    "Epistemic_circle = (np.mean(np.square(mean_circle), axis = 2) - np.square(np.mean(mean_circle, axis = 2)))[scene_number]\n",
    "i = 0\n",
    "table = []\n",
    "for question in questions[arrow]:\n",
    "    table.append([question, Prediction_circle[i], Epistemic_circle[i], Aleatoric_circle[i]])\n",
    "    i += 1\n",
    "print()\n",
    "print(\"Scene number: \", int(stamp_circle))\n",
    "print(tabulate(table, headers= ['Action', 'Prediction', 'Epistemic uncertainty', 'Aleatoric uncertainty'], tablefmt='orgtbl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1304, 8, 100)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
