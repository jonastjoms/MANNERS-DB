{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,argparse,time\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "tstart=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Arguments =\n",
      "\tseed: 0\n",
      "\tdevice: cuda:0\n",
      "\texperiment: 16_task_groups\n",
      "\tapproach: PUGCL\n",
      "\tdata_path: data/data.csv\n",
      "\toutput: \n",
      "\tcheckpoint_dir: ../checkpoints_16_tasks\n",
      "\tn_epochs: 100\n",
      "\tbatch_size: 64\n",
      "\tlr: 0.03\n",
      "\thidden_size: 800\n",
      "\tparameter: \n",
      "\tMC_samples: 10\n",
      "\trho: -3.0\n",
      "\tsigma1: 0.0\n",
      "\tsigma2: 6.0\n",
      "\tpi: 0.25\n",
      "\tresume: no\n",
      "\tsti: 1\n",
      "\tfff: /Users/jonastjomsland/Library/Jupyter/runtime/kernel-76d522b6-018e-4438-822a-35b9f00dfa0f.json\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Arguments\n",
    "parser=argparse.ArgumentParser(description='xxx')\n",
    "parser.add_argument('--seed',               default=0,              type=int,     help='(default=%(default)d)')\n",
    "parser.add_argument('--device',             default='cuda:0',          type=str,     help='gpu id')\n",
    "parser.add_argument('--experiment',         default='16_task_groups',       type =str,    help='Mnist or dissertation')\n",
    "parser.add_argument('--approach',           default='PUGCL',          type =str,    help='Method, always Lifelong Uncertainty-aware learning')\n",
    "parser.add_argument('--data_path',          default='data/data.csv',     type=str,     help='gpu id')\n",
    "\n",
    "# Training parameters\n",
    "parser.add_argument('--output',             default='',             type=str,     help='')\n",
    "parser.add_argument('--checkpoint_dir',     default='../checkpoints_16_tasks',    type=str,   help='')\n",
    "parser.add_argument('--n_epochs',           default=100,              type=int,     help='')\n",
    "parser.add_argument('--batch_size',         default=64,             type=int,     help='')\n",
    "parser.add_argument('--lr',                 default=0.03,           type=float,   help='')\n",
    "parser.add_argument('--hidden_size',        default=800,           type=int,     help='')\n",
    "parser.add_argument('--parameter',          default='',             type=str,     help='')\n",
    "\n",
    "# UCB HYPER-PARAMETERS\n",
    "parser.add_argument('--MC_samples',         default='10',           type=int,     help='Number of Monte Carlo samples')\n",
    "parser.add_argument('--rho',                default='-3',           type=float,   help='Initial rho')\n",
    "parser.add_argument('--sigma1',             default='0.0',          type=float,   help='STD foor the 1st prior pdf in scaled mixture Gaussian')\n",
    "parser.add_argument('--sigma2',             default='6.0',          type=float,   help='STD foor the 2nd prior pdf in scaled mixture Gaussian')\n",
    "parser.add_argument('--pi',                 default='0.25',         type=float,   help='weighting factor for prior')\n",
    "\n",
    "parser.add_argument('--resume',             default='no',           type=str,     help='resume?')\n",
    "parser.add_argument('--sti',                default=1,              type=int,     help='starting task?')\n",
    "\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "args=parser.parse_args()\n",
    "utils.print_arguments(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid token (<ipython-input-6-1fb0f9e8477e>, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-1fb0f9e8477e>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    from data import 16_tasks_dataloader as dataloader\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid token\n"
     ]
    }
   ],
   "source": [
    "# Set seed for stable results\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Check if Cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"Using device:\", args.device)\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = utils.make_directories(args)\n",
    "args.checkpoint = checkpoint\n",
    "print()\n",
    "\n",
    "# PUGCL with two tasks:\n",
    "from data import 16_tasks_dataloader as dataloader\n",
    "\n",
    "# Import Lifelong Uncertainty-aware Learning approach:\n",
    "#from bayesian_model.lul import Lul\n",
    "from bayesian_model.PUGCL import Lul\n",
    "\n",
    "# Import model used:\n",
    "#from bayesian_model.bayesian_network import BayesianNetwork\n",
    "from bayesian_model.bayesian_network import BayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting this session on: \n",
      "2020-05-12 09:58\n",
      "Loading data...\n",
      "Input size = [1, 29] \n",
      "Task info = [(0, 2), (1, 2), (2, 2), (3, 2), (4, 2), (5, 2), (6, 2), (7, 2), (8, 2), (9, 2), (10, 2), (11, 2), (12, 2), (13, 2), (14, 2), (15, 2)]\n",
      "Number of data samples:  500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing network...\n",
      "Initialize Lifelong Uncertainty-aware Learning\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Starting this session on: \")\n",
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "# Load data:\n",
    "print(\"Loading data...\")\n",
    "data, task_outputs, input_size = dataloader.get(data_path=args.data_path)\n",
    "print(\"Input size =\", input_size, \"\\nTask info =\", task_outputs)\n",
    "print(\"Number of data samples: \", len(data[0]['train']['x']))\n",
    "args.num_tasks = len(task_outputs)\n",
    "args.input_size = input_size\n",
    "args.task_outputs = task_outputs\n",
    "pickle.dump(data, open( \"structured_data/data.p\", \"wb\" ))\n",
    "\n",
    "# Initialize Bayesian network\n",
    "print(\"Initializing network...\")\n",
    "model = BayesianNetwork(args).to(args.device)\n",
    "\n",
    "# Initialize Lul approach\n",
    "print(\"Initialize Lifelong Uncertainty-aware Learning\")\n",
    "approach = Lul(model, args=args)\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Check wether resuming:\n",
    "if args.resume == \"yes\":\n",
    "    checkpoint = torch.load(os.path.join(args.checkpoint, 'model_{}.pth.tar'.format(args.sti)))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device=args.device)\n",
    "else:\n",
    "    args.sti = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Task  0 (Vacuum cleaning)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  0\n",
      "\r",
      "Batch: 0/500 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:749: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch   1, time=563.8ms/ 13.4ms | Train: loss=1.870 | Valid: loss=1.870 | *\n",
      "Batch: 448/500 | Epoch   2, time=543.1ms/ 12.9ms | Train: loss=1.839 | Valid: loss=1.839 | *\n",
      "Batch: 448/500 | Epoch   3, time=559.7ms/ 13.1ms | Train: loss=1.687 | Valid: loss=1.687 | *\n",
      "Batch: 448/500 | Epoch   4, time=569.8ms/ 13.1ms | Train: loss=1.637 | Valid: loss=1.637 | *\n",
      "Batch: 448/500 | Epoch   5, time=578.0ms/ 13.1ms | Train: loss=1.653 | Valid: loss=1.653 |\n",
      "Batch: 448/500 | Epoch   6, time=588.4ms/ 16.5ms | Train: loss=1.601 | Valid: loss=1.601 | *\n",
      "Batch: 448/500 | Epoch   7, time=592.7ms/ 13.4ms | Train: loss=1.629 | Valid: loss=1.629 |\n",
      "Batch: 448/500 | Epoch   8, time=583.5ms/ 13.1ms | Train: loss=1.612 | Valid: loss=1.612 |\n",
      "Batch: 448/500 | Epoch   9, time=540.7ms/ 13.0ms | Train: loss=1.570 | Valid: loss=1.570 | *\n",
      "Batch: 448/500 | Epoch  10, time=571.8ms/ 12.8ms | Train: loss=1.602 | Valid: loss=1.602 |\n",
      "Batch: 448/500 | Epoch  11, time=590.4ms/ 13.9ms | Train: loss=1.591 | Valid: loss=1.591 |\n",
      "Batch: 448/500 | Epoch  12, time=595.2ms/ 13.1ms | Train: loss=1.556 | Valid: loss=1.556 | *\n",
      "Batch: 448/500 | Epoch  13, time=577.3ms/ 14.4ms | Train: loss=1.559 | Valid: loss=1.559 |\n",
      "Batch: 448/500 | Epoch  14, time=561.0ms/ 13.1ms | Train: loss=1.573 | Valid: loss=1.573 |\n",
      "Batch: 448/500 | Epoch  15, time=530.5ms/ 13.2ms | Train: loss=1.549 | Valid: loss=1.549 | *\n",
      "Batch: 448/500 | Epoch  16, time=581.0ms/ 13.2ms | Train: loss=1.550 | Valid: loss=1.550 |\n",
      "Batch: 448/500 | Epoch  17, time=529.1ms/ 13.3ms | Train: loss=1.536 | Valid: loss=1.536 | *\n",
      "Batch: 448/500 | Epoch  18, time=523.2ms/ 12.9ms | Train: loss=1.548 | Valid: loss=1.548 |\n",
      "Batch: 448/500 | Epoch  19, time=529.4ms/ 13.5ms | Train: loss=1.563 | Valid: loss=1.563 |\n",
      "Batch: 448/500 | Epoch  20, time=552.8ms/ 13.0ms | Train: loss=1.529 | Valid: loss=1.529 | *\n",
      "Batch: 448/500 | Epoch  21, time=583.7ms/ 13.5ms | Train: loss=1.603 | Valid: loss=1.603 |\n",
      "Batch: 448/500 | Epoch  22, time=530.8ms/ 13.3ms | Train: loss=1.548 | Valid: loss=1.548 |\n",
      "Batch: 448/500 | Epoch  23, time=609.0ms/ 13.1ms | Train: loss=1.555 | Valid: loss=1.555 |\n",
      "Batch: 448/500 | Epoch  24, time=607.9ms/ 13.1ms | Train: loss=1.518 | Valid: loss=1.518 | *\n",
      "Batch: 448/500 | Epoch  25, time=569.7ms/ 13.0ms | Train: loss=1.546 | Valid: loss=1.546 |\n",
      "Batch: 448/500 | Epoch  26, time=572.1ms/ 13.0ms | Train: loss=1.547 | Valid: loss=1.547 |\n",
      "Batch: 448/500 | Epoch  27, time=527.1ms/ 13.1ms | Train: loss=1.563 | Valid: loss=1.563 |\n",
      "Batch: 448/500 | Epoch  28, time=528.1ms/ 13.1ms | Train: loss=1.569 | Valid: loss=1.569 |\n",
      "Batch: 448/500 | Epoch  29, time=588.6ms/ 13.2ms | Train: loss=1.517 | Valid: loss=1.517 | *\n",
      "Batch: 448/500 | Epoch  30, time=535.4ms/ 13.8ms | Train: loss=1.504 | Valid: loss=1.504 | *\n",
      "Batch: 448/500 | Epoch  31, time=580.6ms/ 15.2ms | Train: loss=1.518 | Valid: loss=1.518 |\n",
      "Batch: 448/500 | Epoch  32, time=567.5ms/ 12.9ms | Train: loss=1.500 | Valid: loss=1.500 | *\n",
      "Batch: 448/500 | Epoch  33, time=562.4ms/ 13.5ms | Train: loss=1.561 | Valid: loss=1.561 |\n",
      "Batch: 448/500 | Epoch  34, time=546.1ms/ 13.0ms | Train: loss=1.498 | Valid: loss=1.498 | *\n",
      "Batch: 448/500 | Epoch  35, time=574.0ms/ 13.1ms | Train: loss=1.497 | Valid: loss=1.497 | *\n",
      "Batch: 448/500 | Epoch  36, time=611.1ms/ 13.5ms | Train: loss=1.524 | Valid: loss=1.524 |\n",
      "Batch: 448/500 | Epoch  37, time=566.4ms/ 13.2ms | Train: loss=1.514 | Valid: loss=1.514 |\n",
      "Batch: 448/500 | Epoch  38, time=555.7ms/ 13.0ms | Train: loss=1.510 | Valid: loss=1.510 |\n",
      "Batch: 448/500 | Epoch  39, time=564.5ms/ 12.9ms | Train: loss=1.497 | Valid: loss=1.497 |\n",
      "Batch: 448/500 | Epoch  40, time=568.2ms/ 15.1ms | Train: loss=1.520 | Valid: loss=1.520 |\n",
      "Batch: 448/500 | Epoch  41, time=575.8ms/ 16.5ms | Train: loss=1.485 | Valid: loss=1.485 | *\n",
      "Batch: 448/500 | Epoch  42, time=584.7ms/ 13.0ms | Train: loss=1.503 | Valid: loss=1.503 |\n",
      "Batch: 448/500 | Epoch  43, time=573.6ms/ 13.4ms | Train: loss=1.490 | Valid: loss=1.490 |\n",
      "Batch: 448/500 | Epoch  44, time=630.0ms/ 16.5ms | Train: loss=1.527 | Valid: loss=1.527 |\n",
      "Batch: 448/500 | Epoch  45, time=566.8ms/ 12.9ms | Train: loss=1.486 | Valid: loss=1.486 |\n",
      "Batch: 448/500 | Epoch  46, time=542.4ms/ 13.0ms | Train: loss=1.481 | Valid: loss=1.481 | *\n",
      "Batch: 448/500 | Epoch  47, time=524.7ms/ 13.0ms | Train: loss=1.483 | Valid: loss=1.483 |\n",
      "Batch: 448/500 | Epoch  48, time=546.0ms/ 13.1ms | Train: loss=1.481 | Valid: loss=1.481 |\n",
      "Batch: 448/500 | Epoch  49, time=547.3ms/ 13.0ms | Train: loss=1.483 | Valid: loss=1.483 |\n",
      "Batch: 448/500 | Epoch  50, time=551.5ms/ 13.3ms | Train: loss=1.486 | Valid: loss=1.486 |\n",
      "Batch: 448/500 | Epoch  51, time=543.6ms/ 12.9ms | Train: loss=1.487 | Valid: loss=1.487 |\n",
      "Batch: 448/500 | Epoch  52, time=570.7ms/ 13.2ms | Train: loss=1.561 | Valid: loss=1.561 |\n",
      "Batch: 448/500 | Epoch  53, time=560.4ms/ 13.0ms | Train: loss=1.478 | Valid: loss=1.478 | *\n",
      "Batch: 448/500 | Epoch  54, time=551.5ms/ 14.9ms | Train: loss=1.487 | Valid: loss=1.487 |\n",
      "Batch: 448/500 | Epoch  55, time=570.2ms/ 13.2ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  56, time=583.4ms/ 14.1ms | Train: loss=1.483 | Valid: loss=1.483 |\n",
      "Batch: 448/500 | Epoch  57, time=573.0ms/ 12.9ms | Train: loss=1.517 | Valid: loss=1.517 |\n",
      "Batch: 448/500 | Epoch  58, time=555.4ms/ 16.3ms | Train: loss=1.486 | Valid: loss=1.486 |\n",
      "Batch: 448/500 | Epoch  59, time=617.6ms/ 13.2ms | Train: loss=1.618 | Valid: loss=1.618 |\n",
      "Batch: 448/500 | Epoch  60, time=567.6ms/ 13.2ms | Train: loss=1.542 | Valid: loss=1.542 |\n",
      "Batch: 448/500 | Epoch  61, time=568.7ms/ 13.7ms | Train: loss=1.490 | Valid: loss=1.490 |\n",
      "Batch: 448/500 | Epoch  62, time=536.0ms/ 13.0ms | Train: loss=1.500 | Valid: loss=1.500 |\n",
      "Batch: 448/500 | Epoch  63, time=573.2ms/ 13.2ms | Train: loss=1.477 | Valid: loss=1.477 | *\n",
      "Batch: 448/500 | Epoch  64, time=543.5ms/ 13.0ms | Train: loss=1.540 | Valid: loss=1.540 |\n",
      "Batch: 448/500 | Epoch  65, time=564.3ms/ 14.4ms | Train: loss=1.474 | Valid: loss=1.474 | *\n",
      "Batch: 448/500 | Epoch  66, time=558.2ms/ 13.2ms | Train: loss=1.475 | Valid: loss=1.475 |\n",
      "Batch: 448/500 | Epoch  67, time=524.9ms/ 16.4ms | Train: loss=1.483 | Valid: loss=1.483 |\n",
      "Batch: 448/500 | Epoch  68, time=570.8ms/ 12.9ms | Train: loss=1.467 | Valid: loss=1.467 | *\n",
      "Batch: 448/500 | Epoch  69, time=560.0ms/ 13.3ms | Train: loss=1.467 | Valid: loss=1.467 | *\n",
      "Batch: 448/500 | Epoch  70, time=580.0ms/ 12.9ms | Train: loss=1.488 | Valid: loss=1.488 |\n",
      "Batch: 448/500 | Epoch  71, time=563.7ms/ 13.3ms | Train: loss=1.476 | Valid: loss=1.476 |\n",
      "Batch: 448/500 | Epoch  72, time=523.3ms/ 16.4ms | Train: loss=1.481 | Valid: loss=1.481 |\n",
      "Batch: 448/500 | Epoch  73, time=587.3ms/ 13.2ms | Train: loss=1.473 | Valid: loss=1.473 |\n",
      "Batch: 448/500 | Epoch  74, time=571.3ms/ 14.1ms | Train: loss=1.499 | Valid: loss=1.499 |\n",
      "Batch: 448/500 | Epoch  75, time=546.2ms/ 12.9ms | Train: loss=1.468 | Valid: loss=1.468 |\n",
      "Batch: 448/500 | Epoch  76, time=549.8ms/ 12.9ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  77, time=566.2ms/ 13.1ms | Train: loss=1.470 | Valid: loss=1.470 |\n",
      "Batch: 448/500 | Epoch  78, time=574.1ms/ 13.3ms | Train: loss=1.465 | Valid: loss=1.465 | *\n",
      "Batch: 448/500 | Epoch  79, time=582.3ms/ 13.2ms | Train: loss=1.482 | Valid: loss=1.482 |\n",
      "Batch: 448/500 | Epoch  80, time=524.8ms/ 13.5ms | Train: loss=1.465 | Valid: loss=1.465 |\n",
      "Batch: 448/500 | Epoch  81, time=553.0ms/ 13.4ms | Train: loss=1.490 | Valid: loss=1.490 |\n",
      "Batch: 448/500 | Epoch  82, time=524.1ms/ 13.4ms | Train: loss=1.485 | Valid: loss=1.485 |\n",
      "Batch: 448/500 | Epoch  83, time=522.7ms/ 13.4ms | Train: loss=1.529 | Valid: loss=1.529 |\n",
      "Batch: 448/500 | Epoch  84, time=522.0ms/ 13.1ms | Train: loss=1.465 | Valid: loss=1.465 |\n",
      "Batch: 448/500 | Epoch  85, time=539.1ms/ 13.3ms | Train: loss=1.470 | Valid: loss=1.470 |\n",
      "Batch: 448/500 | Epoch  86, time=595.0ms/ 12.9ms | Train: loss=1.499 | Valid: loss=1.499 |\n",
      "Batch: 448/500 | Epoch  87, time=579.6ms/ 13.2ms | Train: loss=1.467 | Valid: loss=1.467 |\n",
      "Batch: 448/500 | Epoch  88, time=582.2ms/ 12.9ms | Train: loss=1.481 | Valid: loss=1.481 |\n",
      "Batch: 448/500 | Epoch  89, time=575.1ms/ 13.2ms | Train: loss=1.494 | Valid: loss=1.494 |\n",
      "Batch: 448/500 | Epoch  90, time=577.5ms/ 15.3ms | Train: loss=1.475 | Valid: loss=1.475 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  91, time=584.9ms/ 17.2ms | Train: loss=1.463 | Valid: loss=1.463 | *\n",
      "Batch: 448/500 | Epoch  92, time=578.7ms/ 13.1ms | Train: loss=1.462 | Valid: loss=1.462 | *\n",
      "Batch: 448/500 | Epoch  93, time=554.6ms/ 13.5ms | Train: loss=1.461 | Valid: loss=1.461 | *\n",
      "Batch: 448/500 | Epoch  94, time=557.6ms/ 13.0ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  95, time=577.0ms/ 12.9ms | Train: loss=1.478 | Valid: loss=1.478 |\n",
      "Batch: 448/500 | Epoch  96, time=562.4ms/ 13.3ms | Train: loss=1.461 | Valid: loss=1.461 |\n",
      "Batch: 448/500 | Epoch  97, time=565.8ms/ 13.3ms | Train: loss=1.523 | Valid: loss=1.523 |\n",
      "Batch: 448/500 | Epoch  98, time=537.3ms/ 14.0ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  99, time=553.0ms/ 13.3ms | Train: loss=1.466 | Valid: loss=1.466 |\n",
      "Batch: 448/500 | Epoch 100, time=593.9ms/ 13.1ms | Train: loss=1.474 | Valid: loss=1.474 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.534\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task  1 (Mopping the floor)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  1\n",
      "Batch: 448/500 | Epoch   1, time=584.8ms/ 12.9ms | Train: loss=3.073 | Valid: loss=3.073 | *\n",
      "Batch: 448/500 | Epoch   2, time=585.4ms/ 13.3ms | Train: loss=3.001 | Valid: loss=3.001 | *\n",
      "Batch: 448/500 | Epoch   3, time=560.2ms/ 13.4ms | Train: loss=2.892 | Valid: loss=2.892 | *\n",
      "Batch: 448/500 | Epoch   4, time=571.7ms/ 13.0ms | Train: loss=2.843 | Valid: loss=2.843 | *\n",
      "Batch: 448/500 | Epoch   5, time=573.6ms/ 13.0ms | Train: loss=2.793 | Valid: loss=2.793 | *\n",
      "Batch: 448/500 | Epoch   6, time=574.2ms/ 13.3ms | Train: loss=2.742 | Valid: loss=2.742 | *\n",
      "Batch: 448/500 | Epoch   7, time=619.8ms/ 13.1ms | Train: loss=2.679 | Valid: loss=2.679 | *\n",
      "Batch: 448/500 | Epoch   8, time=589.0ms/ 14.7ms | Train: loss=2.645 | Valid: loss=2.645 | *\n",
      "Batch: 448/500 | Epoch   9, time=581.6ms/ 13.4ms | Train: loss=2.607 | Valid: loss=2.607 | *\n",
      "Batch: 448/500 | Epoch  10, time=568.6ms/ 13.2ms | Train: loss=2.576 | Valid: loss=2.576 | *\n",
      "Batch: 448/500 | Epoch  11, time=584.0ms/ 13.4ms | Train: loss=2.533 | Valid: loss=2.533 | *\n",
      "Batch: 448/500 | Epoch  12, time=569.0ms/ 13.6ms | Train: loss=2.487 | Valid: loss=2.487 | *\n",
      "Batch: 448/500 | Epoch  13, time=531.2ms/ 13.2ms | Train: loss=2.453 | Valid: loss=2.453 | *\n",
      "Batch: 448/500 | Epoch  14, time=539.0ms/ 13.2ms | Train: loss=2.410 | Valid: loss=2.410 | *\n",
      "Batch: 448/500 | Epoch  15, time=576.1ms/ 13.0ms | Train: loss=2.383 | Valid: loss=2.383 | *\n",
      "Batch: 448/500 | Epoch  16, time=572.8ms/ 13.0ms | Train: loss=2.356 | Valid: loss=2.356 | *\n",
      "Batch: 448/500 | Epoch  17, time=587.1ms/ 16.6ms | Train: loss=2.322 | Valid: loss=2.322 | *\n",
      "Batch: 448/500 | Epoch  18, time=619.1ms/ 13.2ms | Train: loss=2.305 | Valid: loss=2.305 | *\n",
      "Batch: 448/500 | Epoch  19, time=588.7ms/ 12.9ms | Train: loss=2.253 | Valid: loss=2.253 | *\n",
      "Batch: 448/500 | Epoch  20, time=571.2ms/ 13.5ms | Train: loss=2.238 | Valid: loss=2.238 | *\n",
      "Batch: 448/500 | Epoch  21, time=573.2ms/ 13.8ms | Train: loss=2.220 | Valid: loss=2.220 | *\n",
      "Batch: 448/500 | Epoch  22, time=574.5ms/ 13.0ms | Train: loss=2.201 | Valid: loss=2.201 | *\n",
      "Batch: 448/500 | Epoch  23, time=547.9ms/ 13.5ms | Train: loss=2.184 | Valid: loss=2.184 | *\n",
      "Batch: 448/500 | Epoch  24, time=537.6ms/ 13.4ms | Train: loss=2.167 | Valid: loss=2.167 | *\n",
      "Batch: 448/500 | Epoch  25, time=537.4ms/ 13.0ms | Train: loss=2.153 | Valid: loss=2.153 | *\n",
      "Batch: 448/500 | Epoch  26, time=562.8ms/ 12.9ms | Train: loss=2.129 | Valid: loss=2.129 | *\n",
      "Batch: 448/500 | Epoch  27, time=552.6ms/ 13.9ms | Train: loss=2.109 | Valid: loss=2.109 | *\n",
      "Batch: 448/500 | Epoch  28, time=559.4ms/ 13.0ms | Train: loss=2.085 | Valid: loss=2.085 | *\n",
      "Batch: 448/500 | Epoch  29, time=547.1ms/ 12.9ms | Train: loss=2.060 | Valid: loss=2.060 | *\n",
      "Batch: 448/500 | Epoch  30, time=525.8ms/ 13.5ms | Train: loss=2.042 | Valid: loss=2.042 | *\n",
      "Batch: 448/500 | Epoch  31, time=530.1ms/ 13.0ms | Train: loss=2.013 | Valid: loss=2.013 | *\n",
      "Batch: 448/500 | Epoch  32, time=539.4ms/ 13.0ms | Train: loss=1.997 | Valid: loss=1.997 | *\n",
      "Batch: 448/500 | Epoch  33, time=561.3ms/ 13.0ms | Train: loss=1.983 | Valid: loss=1.983 | *\n",
      "Batch: 448/500 | Epoch  34, time=531.5ms/ 16.6ms | Train: loss=1.976 | Valid: loss=1.976 | *\n",
      "Batch: 448/500 | Epoch  35, time=556.3ms/ 13.4ms | Train: loss=1.960 | Valid: loss=1.960 | *\n",
      "Batch: 448/500 | Epoch  36, time=554.0ms/ 13.3ms | Train: loss=1.942 | Valid: loss=1.942 | *\n",
      "Batch: 448/500 | Epoch  37, time=569.3ms/ 13.3ms | Train: loss=1.935 | Valid: loss=1.935 | *\n",
      "Batch: 448/500 | Epoch  38, time=538.5ms/ 13.0ms | Train: loss=1.930 | Valid: loss=1.930 | *\n",
      "Batch: 448/500 | Epoch  39, time=583.1ms/ 13.3ms | Train: loss=1.915 | Valid: loss=1.915 | *\n",
      "Batch: 448/500 | Epoch  40, time=572.4ms/ 13.0ms | Train: loss=1.904 | Valid: loss=1.904 | *\n",
      "Batch: 448/500 | Epoch  41, time=606.3ms/ 13.9ms | Train: loss=1.898 | Valid: loss=1.898 | *\n",
      "Batch: 448/500 | Epoch  42, time=607.1ms/ 13.0ms | Train: loss=1.897 | Valid: loss=1.897 | *\n",
      "Batch: 448/500 | Epoch  43, time=558.5ms/ 13.0ms | Train: loss=1.882 | Valid: loss=1.882 | *\n",
      "Batch: 448/500 | Epoch  44, time=536.7ms/ 13.2ms | Train: loss=1.875 | Valid: loss=1.875 | *\n",
      "Batch: 448/500 | Epoch  45, time=571.0ms/ 13.2ms | Train: loss=1.873 | Valid: loss=1.873 | *\n",
      "Batch: 448/500 | Epoch  46, time=583.6ms/ 13.1ms | Train: loss=1.867 | Valid: loss=1.867 | *\n",
      "Batch: 448/500 | Epoch  47, time=548.7ms/ 13.6ms | Train: loss=1.856 | Valid: loss=1.856 | *\n",
      "Batch: 448/500 | Epoch  48, time=557.3ms/ 13.0ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  49, time=545.9ms/ 13.3ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  50, time=580.7ms/ 13.1ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  51, time=572.3ms/ 14.0ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  52, time=587.5ms/ 12.9ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  53, time=566.9ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  54, time=530.9ms/ 13.6ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  55, time=549.2ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  56, time=572.3ms/ 13.5ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  57, time=600.1ms/ 13.1ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  58, time=572.6ms/ 13.4ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  59, time=571.6ms/ 13.0ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  60, time=544.0ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  61, time=595.3ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  62, time=560.0ms/ 13.1ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  63, time=523.1ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  64, time=530.6ms/ 13.0ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  65, time=548.3ms/ 13.3ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  66, time=584.4ms/ 13.3ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  67, time=600.3ms/ 13.9ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  68, time=573.2ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  69, time=559.8ms/ 12.9ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  70, time=561.5ms/ 13.0ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  71, time=589.1ms/ 13.7ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  72, time=559.1ms/ 13.0ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  73, time=542.4ms/ 13.3ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  74, time=569.0ms/ 13.1ms | Train: loss=1.858 | Valid: loss=1.858 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  75, time=573.8ms/ 13.5ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  76, time=559.6ms/ 13.5ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  77, time=568.8ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  78, time=574.7ms/ 13.0ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  79, time=599.6ms/ 14.6ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  80, time=578.4ms/ 13.1ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  81, time=588.9ms/ 12.9ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  82, time=581.5ms/ 13.1ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  83, time=573.9ms/ 16.6ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  84, time=590.4ms/ 16.4ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  85, time=608.7ms/ 13.3ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  86, time=592.0ms/ 14.4ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  87, time=580.6ms/ 13.1ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  88, time=575.2ms/ 13.6ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  89, time=555.3ms/ 13.3ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  90, time=590.5ms/ 13.4ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  91, time=558.8ms/ 13.6ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  92, time=569.7ms/ 15.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  93, time=547.8ms/ 14.5ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  94, time=590.0ms/ 13.1ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  95, time=575.3ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  96, time=568.6ms/ 12.9ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  97, time=521.7ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  98, time=519.7ms/ 12.9ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch  99, time=570.6ms/ 13.1ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "Batch: 448/500 | Epoch 100, time=563.5ms/ 13.2ms | Train: loss=1.858 | Valid: loss=1.858 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.537\n",
      "Test on task  1 - Mopping the floor: loss=1.925\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task  2 (Carry warm food)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  2\n",
      "Batch: 448/500 | Epoch   1, time=581.7ms/ 13.0ms | Train: loss=3.644 | Valid: loss=3.644 | *\n",
      "Batch: 448/500 | Epoch   2, time=576.5ms/ 13.2ms | Train: loss=3.374 | Valid: loss=3.374 | *\n",
      "Batch: 448/500 | Epoch   3, time=625.4ms/ 16.2ms | Train: loss=3.060 | Valid: loss=3.060 | *\n",
      "Batch: 448/500 | Epoch   4, time=544.3ms/ 12.9ms | Train: loss=2.845 | Valid: loss=2.845 | *\n",
      "Batch: 384/500 | Epoch   5, time=521.4ms/ 13.3ms | Train: loss=2.664 | Valid: loss=2.664 | *\n",
      "Batch: 448/500 | Epoch   6, time=565.0ms/ 13.1ms | Train: loss=2.596 | Valid: loss=2.596 | *\n",
      "Batch: 448/500 | Epoch   7, time=571.8ms/ 13.4ms | Train: loss=2.493 | Valid: loss=2.493 | *\n",
      "Batch: 448/500 | Epoch   8, time=570.6ms/ 13.3ms | Train: loss=2.402 | Valid: loss=2.402 | *\n",
      "Batch: 448/500 | Epoch   9, time=573.7ms/ 13.2ms | Train: loss=2.319 | Valid: loss=2.319 | *\n",
      "Batch: 448/500 | Epoch  26, time=574.3ms/ 16.7ms | Train: loss=1.869 | Valid: loss=1.869 | *\n",
      "Batch: 448/500 | Epoch  27, time=538.0ms/ 13.0ms | Train: loss=1.859 | Valid: loss=1.859 | *\n",
      "Batch: 448/500 | Epoch  28, time=523.8ms/ 13.2ms | Train: loss=1.854 | Valid: loss=1.854 | *\n",
      "Batch: 448/500 | Epoch  29, time=548.2ms/ 14.0ms | Train: loss=1.848 | Valid: loss=1.848 | *\n",
      "Batch: 448/500 | Epoch  30, time=572.6ms/ 13.1ms | Train: loss=1.833 | Valid: loss=1.833 | *\n",
      "Batch: 448/500 | Epoch  31, time=578.0ms/ 16.5ms | Train: loss=1.826 | Valid: loss=1.826 | *\n",
      "Batch: 448/500 | Epoch  32, time=574.3ms/ 13.2ms | Train: loss=1.817 | Valid: loss=1.817 | *\n",
      "Batch: 448/500 | Epoch  33, time=598.7ms/ 13.6ms | Train: loss=1.805 | Valid: loss=1.805 | *\n",
      "Batch: 448/500 | Epoch  34, time=571.3ms/ 12.9ms | Train: loss=1.799 | Valid: loss=1.799 | *\n",
      "Batch: 448/500 | Epoch  35, time=596.5ms/ 16.2ms | Train: loss=1.791 | Valid: loss=1.791 | *\n",
      "Batch: 448/500 | Epoch  36, time=590.7ms/ 13.6ms | Train: loss=1.786 | Valid: loss=1.786 | *\n",
      "Batch: 448/500 | Epoch  37, time=585.2ms/ 12.9ms | Train: loss=1.779 | Valid: loss=1.779 | *\n",
      "Batch: 448/500 | Epoch  38, time=537.5ms/ 13.0ms | Train: loss=1.772 | Valid: loss=1.772 | *\n",
      "Batch: 448/500 | Epoch  39, time=536.6ms/ 13.2ms | Train: loss=1.765 | Valid: loss=1.765 | *\n",
      "Batch: 448/500 | Epoch  40, time=554.3ms/ 13.0ms | Train: loss=1.757 | Valid: loss=1.757 | *\n",
      "Batch: 448/500 | Epoch  41, time=577.2ms/ 13.2ms | Train: loss=1.749 | Valid: loss=1.749 | *\n",
      "Batch: 448/500 | Epoch  42, time=577.9ms/ 13.0ms | Train: loss=1.746 | Valid: loss=1.746 | *\n",
      "Batch: 448/500 | Epoch  43, time=587.1ms/ 13.5ms | Train: loss=1.741 | Valid: loss=1.741 | *\n",
      "Batch: 448/500 | Epoch  44, time=583.3ms/ 12.9ms | Train: loss=1.733 | Valid: loss=1.733 | *\n",
      "Batch: 448/500 | Epoch  45, time=568.7ms/ 13.4ms | Train: loss=1.729 | Valid: loss=1.729 | *\n",
      "Batch: 448/500 | Epoch  46, time=547.0ms/ 13.3ms | Train: loss=1.727 | Valid: loss=1.727 | *\n",
      "Batch: 448/500 | Epoch  47, time=578.7ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  48, time=584.3ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  49, time=593.0ms/ 13.2ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  50, time=550.1ms/ 13.0ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  51, time=596.2ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  52, time=557.5ms/ 12.9ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  53, time=597.0ms/ 14.8ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  54, time=586.6ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  55, time=576.7ms/ 13.2ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  56, time=581.6ms/ 13.0ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  57, time=553.0ms/ 13.5ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  58, time=576.1ms/ 12.9ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  59, time=567.6ms/ 13.0ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  60, time=551.8ms/ 12.9ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  61, time=569.6ms/ 13.4ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  62, time=586.2ms/ 13.3ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  63, time=572.1ms/ 16.5ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  64, time=642.0ms/ 16.7ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  65, time=599.3ms/ 15.3ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  66, time=577.0ms/ 16.8ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  67, time=568.7ms/ 13.0ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  68, time=539.2ms/ 13.4ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  69, time=564.3ms/ 17.0ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  70, time=626.4ms/ 13.7ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  71, time=590.3ms/ 13.9ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  72, time=564.5ms/ 13.2ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  73, time=590.4ms/ 13.5ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  74, time=547.9ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  75, time=568.8ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  76, time=553.2ms/ 12.8ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  77, time=584.7ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  78, time=583.8ms/ 13.5ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  79, time=577.0ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  80, time=577.1ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  81, time=576.3ms/ 13.2ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  82, time=568.6ms/ 13.3ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  83, time=552.8ms/ 13.2ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  84, time=575.1ms/ 13.8ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  85, time=577.4ms/ 13.2ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  86, time=597.3ms/ 13.9ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  87, time=605.9ms/ 13.3ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  88, time=559.0ms/ 13.2ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  89, time=547.7ms/ 13.0ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  90, time=599.9ms/ 13.9ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  91, time=583.3ms/ 13.2ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  92, time=576.9ms/ 13.3ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  93, time=535.3ms/ 16.4ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  94, time=578.8ms/ 14.6ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  95, time=539.4ms/ 13.3ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  96, time=523.9ms/ 13.0ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  97, time=558.8ms/ 13.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  98, time=565.7ms/ 13.0ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch  99, time=568.9ms/ 13.0ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "Batch: 448/500 | Epoch 100, time=557.6ms/ 14.1ms | Train: loss=1.728 | Valid: loss=1.728 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.549\n",
      "Test on task  1 - Mopping the floor: loss=1.912\n",
      "Test on task  2 - Carry warm food: loss=1.648\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task  3 (Carry cold food)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  3\n",
      "Batch: 448/500 | Epoch   1, time=569.2ms/ 13.6ms | Train: loss=6.186 | Valid: loss=6.186 | *\n",
      "Batch: 448/500 | Epoch   2, time=597.6ms/ 13.3ms | Train: loss=4.283 | Valid: loss=4.283 | *\n",
      "Batch: 448/500 | Epoch   3, time=539.9ms/ 13.1ms | Train: loss=3.660 | Valid: loss=3.660 | *\n",
      "Batch: 448/500 | Epoch   4, time=538.0ms/ 13.7ms | Train: loss=3.359 | Valid: loss=3.359 | *\n",
      "Batch: 448/500 | Epoch   5, time=576.5ms/ 13.6ms | Train: loss=3.234 | Valid: loss=3.234 | *\n",
      "Batch: 448/500 | Epoch   6, time=581.9ms/ 16.4ms | Train: loss=3.157 | Valid: loss=3.157 | *\n",
      "Batch: 448/500 | Epoch   7, time=577.2ms/ 12.9ms | Train: loss=3.096 | Valid: loss=3.096 | *\n",
      "Batch: 448/500 | Epoch   8, time=573.8ms/ 13.3ms | Train: loss=3.053 | Valid: loss=3.053 | *\n",
      "Batch: 448/500 | Epoch   9, time=587.1ms/ 13.2ms | Train: loss=3.013 | Valid: loss=3.013 | *\n",
      "Batch: 448/500 | Epoch  10, time=564.3ms/ 13.3ms | Train: loss=2.980 | Valid: loss=2.980 | *\n",
      "Batch: 448/500 | Epoch  11, time=563.2ms/ 13.5ms | Train: loss=2.955 | Valid: loss=2.955 | *\n",
      "Batch: 448/500 | Epoch  12, time=541.1ms/ 15.9ms | Train: loss=2.950 | Valid: loss=2.950 | *\n",
      "Batch: 448/500 | Epoch  13, time=575.2ms/ 13.1ms | Train: loss=2.907 | Valid: loss=2.907 | *\n",
      "Batch: 448/500 | Epoch  14, time=570.9ms/ 13.0ms | Train: loss=2.868 | Valid: loss=2.868 | *\n",
      "Batch: 448/500 | Epoch  15, time=527.9ms/ 13.5ms | Train: loss=2.848 | Valid: loss=2.848 | *\n",
      "Batch: 448/500 | Epoch  16, time=562.1ms/ 12.9ms | Train: loss=2.815 | Valid: loss=2.815 | *\n",
      "Batch: 448/500 | Epoch  17, time=596.9ms/ 13.1ms | Train: loss=2.801 | Valid: loss=2.801 | *\n",
      "Batch: 448/500 | Epoch  18, time=627.3ms/ 13.7ms | Train: loss=2.785 | Valid: loss=2.785 | *\n",
      "Batch: 448/500 | Epoch  19, time=554.4ms/ 12.9ms | Train: loss=2.755 | Valid: loss=2.755 | *\n",
      "Batch: 448/500 | Epoch  20, time=569.3ms/ 15.1ms | Train: loss=2.693 | Valid: loss=2.693 | *\n",
      "Batch: 448/500 | Epoch  21, time=574.3ms/ 13.4ms | Train: loss=2.657 | Valid: loss=2.657 | *\n",
      "Batch: 448/500 | Epoch  22, time=576.4ms/ 13.4ms | Train: loss=2.617 | Valid: loss=2.617 | *\n",
      "Batch: 448/500 | Epoch  23, time=561.2ms/ 13.1ms | Train: loss=2.573 | Valid: loss=2.573 | *\n",
      "Batch: 448/500 | Epoch  24, time=525.8ms/ 12.8ms | Train: loss=2.535 | Valid: loss=2.535 | *\n",
      "Batch: 448/500 | Epoch  25, time=598.7ms/ 15.5ms | Train: loss=2.514 | Valid: loss=2.514 | *\n",
      "Batch: 448/500 | Epoch  26, time=598.4ms/ 12.9ms | Train: loss=2.485 | Valid: loss=2.485 | *\n",
      "Batch: 448/500 | Epoch  27, time=559.4ms/ 13.1ms | Train: loss=2.449 | Valid: loss=2.449 | *\n",
      "Batch: 448/500 | Epoch  28, time=560.2ms/ 14.5ms | Train: loss=2.398 | Valid: loss=2.398 | *\n",
      "Batch: 448/500 | Epoch  29, time=537.8ms/ 15.8ms | Train: loss=2.376 | Valid: loss=2.376 | *\n",
      "Batch: 448/500 | Epoch  30, time=580.3ms/ 13.4ms | Train: loss=2.332 | Valid: loss=2.332 | *\n",
      "Batch: 448/500 | Epoch  31, time=577.7ms/ 13.0ms | Train: loss=2.297 | Valid: loss=2.297 | *\n",
      "Batch: 448/500 | Epoch  32, time=580.1ms/ 13.4ms | Train: loss=2.283 | Valid: loss=2.283 | *\n",
      "Batch: 448/500 | Epoch  33, time=569.6ms/ 13.4ms | Train: loss=2.241 | Valid: loss=2.241 | *\n",
      "Batch: 448/500 | Epoch  34, time=543.9ms/ 13.6ms | Train: loss=2.212 | Valid: loss=2.212 | *\n",
      "Batch: 448/500 | Epoch  35, time=562.6ms/ 13.4ms | Train: loss=2.193 | Valid: loss=2.193 | *\n",
      "Batch: 448/500 | Epoch  36, time=575.9ms/ 16.3ms | Train: loss=2.168 | Valid: loss=2.168 | *\n",
      "Batch: 448/500 | Epoch  37, time=545.8ms/ 13.1ms | Train: loss=2.135 | Valid: loss=2.135 | *\n",
      "Batch: 448/500 | Epoch  38, time=589.5ms/ 16.7ms | Train: loss=2.113 | Valid: loss=2.113 | *\n",
      "Batch: 448/500 | Epoch  39, time=577.7ms/ 13.2ms | Train: loss=2.103 | Valid: loss=2.103 | *\n",
      "Batch: 448/500 | Epoch  40, time=560.8ms/ 13.0ms | Train: loss=2.090 | Valid: loss=2.090 | *\n",
      "Batch: 448/500 | Epoch  41, time=544.2ms/ 12.9ms | Train: loss=2.055 | Valid: loss=2.055 | *\n",
      "Batch: 448/500 | Epoch  42, time=567.8ms/ 13.6ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  43, time=560.9ms/ 12.9ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  44, time=572.5ms/ 13.0ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  45, time=567.9ms/ 13.5ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  46, time=535.9ms/ 13.6ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  47, time=550.1ms/ 13.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  48, time=593.9ms/ 13.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  49, time=585.0ms/ 16.4ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  50, time=554.8ms/ 15.7ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  51, time=526.9ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  52, time=554.4ms/ 16.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  53, time=534.9ms/ 13.0ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  54, time=575.0ms/ 13.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  55, time=594.9ms/ 13.2ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  56, time=570.9ms/ 13.0ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  57, time=526.2ms/ 13.0ms | Train: loss=2.057 | Valid: loss=2.057 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  58, time=572.8ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  59, time=528.8ms/ 12.9ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  60, time=589.9ms/ 13.4ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  61, time=554.1ms/ 12.9ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  62, time=616.8ms/ 12.8ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  63, time=593.3ms/ 14.0ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  64, time=552.3ms/ 13.7ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  65, time=526.0ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  66, time=586.2ms/ 13.5ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  67, time=578.3ms/ 12.9ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  68, time=581.4ms/ 15.6ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  69, time=573.0ms/ 13.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  70, time=567.9ms/ 13.4ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  71, time=570.2ms/ 13.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  72, time=572.4ms/ 13.0ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  73, time=558.0ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  74, time=563.0ms/ 13.9ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  75, time=527.9ms/ 13.7ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  76, time=547.0ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  77, time=576.2ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  78, time=573.1ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  79, time=611.4ms/ 13.7ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  80, time=570.9ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  81, time=576.2ms/ 13.2ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  82, time=575.8ms/ 12.9ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  83, time=576.7ms/ 17.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  84, time=543.5ms/ 13.5ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  85, time=554.7ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  86, time=560.3ms/ 13.4ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  87, time=529.9ms/ 12.8ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  88, time=568.0ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  89, time=546.4ms/ 14.0ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  90, time=557.4ms/ 13.2ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  91, time=567.0ms/ 13.2ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  92, time=581.6ms/ 13.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  93, time=524.6ms/ 13.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  94, time=557.3ms/ 13.5ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  95, time=582.6ms/ 13.0ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  96, time=562.0ms/ 16.3ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  97, time=579.6ms/ 16.4ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  98, time=571.3ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch  99, time=591.3ms/ 12.9ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "Batch: 448/500 | Epoch 100, time=583.0ms/ 13.0ms | Train: loss=2.057 | Valid: loss=2.057 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.562\n",
      "Test on task  1 - Mopping the floor: loss=1.846\n",
      "Test on task  2 - Carry warm food: loss=1.636\n",
      "Test on task  3 - Carry cold food: loss=2.110\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task  4 (Carry drinks)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  4\n",
      "Batch: 448/500 | Epoch   1, time=540.6ms/ 13.2ms | Train: loss=3.259 | Valid: loss=3.259 | *\n",
      "Batch: 448/500 | Epoch   2, time=584.5ms/ 13.0ms | Train: loss=3.201 | Valid: loss=3.201 | *\n",
      "Batch: 448/500 | Epoch   3, time=568.2ms/ 13.5ms | Train: loss=3.141 | Valid: loss=3.141 | *\n",
      "Batch: 448/500 | Epoch   4, time=563.1ms/ 13.4ms | Train: loss=3.088 | Valid: loss=3.088 | *\n",
      "Batch: 448/500 | Epoch   5, time=557.5ms/ 13.2ms | Train: loss=3.036 | Valid: loss=3.036 | *\n",
      "Batch: 448/500 | Epoch   6, time=586.2ms/ 14.8ms | Train: loss=2.986 | Valid: loss=2.986 | *\n",
      "Batch: 448/500 | Epoch   7, time=567.0ms/ 13.6ms | Train: loss=2.937 | Valid: loss=2.937 | *\n",
      "Batch: 448/500 | Epoch   8, time=599.9ms/ 12.9ms | Train: loss=2.889 | Valid: loss=2.889 | *\n",
      "Batch: 448/500 | Epoch   9, time=553.0ms/ 13.0ms | Train: loss=2.845 | Valid: loss=2.845 | *\n",
      "Batch: 448/500 | Epoch  10, time=554.5ms/ 12.9ms | Train: loss=2.801 | Valid: loss=2.801 | *\n",
      "Batch: 448/500 | Epoch  11, time=602.5ms/ 16.7ms | Train: loss=2.761 | Valid: loss=2.761 | *\n",
      "Batch: 448/500 | Epoch  12, time=581.0ms/ 13.3ms | Train: loss=2.718 | Valid: loss=2.718 | *\n",
      "Batch: 448/500 | Epoch  13, time=573.6ms/ 13.9ms | Train: loss=2.678 | Valid: loss=2.678 | *\n",
      "Batch: 448/500 | Epoch  14, time=591.3ms/ 13.1ms | Train: loss=2.636 | Valid: loss=2.636 | *\n",
      "Batch: 448/500 | Epoch  15, time=591.2ms/ 16.3ms | Train: loss=2.591 | Valid: loss=2.591 | *\n",
      "Batch: 448/500 | Epoch  16, time=598.6ms/ 15.6ms | Train: loss=2.554 | Valid: loss=2.554 | *\n",
      "Batch: 448/500 | Epoch  17, time=545.8ms/ 13.1ms | Train: loss=2.517 | Valid: loss=2.517 | *\n",
      "Batch: 448/500 | Epoch  18, time=562.4ms/ 13.1ms | Train: loss=2.480 | Valid: loss=2.480 | *\n",
      "Batch: 448/500 | Epoch  19, time=541.4ms/ 13.2ms | Train: loss=2.442 | Valid: loss=2.442 | *\n",
      "Batch: 448/500 | Epoch  20, time=574.4ms/ 13.1ms | Train: loss=2.410 | Valid: loss=2.410 | *\n",
      "Batch: 448/500 | Epoch  21, time=569.6ms/ 13.0ms | Train: loss=2.373 | Valid: loss=2.373 | *\n",
      "Batch: 448/500 | Epoch  22, time=588.5ms/ 13.0ms | Train: loss=2.342 | Valid: loss=2.342 | *\n",
      "Batch: 448/500 | Epoch  23, time=585.9ms/ 13.5ms | Train: loss=2.307 | Valid: loss=2.307 | *\n",
      "Batch: 448/500 | Epoch  24, time=526.7ms/ 12.9ms | Train: loss=2.270 | Valid: loss=2.270 | *\n",
      "Batch: 448/500 | Epoch  25, time=536.3ms/ 13.9ms | Train: loss=2.244 | Valid: loss=2.244 | *\n",
      "Batch: 448/500 | Epoch  26, time=562.4ms/ 13.6ms | Train: loss=2.209 | Valid: loss=2.209 | *\n",
      "Batch: 448/500 | Epoch  27, time=535.0ms/ 13.4ms | Train: loss=2.180 | Valid: loss=2.180 | *\n",
      "Batch: 448/500 | Epoch  28, time=537.7ms/ 13.7ms | Train: loss=2.148 | Valid: loss=2.148 | *\n",
      "Batch: 448/500 | Epoch  29, time=544.2ms/ 12.9ms | Train: loss=2.119 | Valid: loss=2.119 | *\n",
      "Batch: 448/500 | Epoch  30, time=574.0ms/ 12.9ms | Train: loss=2.085 | Valid: loss=2.085 | *\n",
      "Batch: 448/500 | Epoch  31, time=567.8ms/ 13.1ms | Train: loss=2.057 | Valid: loss=2.057 | *\n",
      "Batch: 448/500 | Epoch  32, time=576.0ms/ 13.1ms | Train: loss=2.030 | Valid: loss=2.030 | *\n",
      "Batch: 448/500 | Epoch  33, time=540.4ms/ 13.6ms | Train: loss=2.007 | Valid: loss=2.007 | *\n",
      "Batch: 448/500 | Epoch  34, time=560.3ms/ 13.0ms | Train: loss=1.974 | Valid: loss=1.974 | *\n",
      "Batch: 448/500 | Epoch  35, time=548.0ms/ 13.8ms | Train: loss=1.951 | Valid: loss=1.951 | *\n",
      "Batch: 448/500 | Epoch  36, time=572.6ms/ 13.5ms | Train: loss=1.924 | Valid: loss=1.924 | *\n",
      "Batch: 448/500 | Epoch  37, time=573.6ms/ 13.1ms | Train: loss=1.897 | Valid: loss=1.897 | *\n",
      "Batch: 448/500 | Epoch  38, time=567.0ms/ 13.1ms | Train: loss=1.874 | Valid: loss=1.874 | *\n",
      "Batch: 448/500 | Epoch  39, time=543.7ms/ 13.2ms | Train: loss=1.853 | Valid: loss=1.853 | *\n",
      "Batch: 448/500 | Epoch  40, time=568.2ms/ 13.0ms | Train: loss=1.831 | Valid: loss=1.831 | *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  41, time=571.6ms/ 12.9ms | Train: loss=1.812 | Valid: loss=1.812 | *\n",
      "Batch: 448/500 | Epoch  42, time=573.6ms/ 13.1ms | Train: loss=1.790 | Valid: loss=1.790 | *\n",
      "Batch: 448/500 | Epoch  43, time=592.6ms/ 13.5ms | Train: loss=1.771 | Valid: loss=1.771 | *\n",
      "Batch: 448/500 | Epoch  44, time=580.5ms/ 13.8ms | Train: loss=1.752 | Valid: loss=1.752 | *\n",
      "Batch: 448/500 | Epoch  45, time=593.0ms/ 14.6ms | Train: loss=1.734 | Valid: loss=1.734 | *\n",
      "Batch: 448/500 | Epoch  46, time=535.4ms/ 17.4ms | Train: loss=1.716 | Valid: loss=1.716 | *\n",
      "Batch: 448/500 | Epoch  47, time=592.7ms/ 13.0ms | Train: loss=1.702 | Valid: loss=1.702 | *\n",
      "Batch: 448/500 | Epoch  48, time=587.3ms/ 13.0ms | Train: loss=1.686 | Valid: loss=1.686 | *\n",
      "Batch: 448/500 | Epoch  49, time=565.7ms/ 13.0ms | Train: loss=1.673 | Valid: loss=1.673 | *\n",
      "Batch: 448/500 | Epoch  50, time=548.7ms/ 13.7ms | Train: loss=1.658 | Valid: loss=1.658 | *\n",
      "Batch: 448/500 | Epoch  51, time=548.2ms/ 13.6ms | Train: loss=1.644 | Valid: loss=1.644 | *\n",
      "Batch: 448/500 | Epoch  52, time=588.7ms/ 13.6ms | Train: loss=1.629 | Valid: loss=1.629 | *\n",
      "Batch: 448/500 | Epoch  53, time=560.6ms/ 13.3ms | Train: loss=1.617 | Valid: loss=1.617 | *\n",
      "Batch: 448/500 | Epoch  54, time=542.6ms/ 16.6ms | Train: loss=1.606 | Valid: loss=1.606 | *\n",
      "Batch: 448/500 | Epoch  55, time=556.6ms/ 16.9ms | Train: loss=1.594 | Valid: loss=1.594 | *\n",
      "Batch: 448/500 | Epoch  56, time=573.4ms/ 12.8ms | Train: loss=1.589 | Valid: loss=1.589 | *\n",
      "Batch: 448/500 | Epoch  57, time=530.9ms/ 13.1ms | Train: loss=1.580 | Valid: loss=1.580 | *\n",
      "Batch: 448/500 | Epoch  58, time=544.0ms/ 13.5ms | Train: loss=1.570 | Valid: loss=1.570 | *\n",
      "Batch: 448/500 | Epoch  59, time=549.4ms/ 13.3ms | Train: loss=1.565 | Valid: loss=1.565 | *\n",
      "Batch: 448/500 | Epoch  60, time=578.4ms/ 13.1ms | Train: loss=1.558 | Valid: loss=1.558 | *\n",
      "Batch: 448/500 | Epoch  61, time=595.9ms/ 15.4ms | Train: loss=1.551 | Valid: loss=1.551 | *\n",
      "Batch: 448/500 | Epoch  62, time=581.7ms/ 12.9ms | Train: loss=1.544 | Valid: loss=1.544 | *\n",
      "Batch: 448/500 | Epoch  63, time=578.2ms/ 13.0ms | Train: loss=1.536 | Valid: loss=1.536 | *\n",
      "Batch: 448/500 | Epoch  64, time=557.0ms/ 14.4ms | Train: loss=1.531 | Valid: loss=1.531 | *\n",
      "Batch: 448/500 | Epoch  65, time=547.7ms/ 13.9ms | Train: loss=1.525 | Valid: loss=1.525 | *\n",
      "Batch: 448/500 | Epoch  66, time=606.4ms/ 13.2ms | Train: loss=1.520 | Valid: loss=1.520 | *\n",
      "Batch: 448/500 | Epoch  67, time=530.4ms/ 13.7ms | Train: loss=1.514 | Valid: loss=1.514 | *\n",
      "Batch: 448/500 | Epoch  68, time=558.5ms/ 14.9ms | Train: loss=1.511 | Valid: loss=1.511 | *\n",
      "Batch: 448/500 | Epoch  69, time=549.6ms/ 12.9ms | Train: loss=1.508 | Valid: loss=1.508 | *\n",
      "Batch: 448/500 | Epoch  70, time=565.9ms/ 13.1ms | Train: loss=1.505 | Valid: loss=1.505 | *\n",
      "Batch: 448/500 | Epoch  71, time=572.1ms/ 13.3ms | Train: loss=1.500 | Valid: loss=1.500 | *\n",
      "Batch: 448/500 | Epoch  72, time=576.5ms/ 13.1ms | Train: loss=1.497 | Valid: loss=1.497 | *\n",
      "Batch: 448/500 | Epoch  73, time=535.7ms/ 12.9ms | Train: loss=1.494 | Valid: loss=1.494 | *\n",
      "Batch: 448/500 | Epoch  74, time=568.2ms/ 13.1ms | Train: loss=1.491 | Valid: loss=1.491 | *\n",
      "Batch: 448/500 | Epoch  75, time=574.1ms/ 16.4ms | Train: loss=1.489 | Valid: loss=1.489 | *\n",
      "Batch: 448/500 | Epoch  76, time=547.9ms/ 12.9ms | Train: loss=1.488 | Valid: loss=1.488 | *\n",
      "Batch: 448/500 | Epoch  77, time=563.8ms/ 13.0ms | Train: loss=1.487 | Valid: loss=1.487 | *\n",
      "Batch: 448/500 | Epoch  78, time=561.1ms/ 13.0ms | Train: loss=1.485 | Valid: loss=1.485 | *\n",
      "Batch: 448/500 | Epoch  79, time=577.8ms/ 12.9ms | Train: loss=1.484 | Valid: loss=1.484 | *\n",
      "Batch: 448/500 | Epoch  80, time=556.8ms/ 12.9ms | Train: loss=1.483 | Valid: loss=1.483 | *\n",
      "Batch: 448/500 | Epoch  81, time=563.0ms/ 14.0ms | Train: loss=1.483 | Valid: loss=1.483 | *\n",
      "Batch: 448/500 | Epoch  82, time=588.1ms/ 13.1ms | Train: loss=1.482 | Valid: loss=1.482 | *\n",
      "Batch: 448/500 | Epoch  83, time=561.2ms/ 13.0ms | Train: loss=1.482 | Valid: loss=1.482 | *\n",
      "Batch: 448/500 | Epoch  84, time=537.4ms/ 12.9ms | Train: loss=1.481 | Valid: loss=1.481 | *\n",
      "Batch: 448/500 | Epoch  85, time=537.2ms/ 14.8ms | Train: loss=1.480 | Valid: loss=1.480 | *\n",
      "Batch: 448/500 | Epoch  86, time=579.4ms/ 13.2ms | Train: loss=1.479 | Valid: loss=1.479 | *\n",
      "Batch: 448/500 | Epoch  87, time=581.3ms/ 12.8ms | Train: loss=1.479 | Valid: loss=1.479 | *\n",
      "Batch: 448/500 | Epoch  88, time=566.1ms/ 16.6ms | Train: loss=1.479 | Valid: loss=1.479 | *\n",
      "Batch: 448/500 | Epoch  89, time=581.4ms/ 13.1ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  90, time=573.6ms/ 13.1ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  91, time=575.6ms/ 13.5ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  92, time=571.0ms/ 12.8ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  93, time=571.9ms/ 13.5ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  94, time=560.3ms/ 13.1ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  95, time=525.1ms/ 13.1ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  96, time=541.7ms/ 13.6ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  97, time=560.1ms/ 13.4ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  98, time=569.1ms/ 12.9ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch  99, time=602.9ms/ 12.9ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "Batch: 448/500 | Epoch 100, time=593.7ms/ 13.2ms | Train: loss=1.479 | Valid: loss=1.479 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.618\n",
      "Test on task  1 - Mopping the floor: loss=1.959\n",
      "Test on task  2 - Carry warm food: loss=1.772\n",
      "Test on task  3 - Carry cold food: loss=2.311\n",
      "Test on task  4 - Carry drinks   : loss=1.411\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task  5 (Carry small objects (plates, toys))\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  5\n",
      "Batch: 448/500 | Epoch   1, time=538.6ms/ 13.8ms | Train: loss=8.158 | Valid: loss=8.158 | *\n",
      "Batch: 448/500 | Epoch   2, time=566.5ms/ 12.8ms | Train: loss=5.388 | Valid: loss=5.388 | *\n",
      "Batch: 448/500 | Epoch   3, time=571.1ms/ 13.3ms | Train: loss=3.969 | Valid: loss=3.969 | *\n",
      "Batch: 448/500 | Epoch   4, time=538.6ms/ 13.7ms | Train: loss=3.277 | Valid: loss=3.277 | *\n",
      "Batch: 448/500 | Epoch   5, time=598.4ms/ 16.5ms | Train: loss=2.910 | Valid: loss=2.910 | *\n",
      "Batch: 448/500 | Epoch   6, time=530.0ms/ 12.9ms | Train: loss=2.658 | Valid: loss=2.658 | *\n",
      "Batch: 448/500 | Epoch   7, time=572.4ms/ 13.4ms | Train: loss=2.410 | Valid: loss=2.410 | *\n",
      "Batch: 448/500 | Epoch   8, time=616.4ms/ 16.4ms | Train: loss=2.256 | Valid: loss=2.256 | *\n",
      "Batch: 448/500 | Epoch   9, time=565.4ms/ 13.1ms | Train: loss=2.173 | Valid: loss=2.173 | *\n",
      "Batch: 448/500 | Epoch  10, time=574.8ms/ 15.6ms | Train: loss=2.109 | Valid: loss=2.109 | *\n",
      "Batch: 448/500 | Epoch  11, time=594.7ms/ 12.9ms | Train: loss=2.049 | Valid: loss=2.049 | *\n",
      "Batch: 448/500 | Epoch  12, time=567.9ms/ 12.9ms | Train: loss=2.007 | Valid: loss=2.007 | *\n",
      "Batch: 448/500 | Epoch  13, time=557.0ms/ 16.4ms | Train: loss=1.974 | Valid: loss=1.974 | *\n",
      "Batch: 448/500 | Epoch  14, time=582.9ms/ 13.5ms | Train: loss=1.928 | Valid: loss=1.928 | *\n",
      "Batch: 448/500 | Epoch  15, time=571.8ms/ 13.1ms | Train: loss=1.896 | Valid: loss=1.896 | *\n",
      "Batch: 448/500 | Epoch  16, time=566.1ms/ 13.0ms | Train: loss=1.870 | Valid: loss=1.870 | *\n",
      "Batch: 448/500 | Epoch  17, time=530.0ms/ 13.0ms | Train: loss=1.850 | Valid: loss=1.850 | *\n",
      "Batch: 448/500 | Epoch  18, time=574.1ms/ 13.1ms | Train: loss=1.831 | Valid: loss=1.831 | *\n",
      "Batch: 448/500 | Epoch  19, time=572.9ms/ 13.4ms | Train: loss=1.811 | Valid: loss=1.811 | *\n",
      "Batch: 448/500 | Epoch  20, time=583.5ms/ 13.0ms | Train: loss=1.797 | Valid: loss=1.797 | *\n",
      "Batch: 448/500 | Epoch  21, time=574.0ms/ 13.1ms | Train: loss=1.781 | Valid: loss=1.781 | *\n",
      "Batch: 448/500 | Epoch  22, time=538.6ms/ 13.5ms | Train: loss=1.769 | Valid: loss=1.769 | *\n",
      "Batch: 448/500 | Epoch  23, time=577.4ms/ 14.1ms | Train: loss=1.760 | Valid: loss=1.760 | *\n",
      "Batch: 448/500 | Epoch  24, time=584.5ms/ 14.4ms | Train: loss=1.747 | Valid: loss=1.747 | *\n",
      "Batch: 448/500 | Epoch  25, time=546.5ms/ 13.2ms | Train: loss=1.740 | Valid: loss=1.740 | *\n",
      "Batch: 448/500 | Epoch  26, time=579.4ms/ 13.0ms | Train: loss=1.730 | Valid: loss=1.730 | *\n",
      "Batch: 448/500 | Epoch  27, time=576.2ms/ 12.9ms | Train: loss=1.723 | Valid: loss=1.723 | *\n",
      "Batch: 448/500 | Epoch  28, time=597.1ms/ 12.8ms | Train: loss=1.713 | Valid: loss=1.713 | *\n",
      "Batch: 448/500 | Epoch  29, time=525.8ms/ 12.9ms | Train: loss=1.703 | Valid: loss=1.703 | *\n",
      "Batch: 448/500 | Epoch  30, time=547.2ms/ 13.1ms | Train: loss=1.697 | Valid: loss=1.697 | *\n",
      "Batch: 448/500 | Epoch  31, time=546.9ms/ 13.5ms | Train: loss=1.689 | Valid: loss=1.689 | *\n",
      "Batch: 448/500 | Epoch  32, time=560.5ms/ 13.2ms | Train: loss=1.681 | Valid: loss=1.681 | *\n",
      "Batch: 448/500 | Epoch  33, time=565.3ms/ 13.9ms | Train: loss=1.672 | Valid: loss=1.672 | *\n",
      "Batch: 448/500 | Epoch  34, time=569.0ms/ 13.6ms | Train: loss=1.665 | Valid: loss=1.665 | *\n",
      "Batch: 448/500 | Epoch  35, time=562.5ms/ 13.0ms | Train: loss=1.658 | Valid: loss=1.658 | *\n",
      "Batch: 448/500 | Epoch  36, time=557.2ms/ 13.0ms | Train: loss=1.650 | Valid: loss=1.650 | *\n",
      "Batch: 448/500 | Epoch  37, time=574.6ms/ 13.2ms | Train: loss=1.640 | Valid: loss=1.640 | *\n",
      "Batch: 448/500 | Epoch  38, time=566.9ms/ 14.4ms | Train: loss=1.640 | Valid: loss=1.640 | *\n",
      "Batch: 448/500 | Epoch  39, time=548.0ms/ 12.9ms | Train: loss=1.637 | Valid: loss=1.637 | *\n",
      "Batch: 448/500 | Epoch  40, time=561.0ms/ 13.0ms | Train: loss=1.626 | Valid: loss=1.626 | *\n",
      "Batch: 448/500 | Epoch  41, time=600.8ms/ 13.2ms | Train: loss=1.622 | Valid: loss=1.622 | *\n",
      "Batch: 448/500 | Epoch  42, time=574.9ms/ 13.2ms | Train: loss=1.612 | Valid: loss=1.612 | *\n",
      "Batch: 448/500 | Epoch  43, time=584.7ms/ 16.4ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  44, time=583.6ms/ 13.3ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  45, time=578.2ms/ 13.3ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  46, time=552.6ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  47, time=535.9ms/ 13.9ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  48, time=554.2ms/ 13.8ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  49, time=524.5ms/ 13.0ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  50, time=554.5ms/ 17.2ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  51, time=527.8ms/ 12.9ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  52, time=566.6ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  53, time=573.5ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  54, time=583.3ms/ 16.6ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  55, time=583.4ms/ 14.9ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  56, time=577.1ms/ 13.2ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  57, time=576.6ms/ 13.0ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  58, time=589.1ms/ 16.8ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  59, time=587.2ms/ 13.2ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  60, time=569.3ms/ 13.2ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  61, time=592.5ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  62, time=591.3ms/ 15.0ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  63, time=583.2ms/ 13.7ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  64, time=571.8ms/ 13.9ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  65, time=576.3ms/ 13.0ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  66, time=537.6ms/ 13.2ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  67, time=544.9ms/ 14.4ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  68, time=553.6ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  69, time=541.8ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  70, time=529.9ms/ 13.6ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  71, time=556.0ms/ 12.8ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  72, time=595.9ms/ 13.5ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  73, time=546.4ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  74, time=542.2ms/ 12.9ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  75, time=580.3ms/ 14.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  76, time=546.0ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  77, time=583.1ms/ 14.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  78, time=566.5ms/ 13.4ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  79, time=576.8ms/ 13.2ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  80, time=556.2ms/ 13.0ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  81, time=522.8ms/ 12.9ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  82, time=575.4ms/ 13.7ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  83, time=548.2ms/ 13.8ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  84, time=544.2ms/ 13.8ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  85, time=526.6ms/ 13.3ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  86, time=526.3ms/ 12.9ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  87, time=549.0ms/ 13.3ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  88, time=600.8ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  89, time=554.3ms/ 12.9ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  90, time=563.3ms/ 13.5ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  91, time=548.7ms/ 16.3ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  92, time=576.2ms/ 13.2ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  93, time=597.2ms/ 13.4ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  94, time=576.7ms/ 12.9ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  95, time=580.3ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  96, time=586.8ms/ 16.7ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  97, time=584.4ms/ 14.8ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  98, time=579.1ms/ 13.3ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 | Epoch  99, time=558.2ms/ 13.3ms | Train: loss=1.613 | Valid: loss=1.613 |\n",
      "Batch: 448/500 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch  32, time=576.8ms/ 13.1ms | Train: loss=1.791 | Valid: loss=1.791 | *\n",
      "Batch: 448/500 | Epoch  33, time=580.7ms/ 16.6ms | Train: loss=1.776 | Valid: loss=1.776 | *\n",
      "Batch: 448/500 | Epoch  34, time=554.7ms/ 12.9ms | Train: loss=1.767 | Valid: loss=1.767 | *\n",
      "Batch: 448/500 | Epoch  35, time=583.2ms/ 13.0ms | Train: loss=1.747 | Valid: loss=1.747 | *\n",
      "Batch: 448/500 | Epoch  36, time=574.9ms/ 13.0ms | Train: loss=1.735 | Valid: loss=1.735 | *\n",
      "Batch: 448/500 | Epoch  37, time=582.0ms/ 13.1ms | Train: loss=1.727 | Valid: loss=1.727 | *\n",
      "Batch: 448/500 | Epoch  38, time=527.2ms/ 13.0ms | Train: loss=1.713 | Valid: loss=1.713 | *\n",
      "Batch: 448/500 | Epoch  39, time=599.8ms/ 13.0ms | Train: loss=1.699 | Valid: loss=1.699 | *\n",
      "Batch: 448/500 | Epoch  40, time=549.5ms/ 13.1ms | Train: loss=1.687 | Valid: loss=1.687 | *\n",
      "Batch: 448/500 | Epoch  65, time=533.9ms/ 13.0ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  66, time=542.7ms/ 13.0ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  67, time=526.1ms/ 13.3ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  68, time=603.5ms/ 13.1ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  69, time=588.1ms/ 16.6ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  70, time=576.6ms/ 13.0ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  71, time=589.5ms/ 16.4ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  72, time=567.9ms/ 13.2ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  73, time=528.4ms/ 13.0ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  74, time=573.3ms/ 13.2ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  75, time=541.9ms/ 12.9ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  76, time=539.2ms/ 13.0ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  77, time=541.8ms/ 13.0ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  78, time=554.4ms/ 13.2ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  79, time=579.3ms/ 13.1ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  80, time=551.1ms/ 13.4ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  81, time=557.7ms/ 13.0ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  82, time=560.6ms/ 13.4ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  83, time=538.5ms/ 16.1ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  84, time=590.2ms/ 13.3ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  85, time=554.7ms/ 13.2ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  86, time=558.9ms/ 13.2ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  87, time=572.8ms/ 14.1ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  88, time=562.0ms/ 13.0ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  89, time=563.8ms/ 13.0ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  90, time=552.1ms/ 12.8ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  91, time=585.2ms/ 13.2ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  92, time=565.8ms/ 13.2ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  93, time=558.4ms/ 15.4ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  94, time=553.0ms/ 12.9ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  95, time=577.0ms/ 13.1ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  96, time=601.0ms/ 13.5ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  97, time=588.2ms/ 16.4ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  98, time=587.7ms/ 12.9ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch  99, time=615.6ms/ 16.9ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "Batch: 448/500 | Epoch 100, time=563.7ms/ 13.2ms | Train: loss=1.586 | Valid: loss=1.586 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.698\n",
      "Test on task  1 - Mopping the floor: loss=2.252\n",
      "Test on task  2 - Carry warm food: loss=1.814\n",
      "Test on task  3 - Carry cold food: loss=2.286\n",
      "Test on task  4 - Carry drinks   : loss=1.402\n",
      "Test on task  5 - Carry small objects (plates, toys): loss=1.734\n",
      "Test on task  6 - Carry big objects (tables, chairs): loss=1.526\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task  7 (Cleaning (Picking up stuff))\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  7\n",
      "Batch: 448/500 | Epoch   1, time=570.7ms/ 13.8ms | Train: loss=4.311 | Valid: loss=4.311 | *\n",
      "Batch: 448/500 | Epoch   2, time=564.8ms/ 15.7ms | Train: loss=4.117 | Valid: loss=4.117 | *\n",
      "Batch: 448/500 | Epoch   3, time=560.8ms/ 12.8ms | Train: loss=3.852 | Valid: loss=3.852 | *\n",
      "Batch: 448/500 | Epoch   4, time=579.9ms/ 15.7ms | Train: loss=3.668 | Valid: loss=3.668 | *\n",
      "Batch: 448/500 | Epoch   5, time=586.5ms/ 13.2ms | Train: loss=3.562 | Valid: loss=3.562 | *\n",
      "Batch: 448/500 | Epoch   6, time=553.5ms/ 13.3ms | Train: loss=3.425 | Valid: loss=3.425 | *\n",
      "Batch: 448/500 | Epoch   7, time=575.5ms/ 13.1ms | Train: loss=3.357 | Valid: loss=3.357 | *\n",
      "Batch: 448/500 | Epoch   8, time=588.9ms/ 13.1ms | Train: loss=3.300 | Valid: loss=3.300 | *\n",
      "Batch: 448/500 | Epoch   9, time=563.8ms/ 13.3ms | Train: loss=3.220 | Valid: loss=3.220 | *\n",
      "Batch: 448/500 | Epoch  10, time=555.9ms/ 13.4ms | Train: loss=3.154 | Valid: loss=3.154 | *\n",
      "Batch: 448/500 | Epoch  11, time=572.7ms/ 13.4ms | Train: loss=3.073 | Valid: loss=3.073 | *\n",
      "Batch: 448/500 | Epoch  12, time=573.0ms/ 17.4ms | Train: loss=3.046 | Valid: loss=3.046 | *\n",
      "Batch: 448/500 | Epoch  13, time=547.5ms/ 13.7ms | Train: loss=2.977 | Valid: loss=2.977 | *\n",
      "Batch: 448/500 | Epoch  14, time=575.5ms/ 13.1ms | Train: loss=2.932 | Valid: loss=2.932 | *\n",
      "Batch: 448/500 | Epoch  15, time=572.1ms/ 13.8ms | Train: loss=2.895 | Valid: loss=2.895 | *\n",
      "Batch: 448/500 | Epoch  16, time=583.8ms/ 13.0ms | Train: loss=2.864 | Valid: loss=2.864 | *\n",
      "Batch: 448/500 | Epoch  17, time=607.7ms/ 12.9ms | Train: loss=2.791 | Valid: loss=2.791 | *\n",
      "Batch: 448/500 | Epoch  18, time=590.4ms/ 13.4ms | Train: loss=2.757 | Valid: loss=2.757 | *\n",
      "Batch: 448/500 | Epoch  19, time=578.5ms/ 13.8ms | Train: loss=2.709 | Valid: loss=2.709 | *\n",
      "Batch: 448/500 | Epoch  20, time=564.7ms/ 14.1ms | Train: loss=2.673 | Valid: loss=2.673 | *\n",
      "Batch: 448/500 | Epoch  21, time=544.6ms/ 14.3ms | Train: loss=2.644 | Valid: loss=2.644 | *\n",
      "Batch: 448/500 | Epoch  22, time=601.8ms/ 16.3ms | Train: loss=2.624 | Valid: loss=2.624 | *\n",
      "Batch: 448/500 | Epoch  23, time=583.9ms/ 13.1ms | Train: loss=2.579 | Valid: loss=2.579 | *\n",
      "Batch: 448/500 | Epoch  24, time=597.6ms/ 13.0ms | Train: loss=2.540 | Valid: loss=2.540 | *\n",
      "Batch: 448/500 | Epoch  25, time=610.2ms/ 12.9ms | Train: loss=2.490 | Valid: loss=2.490 | *\n",
      "Batch: 448/500 | Epoch  26, time=588.4ms/ 13.5ms | Train: loss=2.463 | Valid: loss=2.463 | *\n",
      "Batch: 448/500 | Epoch  27, time=549.5ms/ 13.7ms | Train: loss=2.412 | Valid: loss=2.412 | *\n",
      "Batch: 448/500 | Epoch  28, time=525.6ms/ 13.0ms | Train: loss=2.367 | Valid: loss=2.367 | *\n",
      "Batch: 448/500 | Epoch  29, time=579.0ms/ 12.9ms | Train: loss=2.333 | Valid: loss=2.333 | *\n",
      "Batch: 448/500 | Epoch  30, time=533.5ms/ 13.2ms | Train: loss=2.314 | Valid: loss=2.314 | *\n",
      "Batch: 448/500 | Epoch  31, time=558.9ms/ 13.5ms | Train: loss=2.283 | Valid: loss=2.283 | *\n",
      "Batch: 448/500 | Epoch  32, time=541.8ms/ 13.4ms | Train: loss=2.248 | Valid: loss=2.248 | *\n",
      "Batch: 448/500 | Epoch  33, time=555.0ms/ 12.9ms | Train: loss=2.216 | Valid: loss=2.216 | *\n",
      "Batch: 448/500 | Epoch  34, time=571.5ms/ 12.9ms | Train: loss=2.201 | Valid: loss=2.201 | *\n",
      "Batch: 448/500 | Epoch  35, time=587.3ms/ 13.2ms | Train: loss=2.182 | Valid: loss=2.182 | *\n",
      "Batch: 448/500 | Epoch  36, time=545.0ms/ 14.5ms | Train: loss=2.154 | Valid: loss=2.154 | *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  37, time=541.5ms/ 13.2ms | Train: loss=2.126 | Valid: loss=2.126 | *\n",
      "Batch: 448/500 | Epoch  38, time=571.7ms/ 13.0ms | Train: loss=2.094 | Valid: loss=2.094 | *\n",
      "Batch: 448/500 | Epoch  39, time=588.3ms/ 12.9ms | Train: loss=2.065 | Valid: loss=2.065 | *\n",
      "Batch: 448/500 | Epoch  40, time=592.4ms/ 13.0ms | Train: loss=2.037 | Valid: loss=2.037 | *\n",
      "Batch: 448/500 | Epoch  41, time=539.7ms/ 14.2ms | Train: loss=2.004 | Valid: loss=2.004 | *\n",
      "Batch: 448/500 | Epoch  42, time=527.8ms/ 14.2ms | Train: loss=1.992 | Valid: loss=1.992 | *\n",
      "Batch: 448/500 | Epoch  43, time=544.6ms/ 13.1ms | Train: loss=1.964 | Valid: loss=1.964 | *\n",
      "Batch: 448/500 | Epoch  44, time=577.8ms/ 13.6ms | Train: loss=1.941 | Valid: loss=1.941 | *\n",
      "Batch: 448/500 | Epoch  45, time=578.0ms/ 13.2ms | Train: loss=1.921 | Valid: loss=1.921 | *\n",
      "Batch: 448/500 | Epoch  46, time=578.6ms/ 13.0ms | Train: loss=1.906 | Valid: loss=1.906 | *\n",
      "Batch: 448/500 | Epoch  47, time=556.2ms/ 13.0ms | Train: loss=1.891 | Valid: loss=1.891 | *\n",
      "Batch: 448/500 | Epoch  48, time=584.1ms/ 13.7ms | Train: loss=1.876 | Valid: loss=1.876 | *\n",
      "Batch: 448/500 | Epoch  49, time=588.9ms/ 13.0ms | Train: loss=1.859 | Valid: loss=1.859 | *\n",
      "Batch: 448/500 | Epoch  50, time=576.7ms/ 13.1ms | Train: loss=1.837 | Valid: loss=1.837 | *\n",
      "Batch: 448/500 | Epoch  51, time=587.4ms/ 13.4ms | Train: loss=1.822 | Valid: loss=1.822 | *\n",
      "Batch: 448/500 | Epoch  52, time=557.7ms/ 12.9ms | Train: loss=1.809 | Valid: loss=1.809 | *\n",
      "Batch: 448/500 | Epoch  53, time=550.6ms/ 12.9ms | Train: loss=1.796 | Valid: loss=1.796 | *\n",
      "Batch: 448/500 | Epoch  54, time=546.3ms/ 13.1ms | Train: loss=1.780 | Valid: loss=1.780 | *\n",
      "Batch: 448/500 | Epoch  55, time=572.7ms/ 13.0ms | Train: loss=1.766 | Valid: loss=1.766 | *\n",
      "Batch: 448/500 | Epoch  56, time=628.8ms/ 17.0ms | Train: loss=1.754 | Valid: loss=1.754 | *\n",
      "Batch: 448/500 | Epoch  57, time=537.7ms/ 13.7ms | Train: loss=1.744 | Valid: loss=1.744 | *\n",
      "Batch: 448/500 | Epoch  58, time=539.3ms/ 13.3ms | Train: loss=1.726 | Valid: loss=1.726 | *\n",
      "Batch: 448/500 | Epoch  59, time=576.5ms/ 13.8ms | Train: loss=1.718 | Valid: loss=1.718 | *\n",
      "Batch: 448/500 | Epoch  60, time=579.4ms/ 13.1ms | Train: loss=1.709 | Valid: loss=1.709 | *\n",
      "Batch: 448/500 | Epoch  61, time=574.2ms/ 13.0ms | Train: loss=1.699 | Valid: loss=1.699 | *\n",
      "Batch: 448/500 | Epoch  62, time=601.6ms/ 12.9ms | Train: loss=1.690 | Valid: loss=1.690 | *\n",
      "Batch: 448/500 | Epoch  63, time=579.4ms/ 13.0ms | Train: loss=1.677 | Valid: loss=1.677 | *\n",
      "Batch: 448/500 | Epoch  64, time=550.4ms/ 13.5ms | Train: loss=1.666 | Valid: loss=1.666 | *\n",
      "Batch: 448/500 | Epoch  65, time=573.4ms/ 12.9ms | Train: loss=1.659 | Valid: loss=1.659 | *\n",
      "Batch: 448/500 | Epoch  66, time=575.3ms/ 13.3ms | Train: loss=1.650 | Valid: loss=1.650 | *\n",
      "Batch: 448/500 | Epoch  67, time=591.9ms/ 16.3ms | Train: loss=1.645 | Valid: loss=1.645 | *\n",
      "Batch: 448/500 | Epoch  68, time=550.2ms/ 15.6ms | Train: loss=1.636 | Valid: loss=1.636 | *\n",
      "Batch: 448/500 | Epoch  69, time=612.4ms/ 13.0ms | Train: loss=1.630 | Valid: loss=1.630 | *\n",
      "Batch: 448/500 | Epoch  70, time=583.6ms/ 12.9ms | Train: loss=1.618 | Valid: loss=1.618 | *\n",
      "Batch: 448/500 | Epoch  71, time=601.4ms/ 13.1ms | Train: loss=1.610 | Valid: loss=1.610 | *\n",
      "Batch: 448/500 | Epoch  72, time=573.7ms/ 13.4ms | Train: loss=1.605 | Valid: loss=1.605 | *\n",
      "Batch: 448/500 | Epoch  73, time=587.3ms/ 13.5ms | Train: loss=1.601 | Valid: loss=1.601 | *\n",
      "Batch: 448/500 | Epoch  74, time=576.3ms/ 13.7ms | Train: loss=1.597 | Valid: loss=1.597 | *\n",
      "Batch: 448/500 | Epoch  75, time=577.2ms/ 12.8ms | Train: loss=1.593 | Valid: loss=1.593 | *\n",
      "Batch: 448/500 | Epoch  76, time=620.2ms/ 13.6ms | Train: loss=1.593 | Valid: loss=1.593 | *\n",
      "Batch: 448/500 | Epoch  77, time=580.2ms/ 13.2ms | Train: loss=1.588 | Valid: loss=1.588 | *\n",
      "Batch: 448/500 | Epoch  78, time=574.5ms/ 13.0ms | Train: loss=1.579 | Valid: loss=1.579 | *\n",
      "Batch: 448/500 | Epoch  79, time=583.3ms/ 16.5ms | Train: loss=1.576 | Valid: loss=1.576 | *\n",
      "Batch: 448/500 | Epoch  80, time=572.9ms/ 13.4ms | Train: loss=1.568 | Valid: loss=1.568 | *\n",
      "Batch: 448/500 | Epoch  81, time=578.5ms/ 13.4ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  82, time=612.1ms/ 14.0ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  83, time=591.2ms/ 13.2ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  84, time=527.0ms/ 12.8ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  85, time=545.2ms/ 13.3ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  86, time=591.6ms/ 13.5ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  87, time=547.8ms/ 13.4ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  88, time=583.9ms/ 13.1ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  89, time=523.5ms/ 13.1ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  90, time=532.2ms/ 13.3ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  91, time=580.0ms/ 16.3ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  92, time=538.3ms/ 13.1ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  93, time=545.9ms/ 16.7ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  94, time=589.3ms/ 16.3ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  95, time=588.8ms/ 13.4ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  96, time=558.5ms/ 13.1ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  97, time=546.4ms/ 13.2ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  98, time=576.8ms/ 13.4ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch  99, time=593.7ms/ 13.7ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "Batch: 448/500 | Epoch 100, time=549.2ms/ 16.6ms | Train: loss=1.568 | Valid: loss=1.568 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.785\n",
      "Test on task  1 - Mopping the floor: loss=2.304\n",
      "Test on task  2 - Carry warm food: loss=1.711\n",
      "Test on task  3 - Carry cold food: loss=2.215\n",
      "Test on task  4 - Carry drinks   : loss=1.394\n",
      "Test on task  5 - Carry small objects (plates, toys): loss=2.093\n",
      "Test on task  6 - Carry big objects (tables, chairs): loss=1.533\n",
      "Test on task  7 - Cleaning (Picking up stuff): loss=1.624\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task  8 (Vacuum cleaning)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  8\n",
      "Batch: 448/500 | Epoch   1, time=598.5ms/ 13.3ms | Train: loss=2.842 | Valid: loss=2.842 | *\n",
      "Batch: 448/500 | Epoch   2, time=567.7ms/ 13.2ms | Train: loss=2.783 | Valid: loss=2.783 | *\n",
      "Batch: 448/500 | Epoch   3, time=550.3ms/ 16.4ms | Train: loss=2.742 | Valid: loss=2.742 | *\n",
      "Batch: 448/500 | Epoch   4, time=581.7ms/ 16.3ms | Train: loss=2.688 | Valid: loss=2.688 | *\n",
      "Batch: 448/500 | Epoch   5, time=582.5ms/ 14.7ms | Train: loss=2.647 | Valid: loss=2.647 | *\n",
      "Batch: 448/500 | Epoch   6, time=528.8ms/ 13.1ms | Train: loss=2.576 | Valid: loss=2.576 | *\n",
      "Batch: 448/500 | Epoch   7, time=538.6ms/ 13.1ms | Train: loss=2.532 | Valid: loss=2.532 | *\n",
      "Batch: 448/500 | Epoch   8, time=535.7ms/ 13.4ms | Train: loss=2.497 | Valid: loss=2.497 | *\n",
      "Batch: 448/500 | Epoch   9, time=573.3ms/ 13.4ms | Train: loss=2.472 | Valid: loss=2.472 | *\n",
      "Batch: 448/500 | Epoch  10, time=608.8ms/ 13.2ms | Train: loss=2.434 | Valid: loss=2.434 | *\n",
      "Batch: 448/500 | Epoch  11, time=584.1ms/ 13.0ms | Train: loss=2.415 | Valid: loss=2.415 | *\n",
      "Batch: 448/500 | Epoch  12, time=584.5ms/ 13.0ms | Train: loss=2.399 | Valid: loss=2.399 | *\n",
      "Batch: 448/500 | Epoch  13, time=562.4ms/ 13.1ms | Train: loss=2.371 | Valid: loss=2.371 | *\n",
      "Batch: 448/500 | Epoch  14, time=571.2ms/ 13.1ms | Train: loss=2.347 | Valid: loss=2.347 | *\n",
      "Batch: 448/500 | Epoch  15, time=531.1ms/ 13.5ms | Train: loss=2.326 | Valid: loss=2.326 | *\n",
      "Batch: 448/500 | Epoch  16, time=566.3ms/ 13.1ms | Train: loss=2.316 | Valid: loss=2.316 | *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  17, time=586.5ms/ 16.6ms | Train: loss=2.282 | Valid: loss=2.282 | *\n",
      "Batch: 448/500 | Epoch  18, time=582.5ms/ 13.2ms | Train: loss=2.263 | Valid: loss=2.263 | *\n",
      "Batch: 448/500 | Epoch  19, time=570.6ms/ 14.5ms | Train: loss=2.237 | Valid: loss=2.237 | *\n",
      "Batch: 448/500 | Epoch  20, time=564.4ms/ 13.4ms | Train: loss=2.227 | Valid: loss=2.227 | *\n",
      "Batch: 448/500 | Epoch  21, time=572.2ms/ 13.4ms | Train: loss=2.205 | Valid: loss=2.205 | *\n",
      "Batch: 448/500 | Epoch  22, time=550.7ms/ 12.9ms | Train: loss=2.188 | Valid: loss=2.188 | *\n",
      "Batch: 448/500 | Epoch  23, time=545.7ms/ 13.2ms | Train: loss=2.160 | Valid: loss=2.160 | *\n",
      "Batch: 448/500 | Epoch  24, time=595.7ms/ 12.9ms | Train: loss=2.145 | Valid: loss=2.145 | *\n",
      "Batch: 448/500 | Epoch  25, time=583.3ms/ 13.0ms | Train: loss=2.139 | Valid: loss=2.139 | *\n",
      "Batch: 448/500 | Epoch  26, time=567.5ms/ 13.0ms | Train: loss=2.119 | Valid: loss=2.119 | *\n",
      "Batch: 448/500 | Epoch  27, time=531.9ms/ 13.9ms | Train: loss=2.093 | Valid: loss=2.093 | *\n",
      "Batch: 448/500 | Epoch  28, time=577.2ms/ 12.9ms | Train: loss=2.082 | Valid: loss=2.082 | *\n",
      "Batch: 448/500 | Epoch  29, time=574.6ms/ 13.2ms | Train: loss=2.066 | Valid: loss=2.066 | *\n",
      "Batch: 448/500 | Epoch  30, time=579.1ms/ 12.9ms | Train: loss=2.045 | Valid: loss=2.045 | *\n",
      "Batch: 448/500 | Epoch  31, time=605.9ms/ 12.9ms | Train: loss=2.036 | Valid: loss=2.036 | *\n",
      "Batch: 448/500 | Epoch  32, time=565.8ms/ 12.9ms | Train: loss=2.016 | Valid: loss=2.016 | *\n",
      "Batch: 448/500 | Epoch  33, time=556.6ms/ 13.7ms | Train: loss=1.998 | Valid: loss=1.998 | *\n",
      "Batch: 448/500 | Epoch  34, time=573.0ms/ 13.4ms | Train: loss=1.987 | Valid: loss=1.987 | *\n",
      "Batch: 448/500 | Epoch  35, time=564.9ms/ 13.3ms | Train: loss=1.979 | Valid: loss=1.979 | *\n",
      "Batch: 448/500 | Epoch  36, time=558.3ms/ 13.2ms | Train: loss=1.968 | Valid: loss=1.968 | *\n",
      "Batch: 448/500 | Epoch  37, time=521.5ms/ 14.0ms | Train: loss=1.959 | Valid: loss=1.959 | *\n",
      "Batch: 448/500 | Epoch  38, time=610.3ms/ 13.0ms | Train: loss=1.953 | Valid: loss=1.953 | *\n",
      "Batch: 448/500 | Epoch  39, time=544.5ms/ 12.9ms | Train: loss=1.948 | Valid: loss=1.948 | *\n",
      "Batch: 448/500 | Epoch  40, time=572.8ms/ 12.9ms | Train: loss=1.936 | Valid: loss=1.936 | *\n",
      "Batch: 448/500 | Epoch  41, time=574.1ms/ 12.9ms | Train: loss=1.925 | Valid: loss=1.925 | *\n",
      "Batch: 448/500 | Epoch  42, time=552.7ms/ 13.1ms | Train: loss=1.917 | Valid: loss=1.917 | *\n",
      "Batch: 448/500 | Epoch  43, time=543.0ms/ 13.6ms | Train: loss=1.908 | Valid: loss=1.908 | *\n",
      "Batch: 448/500 | Epoch  44, time=557.7ms/ 13.4ms | Train: loss=1.907 | Valid: loss=1.907 | *\n",
      "Batch: 448/500 | Epoch  45, time=574.6ms/ 13.4ms | Train: loss=1.903 | Valid: loss=1.903 | *\n",
      "Batch: 448/500 | Epoch  46, time=582.6ms/ 13.0ms | Train: loss=1.891 | Valid: loss=1.891 | *\n",
      "Batch: 448/500 | Epoch  47, time=581.3ms/ 13.6ms | Train: loss=1.882 | Valid: loss=1.882 | *\n",
      "Batch: 448/500 | Epoch  48, time=589.3ms/ 13.0ms | Train: loss=1.880 | Valid: loss=1.880 | *\n",
      "Batch: 448/500 | Epoch  49, time=530.1ms/ 12.9ms | Train: loss=1.874 | Valid: loss=1.874 | *\n",
      "Batch: 448/500 | Epoch  50, time=582.8ms/ 13.3ms | Train: loss=1.863 | Valid: loss=1.863 | *\n",
      "Batch: 448/500 | Epoch  51, time=584.6ms/ 13.4ms | Train: loss=1.859 | Valid: loss=1.859 | *\n",
      "Batch: 448/500 | Epoch  52, time=591.8ms/ 13.0ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  53, time=574.0ms/ 13.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  54, time=574.9ms/ 16.9ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  55, time=585.4ms/ 13.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  56, time=574.2ms/ 13.4ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  57, time=554.9ms/ 13.2ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  58, time=549.7ms/ 13.6ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  59, time=567.7ms/ 12.9ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  60, time=588.8ms/ 13.8ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  61, time=574.6ms/ 12.9ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  62, time=575.1ms/ 13.2ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  63, time=621.0ms/ 16.4ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  64, time=598.7ms/ 13.3ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  65, time=561.5ms/ 13.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  66, time=554.6ms/ 13.3ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  67, time=540.8ms/ 15.7ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  68, time=544.4ms/ 13.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  69, time=572.8ms/ 13.3ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  70, time=523.7ms/ 13.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  71, time=543.5ms/ 13.0ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  72, time=540.5ms/ 13.3ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  73, time=575.9ms/ 15.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  74, time=555.9ms/ 13.5ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  75, time=544.8ms/ 13.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  76, time=542.6ms/ 13.2ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  77, time=529.9ms/ 12.9ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  78, time=537.5ms/ 13.0ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  79, time=599.7ms/ 13.2ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  80, time=577.5ms/ 13.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  81, time=567.2ms/ 13.0ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  82, time=550.4ms/ 16.0ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  83, time=523.5ms/ 12.9ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  84, time=539.0ms/ 16.4ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  85, time=564.4ms/ 13.4ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  86, time=567.5ms/ 13.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  87, time=570.4ms/ 12.8ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  88, time=568.7ms/ 12.8ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  89, time=585.8ms/ 12.9ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  90, time=576.1ms/ 12.8ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  91, time=556.5ms/ 13.0ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  92, time=546.3ms/ 13.9ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  93, time=548.7ms/ 13.3ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  94, time=540.1ms/ 13.1ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  95, time=548.2ms/ 13.0ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  96, time=527.4ms/ 13.4ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  97, time=526.1ms/ 13.0ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  98, time=545.4ms/ 15.8ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch  99, time=534.5ms/ 16.7ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "Batch: 448/500 | Epoch 100, time=593.8ms/ 12.9ms | Train: loss=1.859 | Valid: loss=1.859 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.789\n",
      "Test on task  1 - Mopping the floor: loss=2.372\n",
      "Test on task  2 - Carry warm food: loss=1.731\n",
      "Test on task  3 - Carry cold food: loss=2.267\n",
      "Test on task  4 - Carry drinks   : loss=1.392\n",
      "Test on task  5 - Carry small objects (plates, toys): loss=2.197\n",
      "Test on task  6 - Carry big objects (tables, chairs): loss=1.546\n",
      "Test on task  7 - Cleaning (Picking up stuff): loss=1.625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test on task  8 - Vacuum cleaning: loss=1.932\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task  9 (Mopping the floor)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  9\n",
      "Batch: 448/500 | Epoch   1, time=537.6ms/ 13.1ms | Train: loss=4.434 | Valid: loss=4.434 | *\n",
      "Batch: 448/500 | Epoch   2, time=592.9ms/ 16.8ms | Train: loss=4.164 | Valid: loss=4.164 | *\n",
      "Batch: 448/500 | Epoch   3, time=567.9ms/ 12.9ms | Train: loss=3.996 | Valid: loss=3.996 | *\n",
      "Batch: 448/500 | Epoch   4, time=556.3ms/ 12.9ms | Train: loss=3.873 | Valid: loss=3.873 | *\n",
      "Batch: 448/500 | Epoch   5, time=569.9ms/ 13.0ms | Train: loss=3.782 | Valid: loss=3.782 | *\n",
      "Batch: 448/500 | Epoch   6, time=543.5ms/ 13.3ms | Train: loss=3.697 | Valid: loss=3.697 | *\n",
      "Batch: 448/500 | Epoch   7, time=539.8ms/ 12.9ms | Train: loss=3.624 | Valid: loss=3.624 | *\n",
      "Batch: 448/500 | Epoch   8, time=542.7ms/ 13.2ms | Train: loss=3.565 | Valid: loss=3.565 | *\n",
      "Batch: 448/500 | Epoch   9, time=594.8ms/ 13.2ms | Train: loss=3.511 | Valid: loss=3.511 | *\n",
      "Batch: 448/500 | Epoch  10, time=544.1ms/ 13.0ms | Train: loss=3.456 | Valid: loss=3.456 | *\n",
      "Batch: 448/500 | Epoch  11, time=583.0ms/ 13.7ms | Train: loss=3.404 | Valid: loss=3.404 | *\n",
      "Batch: 448/500 | Epoch  12, time=583.6ms/ 13.2ms | Train: loss=3.353 | Valid: loss=3.353 | *\n",
      "Batch: 448/500 | Epoch  13, time=558.2ms/ 13.2ms | Train: loss=3.307 | Valid: loss=3.307 | *\n",
      "Batch: 448/500 | Epoch  14, time=537.3ms/ 13.9ms | Train: loss=3.261 | Valid: loss=3.261 | *\n",
      "Batch: 448/500 | Epoch  15, time=577.1ms/ 13.0ms | Train: loss=3.208 | Valid: loss=3.208 | *\n",
      "Batch: 448/500 | Epoch  16, time=578.2ms/ 13.2ms | Train: loss=3.162 | Valid: loss=3.162 | *\n",
      "Batch: 448/500 | Epoch  17, time=572.1ms/ 17.0ms | Train: loss=3.125 | Valid: loss=3.125 | *\n",
      "Batch: 448/500 | Epoch  18, time=608.0ms/ 13.2ms | Train: loss=3.089 | Valid: loss=3.089 | *\n",
      "Batch: 448/500 | Epoch  19, time=581.3ms/ 13.2ms | Train: loss=3.045 | Valid: loss=3.045 | *\n",
      "Batch: 448/500 | Epoch  20, time=533.5ms/ 13.9ms | Train: loss=3.010 | Valid: loss=3.010 | *\n",
      "Batch: 448/500 | Epoch  21, time=562.0ms/ 13.0ms | Train: loss=2.957 | Valid: loss=2.957 | *\n",
      "Batch: 448/500 | Epoch  22, time=611.4ms/ 13.3ms | Train: loss=2.911 | Valid: loss=2.911 | *\n",
      "Batch: 448/500 | Epoch  23, time=549.9ms/ 13.4ms | Train: loss=2.862 | Valid: loss=2.862 | *\n",
      "Batch: 448/500 | Epoch  24, time=589.7ms/ 13.2ms | Train: loss=2.820 | Valid: loss=2.820 | *\n",
      "Batch: 448/500 | Epoch  25, time=559.5ms/ 13.3ms | Train: loss=2.781 | Valid: loss=2.781 | *\n",
      "Batch: 448/500 | Epoch  26, time=573.7ms/ 13.2ms | Train: loss=2.734 | Valid: loss=2.734 | *\n",
      "Batch: 448/500 | Epoch  27, time=554.1ms/ 16.4ms | Train: loss=2.699 | Valid: loss=2.699 | *\n",
      "Batch: 448/500 | Epoch  28, time=600.1ms/ 13.3ms | Train: loss=2.662 | Valid: loss=2.662 | *\n",
      "Batch: 448/500 | Epoch  29, time=587.1ms/ 13.0ms | Train: loss=2.631 | Valid: loss=2.631 | *\n",
      "Batch: 448/500 | Epoch  30, time=571.6ms/ 13.4ms | Train: loss=2.597 | Valid: loss=2.597 | *\n",
      "Batch: 448/500 | Epoch  31, time=580.5ms/ 13.0ms | Train: loss=2.564 | Valid: loss=2.564 | *\n",
      "Batch: 448/500 | Epoch  32, time=572.3ms/ 13.6ms | Train: loss=2.535 | Valid: loss=2.535 | *\n",
      "Batch: 448/500 | Epoch  33, time=571.6ms/ 12.9ms | Train: loss=2.509 | Valid: loss=2.509 | *\n",
      "Batch: 448/500 | Epoch  34, time=544.3ms/ 13.1ms | Train: loss=2.478 | Valid: loss=2.478 | *\n",
      "Batch: 448/500 | Epoch  35, time=528.5ms/ 13.2ms | Train: loss=2.457 | Valid: loss=2.457 | *\n",
      "Batch: 448/500 | Epoch  36, time=528.7ms/ 13.7ms | Train: loss=2.432 | Valid: loss=2.432 | *\n",
      "Batch: 448/500 | Epoch  37, time=582.0ms/ 13.1ms | Train: loss=2.387 | Valid: loss=2.387 | *\n",
      "Batch: 448/500 | Epoch  38, time=594.3ms/ 12.9ms | Train: loss=2.361 | Valid: loss=2.361 | *\n",
      "Batch: 448/500 | Epoch  39, time=626.9ms/ 15.3ms | Train: loss=2.338 | Valid: loss=2.338 | *\n",
      "Batch: 448/500 | Epoch  40, time=579.6ms/ 13.2ms | Train: loss=2.305 | Valid: loss=2.305 | *\n",
      "Batch: 448/500 | Epoch  41, time=588.1ms/ 16.5ms | Train: loss=2.283 | Valid: loss=2.283 | *\n",
      "Batch: 448/500 | Epoch  42, time=625.0ms/ 16.3ms | Train: loss=2.263 | Valid: loss=2.263 | *\n",
      "Batch: 448/500 | Epoch  43, time=582.8ms/ 13.3ms | Train: loss=2.225 | Valid: loss=2.225 | *\n",
      "Batch: 448/500 | Epoch  44, time=549.4ms/ 12.9ms | Train: loss=2.194 | Valid: loss=2.194 | *\n",
      "Batch: 448/500 | Epoch  45, time=608.0ms/ 13.5ms | Train: loss=2.168 | Valid: loss=2.168 | *\n",
      "Batch: 448/500 | Epoch  46, time=576.1ms/ 13.1ms | Train: loss=2.142 | Valid: loss=2.142 | *\n",
      "Batch: 448/500 | Epoch  47, time=563.5ms/ 12.9ms | Train: loss=2.122 | Valid: loss=2.122 | *\n",
      "Batch: 448/500 | Epoch  48, time=576.7ms/ 14.1ms | Train: loss=2.104 | Valid: loss=2.104 | *\n",
      "Batch: 448/500 | Epoch  49, time=574.0ms/ 13.1ms | Train: loss=2.088 | Valid: loss=2.088 | *\n",
      "Batch: 448/500 | Epoch  50, time=558.6ms/ 13.1ms | Train: loss=2.071 | Valid: loss=2.071 | *\n",
      "Batch: 448/500 | Epoch  51, time=618.7ms/ 13.0ms | Train: loss=2.049 | Valid: loss=2.049 | *\n",
      "Batch: 448/500 | Epoch  52, time=574.6ms/ 12.9ms | Train: loss=2.035 | Valid: loss=2.035 | *\n",
      "Batch: 448/500 | Epoch  53, time=601.4ms/ 13.9ms | Train: loss=2.019 | Valid: loss=2.019 | *\n",
      "Batch: 448/500 | Epoch  54, time=561.1ms/ 13.2ms | Train: loss=2.000 | Valid: loss=2.000 | *\n",
      "Batch: 448/500 | Epoch  55, time=544.1ms/ 13.1ms | Train: loss=1.985 | Valid: loss=1.985 | *\n",
      "Batch: 448/500 | Epoch  56, time=538.6ms/ 12.9ms | Train: loss=1.966 | Valid: loss=1.966 | *\n",
      "Batch: 448/500 | Epoch  57, time=551.0ms/ 16.0ms | Train: loss=1.953 | Valid: loss=1.953 | *\n",
      "Batch: 448/500 | Epoch  58, time=604.9ms/ 12.8ms | Train: loss=1.939 | Valid: loss=1.939 | *\n",
      "Batch: 448/500 | Epoch  59, time=591.9ms/ 13.0ms | Train: loss=1.930 | Valid: loss=1.930 | *\n",
      "Batch: 448/500 | Epoch  60, time=565.7ms/ 13.3ms | Train: loss=1.916 | Valid: loss=1.916 | *\n",
      "Batch: 448/500 | Epoch  61, time=529.6ms/ 14.0ms | Train: loss=1.906 | Valid: loss=1.906 | *\n",
      "Batch: 448/500 | Epoch  62, time=525.1ms/ 13.6ms | Train: loss=1.895 | Valid: loss=1.895 | *\n",
      "Batch: 448/500 | Epoch  63, time=555.9ms/ 16.4ms | Train: loss=1.886 | Valid: loss=1.886 | *\n",
      "Batch: 448/500 | Epoch  64, time=569.1ms/ 13.1ms | Train: loss=1.877 | Valid: loss=1.877 | *\n",
      "Batch: 448/500 | Epoch  65, time=569.4ms/ 13.1ms | Train: loss=1.865 | Valid: loss=1.865 | *\n",
      "Batch: 448/500 | Epoch  66, time=546.8ms/ 13.1ms | Train: loss=1.856 | Valid: loss=1.856 | *\n",
      "Batch: 448/500 | Epoch  67, time=575.8ms/ 16.5ms | Train: loss=1.848 | Valid: loss=1.848 | *\n",
      "Batch: 448/500 | Epoch  68, time=537.7ms/ 13.8ms | Train: loss=1.840 | Valid: loss=1.840 | *\n",
      "Batch: 448/500 | Epoch  69, time=595.6ms/ 13.2ms | Train: loss=1.831 | Valid: loss=1.831 | *\n",
      "Batch: 448/500 | Epoch  70, time=576.3ms/ 13.0ms | Train: loss=1.825 | Valid: loss=1.825 | *\n",
      "Batch: 448/500 | Epoch  71, time=578.3ms/ 12.8ms | Train: loss=1.816 | Valid: loss=1.816 | *\n",
      "Batch: 448/500 | Epoch  72, time=555.1ms/ 13.8ms | Train: loss=1.809 | Valid: loss=1.809 | *\n",
      "Batch: 448/500 | Epoch  73, time=583.2ms/ 13.1ms | Train: loss=1.803 | Valid: loss=1.803 | *\n",
      "Batch: 448/500 | Epoch  74, time=574.2ms/ 12.9ms | Train: loss=1.797 | Valid: loss=1.797 | *\n",
      "Batch: 448/500 | Epoch  75, time=586.8ms/ 13.1ms | Train: loss=1.788 | Valid: loss=1.788 | *\n",
      "Batch: 448/500 | Epoch  76, time=574.1ms/ 14.2ms | Train: loss=1.783 | Valid: loss=1.783 | *\n",
      "Batch: 448/500 | Epoch  77, time=588.0ms/ 13.0ms | Train: loss=1.778 | Valid: loss=1.778 | *\n",
      "Batch: 448/500 | Epoch  78, time=539.7ms/ 13.0ms | Train: loss=1.770 | Valid: loss=1.770 | *\n",
      "Batch: 448/500 | Epoch  79, time=549.6ms/ 14.1ms | Train: loss=1.767 | Valid: loss=1.767 | *\n",
      "Batch: 448/500 | Epoch  80, time=568.1ms/ 13.3ms | Train: loss=1.762 | Valid: loss=1.762 | *\n",
      "Batch: 448/500 | Epoch  81, time=568.4ms/ 13.5ms | Train: loss=1.757 | Valid: loss=1.757 | *\n",
      "Batch: 448/500 | Epoch  82, time=520.9ms/ 13.4ms | Train: loss=1.753 | Valid: loss=1.753 | *\n",
      "Batch: 448/500 | Epoch  83, time=568.4ms/ 13.0ms | Train: loss=1.745 | Valid: loss=1.745 | *\n",
      "Batch: 448/500 | Epoch  84, time=531.3ms/ 12.8ms | Train: loss=1.742 | Valid: loss=1.742 | *\n",
      "Batch: 448/500 | Epoch  85, time=563.4ms/ 13.1ms | Train: loss=1.738 | Valid: loss=1.738 | *\n",
      "Batch: 448/500 | Epoch  86, time=574.1ms/ 13.2ms | Train: loss=1.735 | Valid: loss=1.735 | *\n",
      "Batch: 448/500 | Epoch  87, time=557.1ms/ 13.4ms | Train: loss=1.731 | Valid: loss=1.731 | *\n",
      "Batch: 448/500 | Epoch  88, time=595.9ms/ 17.3ms | Train: loss=1.725 | Valid: loss=1.725 | *\n",
      "Batch: 448/500 | Epoch  89, time=575.8ms/ 13.1ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  90, time=588.9ms/ 13.7ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  91, time=611.7ms/ 15.4ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  92, time=551.6ms/ 13.1ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  93, time=563.7ms/ 16.8ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  94, time=586.8ms/ 16.4ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  95, time=555.4ms/ 16.5ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  96, time=566.3ms/ 14.4ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  97, time=596.8ms/ 16.3ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  98, time=555.7ms/ 12.9ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch  99, time=550.5ms/ 13.0ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "Batch: 448/500 | Epoch 100, time=537.5ms/ 12.9ms | Train: loss=1.726 | Valid: loss=1.726 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.847\n",
      "Test on task  1 - Mopping the floor: loss=2.195\n",
      "Test on task  2 - Carry warm food: loss=1.996\n",
      "Test on task  3 - Carry cold food: loss=2.462\n",
      "Test on task  4 - Carry drinks   : loss=1.473\n",
      "Test on task  5 - Carry small objects (plates, toys): loss=2.113\n",
      "Test on task  6 - Carry big objects (tables, chairs): loss=1.497\n",
      "Test on task  7 - Cleaning (Picking up stuff): loss=1.625\n",
      "Test on task  8 - Vacuum cleaning: loss=2.177\n",
      "Test on task  9 - Mopping the floor: loss=1.657\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task 10 (Carry warm food)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  10\n",
      "Batch: 448/500 | Epoch   1, time=597.6ms/ 12.9ms | Train: loss=4.565 | Valid: loss=4.565 | *\n",
      "Batch: 448/500 | Epoch   2, time=555.1ms/ 13.5ms | Train: loss=3.922 | Valid: loss=3.922 | *\n",
      "Batch: 448/500 | Epoch   3, time=545.5ms/ 12.9ms | Train: loss=3.495 | Valid: loss=3.495 | *\n",
      "Batch: 448/500 | Epoch   4, time=563.0ms/ 13.1ms | Train: loss=3.246 | Valid: loss=3.246 | *\n",
      "Batch: 448/500 | Epoch   5, time=578.6ms/ 13.0ms | Train: loss=3.072 | Valid: loss=3.072 | *\n",
      "Batch: 448/500 | Epoch   6, time=584.2ms/ 13.5ms | Train: loss=2.918 | Valid: loss=2.918 | *\n",
      "Batch: 448/500 | Epoch   7, time=577.2ms/ 13.8ms | Train: loss=2.819 | Valid: loss=2.819 | *\n",
      "Batch: 448/500 | Epoch   8, time=580.6ms/ 13.6ms | Train: loss=2.727 | Valid: loss=2.727 | *\n",
      "Batch: 448/500 | Epoch   9, time=582.5ms/ 13.0ms | Train: loss=2.647 | Valid: loss=2.647 | *\n",
      "Batch: 448/500 | Epoch  10, time=569.1ms/ 12.9ms | Train: loss=2.595 | Valid: loss=2.595 | *\n",
      "Batch: 448/500 | Epoch  11, time=552.3ms/ 13.2ms | Train: loss=2.539 | Valid: loss=2.539 | *\n",
      "Batch: 448/500 | Epoch  12, time=543.7ms/ 13.3ms | Train: loss=2.499 | Valid: loss=2.499 | *\n",
      "Batch: 448/500 | Epoch  13, time=544.1ms/ 13.2ms | Train: loss=2.467 | Valid: loss=2.467 | *\n",
      "Batch: 448/500 | Epoch  14, time=521.7ms/ 13.1ms | Train: loss=2.433 | Valid: loss=2.433 | *\n",
      "Batch: 448/500 | Epoch  15, time=588.6ms/ 13.1ms | Train: loss=2.404 | Valid: loss=2.404 | *\n",
      "Batch: 448/500 | Epoch  16, time=555.5ms/ 13.0ms | Train: loss=2.375 | Valid: loss=2.375 | *\n",
      "Batch: 448/500 | Epoch  17, time=531.2ms/ 13.3ms | Train: loss=2.347 | Valid: loss=2.347 | *\n",
      "Batch: 448/500 | Epoch  18, time=559.0ms/ 13.2ms | Train: loss=2.321 | Valid: loss=2.321 | *\n",
      "Batch: 448/500 | Epoch  19, time=560.5ms/ 16.7ms | Train: loss=2.297 | Valid: loss=2.297 | *\n",
      "Batch: 448/500 | Epoch  20, time=549.6ms/ 13.6ms | Train: loss=2.271 | Valid: loss=2.271 | *\n",
      "Batch: 448/500 | Epoch  21, time=535.0ms/ 12.9ms | Train: loss=2.247 | Valid: loss=2.247 | *\n",
      "Batch: 448/500 | Epoch  22, time=581.6ms/ 16.9ms | Train: loss=2.225 | Valid: loss=2.225 | *\n",
      "Batch: 448/500 | Epoch  23, time=570.4ms/ 13.5ms | Train: loss=2.207 | Valid: loss=2.207 | *\n",
      "Batch: 448/500 | Epoch  24, time=584.5ms/ 13.8ms | Train: loss=2.179 | Valid: loss=2.179 | *\n",
      "Batch: 448/500 | Epoch  25, time=547.0ms/ 13.3ms | Train: loss=2.155 | Valid: loss=2.155 | *\n",
      "Batch: 448/500 | Epoch  26, time=536.0ms/ 14.0ms | Train: loss=2.135 | Valid: loss=2.135 | *\n",
      "Batch: 448/500 | Epoch  27, time=525.6ms/ 14.0ms | Train: loss=2.113 | Valid: loss=2.113 | *\n",
      "Batch: 448/500 | Epoch  28, time=522.2ms/ 13.0ms | Train: loss=2.093 | Valid: loss=2.093 | *\n",
      "Batch: 448/500 | Epoch  29, time=544.7ms/ 13.1ms | Train: loss=2.071 | Valid: loss=2.071 | *\n",
      "Batch: 448/500 | Epoch  30, time=558.8ms/ 17.3ms | Train: loss=2.048 | Valid: loss=2.048 | *\n",
      "Batch: 448/500 | Epoch  31, time=568.5ms/ 13.4ms | Train: loss=2.035 | Valid: loss=2.035 | *\n",
      "Batch: 448/500 | Epoch  32, time=574.4ms/ 15.8ms | Train: loss=2.017 | Valid: loss=2.017 | *\n",
      "Batch: 448/500 | Epoch  33, time=550.2ms/ 13.3ms | Train: loss=1.999 | Valid: loss=1.999 | *\n",
      "Batch: 448/500 | Epoch  34, time=577.7ms/ 12.9ms | Train: loss=1.979 | Valid: loss=1.979 | *\n",
      "Batch: 448/500 | Epoch  35, time=566.3ms/ 13.1ms | Train: loss=1.958 | Valid: loss=1.958 | *\n",
      "Batch: 448/500 | Epoch  36, time=570.0ms/ 13.0ms | Train: loss=1.944 | Valid: loss=1.944 | *\n",
      "Batch: 448/500 | Epoch  37, time=583.3ms/ 13.9ms | Train: loss=1.927 | Valid: loss=1.927 | *\n",
      "Batch: 448/500 | Epoch  38, time=555.1ms/ 12.9ms | Train: loss=1.914 | Valid: loss=1.914 | *\n",
      "Batch: 0/500 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  42, time=561.3ms/ 13.1ms | Train: loss=2.119 | Valid: loss=2.119 | *\n",
      "Batch: 448/500 | Epoch  43, time=570.7ms/ 13.2ms | Train: loss=2.089 | Valid: loss=2.089 | *\n",
      "Batch: 448/500 | Epoch  44, time=568.6ms/ 16.4ms | Train: loss=2.064 | Valid: loss=2.064 | *\n",
      "Batch: 448/500 | Epoch  45, time=568.7ms/ 13.0ms | Train: loss=2.038 | Valid: loss=2.038 | *\n",
      "Batch: 448/500 | Epoch  46, time=580.9ms/ 13.0ms | Train: loss=2.014 | Valid: loss=2.014 | *\n",
      "Batch: 448/500 | Epoch  47, time=577.5ms/ 13.2ms | Train: loss=1.990 | Valid: loss=1.990 | *\n",
      "Batch: 448/500 | Epoch  48, time=577.3ms/ 13.4ms | Train: loss=1.968 | Valid: loss=1.968 | *\n",
      "Batch: 448/500 | Epoch  49, time=573.1ms/ 13.1ms | Train: loss=1.941 | Valid: loss=1.941 | *\n",
      "Batch: 448/500 | Epoch  50, time=591.6ms/ 12.9ms | Train: loss=1.920 | Valid: loss=1.920 | *\n",
      "Batch: 448/500 | Epoch  51, time=575.6ms/ 12.9ms | Train: loss=1.899 | Valid: loss=1.899 | *\n",
      "Batch: 448/500 | Epoch  52, time=572.3ms/ 13.1ms | Train: loss=1.879 | Valid: loss=1.879 | *\n",
      "Batch: 448/500 | Epoch  69, time=561.9ms/ 13.3ms | Train: loss=1.632 | Valid: loss=1.632 | *\n",
      "Batch: 448/500 | Epoch  70, time=528.8ms/ 15.2ms | Train: loss=1.624 | Valid: loss=1.624 | *\n",
      "Batch: 448/500 | Epoch  71, time=573.9ms/ 13.0ms | Train: loss=1.615 | Valid: loss=1.615 | *\n",
      "Batch: 448/500 | Epoch  72, time=585.3ms/ 13.4ms | Train: loss=1.609 | Valid: loss=1.609 | *\n",
      "Batch: 448/500 | Epoch  73, time=531.4ms/ 12.9ms | Train: loss=1.603 | Valid: loss=1.603 | *\n",
      "Batch: 448/500 | Epoch  74, time=578.2ms/ 13.1ms | Train: loss=1.597 | Valid: loss=1.597 | *\n",
      "Batch: 448/500 | Epoch  75, time=559.6ms/ 12.9ms | Train: loss=1.591 | Valid: loss=1.591 | *\n",
      "Batch: 448/500 | Epoch  76, time=523.4ms/ 13.3ms | Train: loss=1.585 | Valid: loss=1.585 | *\n",
      "Batch: 448/500 | Epoch  77, time=529.1ms/ 13.2ms | Train: loss=1.581 | Valid: loss=1.581 | *\n",
      "Batch: 448/500 | Epoch  78, time=559.5ms/ 13.2ms | Train: loss=1.575 | Valid: loss=1.575 | *\n",
      "Batch: 448/500 | Epoch  79, time=540.9ms/ 13.1ms | Train: loss=1.570 | Valid: loss=1.570 | *\n",
      "Batch: 448/500 | Epoch  80, time=551.3ms/ 13.3ms | Train: loss=1.567 | Valid: loss=1.567 | *\n",
      "Batch: 448/500 | Epoch  81, time=579.2ms/ 13.0ms | Train: loss=1.564 | Valid: loss=1.564 | *\n",
      "Batch: 448/500 | Epoch  82, time=565.3ms/ 13.1ms | Train: loss=1.561 | Valid: loss=1.561 | *\n",
      "Batch: 448/500 | Epoch  83, time=566.3ms/ 14.2ms | Train: loss=1.557 | Valid: loss=1.557 | *\n",
      "Batch: 448/500 | Epoch  84, time=547.2ms/ 13.0ms | Train: loss=1.554 | Valid: loss=1.554 | *\n",
      "Batch: 448/500 | Epoch  85, time=521.5ms/ 13.1ms | Train: loss=1.551 | Valid: loss=1.551 | *\n",
      "Batch: 448/500 | Epoch  86, time=534.8ms/ 12.9ms | Train: loss=1.548 | Valid: loss=1.548 | *\n",
      "Batch: 448/500 | Epoch  87, time=579.8ms/ 13.4ms | Train: loss=1.545 | Valid: loss=1.545 | *\n",
      "Batch: 448/500 | Epoch  88, time=582.2ms/ 13.3ms | Train: loss=1.543 | Valid: loss=1.543 | *\n",
      "Batch: 448/500 | Epoch  89, time=575.3ms/ 13.3ms | Train: loss=1.541 | Valid: loss=1.541 | *\n",
      "Batch: 448/500 | Epoch  90, time=582.8ms/ 13.5ms | Train: loss=1.539 | Valid: loss=1.539 | *\n",
      "Batch: 448/500 | Epoch  91, time=533.5ms/ 13.0ms | Train: loss=1.537 | Valid: loss=1.537 | *\n",
      "Batch: 448/500 | Epoch  92, time=551.0ms/ 12.9ms | Train: loss=1.536 | Valid: loss=1.536 | *\n",
      "Batch: 448/500 | Epoch  93, time=542.7ms/ 16.6ms | Train: loss=1.534 | Valid: loss=1.534 | *\n",
      "Batch: 448/500 | Epoch  94, time=609.6ms/ 12.9ms | Train: loss=1.532 | Valid: loss=1.532 | *\n",
      "Batch: 448/500 | Epoch  95, time=563.4ms/ 12.9ms | Train: loss=1.531 | Valid: loss=1.531 | *\n",
      "Batch: 448/500 | Epoch  96, time=558.9ms/ 13.8ms | Train: loss=1.530 | Valid: loss=1.530 | *\n",
      "Batch: 448/500 | Epoch  97, time=587.0ms/ 13.5ms | Train: loss=1.528 | Valid: loss=1.528 | *\n",
      "Batch: 448/500 | Epoch  98, time=544.9ms/ 12.8ms | Train: loss=1.527 | Valid: loss=1.527 | *\n",
      "Batch: 448/500 | Epoch  99, time=574.0ms/ 13.1ms | Train: loss=1.526 | Valid: loss=1.526 | *\n",
      "Batch: 448/500 | Epoch 100, time=593.1ms/ 13.2ms | Train: loss=1.525 | Valid: loss=1.525 | *\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.735\n",
      "Test on task  1 - Mopping the floor: loss=2.117\n",
      "Test on task  2 - Carry warm food: loss=1.895\n",
      "Test on task  3 - Carry cold food: loss=2.477\n",
      "Test on task  4 - Carry drinks   : loss=1.832\n",
      "Test on task  5 - Carry small objects (plates, toys): loss=2.312\n",
      "Test on task  6 - Carry big objects (tables, chairs): loss=1.517\n",
      "Test on task  7 - Cleaning (Picking up stuff): loss=1.614\n",
      "Test on task  8 - Vacuum cleaning: loss=2.313\n",
      "Test on task  9 - Mopping the floor: loss=1.636\n",
      "Test on task 10 - Carry warm food: loss=1.687\n",
      "Test on task 11 - Carry cold food: loss=1.538\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task 12 (Carry drinks)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  12\n",
      "Batch: 448/500 | Epoch   1, time=532.5ms/ 13.3ms | Train: loss=4.169 | Valid: loss=4.169 | *\n",
      "Batch: 448/500 | Epoch   2, time=587.6ms/ 12.9ms | Train: loss=3.811 | Valid: loss=3.811 | *\n",
      "Batch: 448/500 | Epoch   3, time=581.1ms/ 13.3ms | Train: loss=3.588 | Valid: loss=3.588 | *\n",
      "Batch: 448/500 | Epoch   4, time=583.9ms/ 13.2ms | Train: loss=3.395 | Valid: loss=3.395 | *\n",
      "Batch: 448/500 | Epoch   5, time=597.9ms/ 13.1ms | Train: loss=3.278 | Valid: loss=3.278 | *\n",
      "Batch: 448/500 | Epoch   6, time=570.3ms/ 15.4ms | Train: loss=3.169 | Valid: loss=3.169 | *\n",
      "Batch: 448/500 | Epoch   7, time=549.8ms/ 13.0ms | Train: loss=3.103 | Valid: loss=3.103 | *\n",
      "Batch: 448/500 | Epoch   8, time=520.2ms/ 13.3ms | Train: loss=3.037 | Valid: loss=3.037 | *\n",
      "Batch: 448/500 | Epoch   9, time=553.5ms/ 12.9ms | Train: loss=2.974 | Valid: loss=2.974 | *\n",
      "Batch: 448/500 | Epoch  10, time=575.5ms/ 13.4ms | Train: loss=2.914 | Valid: loss=2.914 | *\n",
      "Batch: 448/500 | Epoch  11, time=588.7ms/ 13.0ms | Train: loss=2.867 | Valid: loss=2.867 | *\n",
      "Batch: 448/500 | Epoch  12, time=576.3ms/ 16.7ms | Train: loss=2.826 | Valid: loss=2.826 | *\n",
      "Batch: 448/500 | Epoch  13, time=563.4ms/ 14.4ms | Train: loss=2.784 | Valid: loss=2.784 | *\n",
      "Batch: 448/500 | Epoch  14, time=520.0ms/ 12.9ms | Train: loss=2.742 | Valid: loss=2.742 | *\n",
      "Batch: 448/500 | Epoch  15, time=579.9ms/ 13.1ms | Train: loss=2.702 | Valid: loss=2.702 | *\n",
      "Batch: 448/500 | Epoch  16, time=587.7ms/ 13.2ms | Train: loss=2.660 | Valid: loss=2.660 | *\n",
      "Batch: 448/500 | Epoch  17, time=571.0ms/ 13.0ms | Train: loss=2.622 | Valid: loss=2.622 | *\n",
      "Batch: 448/500 | Epoch  18, time=564.1ms/ 17.0ms | Train: loss=2.582 | Valid: loss=2.582 | *\n",
      "Batch: 448/500 | Epoch  19, time=570.5ms/ 13.2ms | Train: loss=2.549 | Valid: loss=2.549 | *\n",
      "Batch: 448/500 | Epoch  20, time=594.5ms/ 13.2ms | Train: loss=2.509 | Valid: loss=2.509 | *\n",
      "Batch: 448/500 | Epoch  21, time=576.0ms/ 12.9ms | Train: loss=2.473 | Valid: loss=2.473 | *\n",
      "Batch: 448/500 | Epoch  22, time=594.0ms/ 16.4ms | Train: loss=2.438 | Valid: loss=2.438 | *\n",
      "Batch: 448/500 | Epoch  23, time=556.8ms/ 15.2ms | Train: loss=2.402 | Valid: loss=2.402 | *\n",
      "Batch: 448/500 | Epoch  24, time=531.3ms/ 13.8ms | Train: loss=2.368 | Valid: loss=2.368 | *\n",
      "Batch: 448/500 | Epoch  25, time=521.9ms/ 13.4ms | Train: loss=2.335 | Valid: loss=2.335 | *\n",
      "Batch: 448/500 | Epoch  26, time=542.5ms/ 13.7ms | Train: loss=2.303 | Valid: loss=2.303 | *\n",
      "Batch: 448/500 | Epoch  27, time=578.1ms/ 17.2ms | Train: loss=2.271 | Valid: loss=2.271 | *\n",
      "Batch: 448/500 | Epoch  28, time=576.3ms/ 13.0ms | Train: loss=2.240 | Valid: loss=2.240 | *\n",
      "Batch: 448/500 | Epoch  29, time=565.8ms/ 12.9ms | Train: loss=2.213 | Valid: loss=2.213 | *\n",
      "Batch: 448/500 | Epoch  30, time=552.9ms/ 12.9ms | Train: loss=2.185 | Valid: loss=2.185 | *\n",
      "Batch: 448/500 | Epoch  31, time=556.6ms/ 13.4ms | Train: loss=2.156 | Valid: loss=2.156 | *\n",
      "Batch: 448/500 | Epoch  32, time=585.3ms/ 13.0ms | Train: loss=2.130 | Valid: loss=2.130 | *\n",
      "Batch: 448/500 | Epoch  33, time=591.6ms/ 13.3ms | Train: loss=2.104 | Valid: loss=2.104 | *\n",
      "Batch: 448/500 | Epoch  34, time=605.0ms/ 13.3ms | Train: loss=2.075 | Valid: loss=2.075 | *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  35, time=575.2ms/ 12.9ms | Train: loss=2.050 | Valid: loss=2.050 | *\n",
      "Batch: 448/500 | Epoch  36, time=539.7ms/ 15.6ms | Train: loss=2.023 | Valid: loss=2.023 | *\n",
      "Batch: 448/500 | Epoch  37, time=571.9ms/ 13.5ms | Train: loss=2.000 | Valid: loss=2.000 | *\n",
      "Batch: 448/500 | Epoch  38, time=533.4ms/ 13.0ms | Train: loss=1.976 | Valid: loss=1.976 | *\n",
      "Batch: 448/500 | Epoch  39, time=582.1ms/ 13.0ms | Train: loss=1.957 | Valid: loss=1.957 | *\n",
      "Batch: 448/500 | Epoch  40, time=579.8ms/ 13.4ms | Train: loss=1.934 | Valid: loss=1.934 | *\n",
      "Batch: 448/500 | Epoch  41, time=538.7ms/ 13.0ms | Train: loss=1.913 | Valid: loss=1.913 | *\n",
      "Batch: 448/500 | Epoch  42, time=517.8ms/ 13.2ms | Train: loss=1.894 | Valid: loss=1.894 | *\n",
      "Batch: 448/500 | Epoch  43, time=598.2ms/ 13.2ms | Train: loss=1.879 | Valid: loss=1.879 | *\n",
      "Batch: 448/500 | Epoch  44, time=593.2ms/ 13.2ms | Train: loss=1.854 | Valid: loss=1.854 | *\n",
      "Batch: 448/500 | Epoch  45, time=552.0ms/ 17.1ms | Train: loss=1.838 | Valid: loss=1.838 | *\n",
      "Batch: 448/500 | Epoch  46, time=559.1ms/ 13.0ms | Train: loss=1.818 | Valid: loss=1.818 | *\n",
      "Batch: 448/500 | Epoch  47, time=571.7ms/ 13.0ms | Train: loss=1.799 | Valid: loss=1.799 | *\n",
      "Batch: 448/500 | Epoch  48, time=584.5ms/ 13.7ms | Train: loss=1.788 | Valid: loss=1.788 | *\n",
      "Batch: 448/500 | Epoch  49, time=584.3ms/ 13.3ms | Train: loss=1.768 | Valid: loss=1.768 | *\n",
      "Batch: 448/500 | Epoch  50, time=553.2ms/ 13.0ms | Train: loss=1.753 | Valid: loss=1.753 | *\n",
      "Batch: 448/500 | Epoch  51, time=630.5ms/ 13.5ms | Train: loss=1.741 | Valid: loss=1.741 | *\n",
      "Batch: 448/500 | Epoch  52, time=581.3ms/ 13.0ms | Train: loss=1.725 | Valid: loss=1.725 | *\n",
      "Batch: 448/500 | Epoch  53, time=574.8ms/ 12.9ms | Train: loss=1.715 | Valid: loss=1.715 | *\n",
      "Batch: 448/500 | Epoch  54, time=588.1ms/ 13.0ms | Train: loss=1.701 | Valid: loss=1.701 | *\n",
      "Batch: 448/500 | Epoch  55, time=548.7ms/ 13.5ms | Train: loss=1.686 | Valid: loss=1.686 | *\n",
      "Batch: 448/500 | Epoch  56, time=570.9ms/ 13.6ms | Train: loss=1.672 | Valid: loss=1.672 | *\n",
      "Batch: 448/500 | Epoch  57, time=535.0ms/ 13.2ms | Train: loss=1.666 | Valid: loss=1.666 | *\n",
      "Batch: 448/500 | Epoch  58, time=524.5ms/ 13.2ms | Train: loss=1.655 | Valid: loss=1.655 | *\n",
      "Batch: 448/500 | Epoch  59, time=567.8ms/ 12.9ms | Train: loss=1.640 | Valid: loss=1.640 | *\n",
      "Batch: 448/500 | Epoch  60, time=575.9ms/ 13.2ms | Train: loss=1.632 | Valid: loss=1.632 | *\n",
      "Batch: 448/500 | Epoch  61, time=563.1ms/ 13.4ms | Train: loss=1.622 | Valid: loss=1.622 | *\n",
      "Batch: 448/500 | Epoch  62, time=546.6ms/ 13.1ms | Train: loss=1.612 | Valid: loss=1.612 | *\n",
      "Batch: 448/500 | Epoch  63, time=576.2ms/ 12.9ms | Train: loss=1.603 | Valid: loss=1.603 | *\n",
      "Batch: 448/500 | Epoch  64, time=571.6ms/ 14.1ms | Train: loss=1.595 | Valid: loss=1.595 | *\n",
      "Batch: 448/500 | Epoch  65, time=578.8ms/ 13.2ms | Train: loss=1.588 | Valid: loss=1.588 | *\n",
      "Batch: 448/500 | Epoch  66, time=601.2ms/ 13.4ms | Train: loss=1.582 | Valid: loss=1.582 | *\n",
      "Batch: 448/500 | Epoch  67, time=555.4ms/ 13.2ms | Train: loss=1.576 | Valid: loss=1.576 | *\n",
      "Batch: 448/500 | Epoch  68, time=565.4ms/ 13.0ms | Train: loss=1.571 | Valid: loss=1.571 | *\n",
      "Batch: 448/500 | Epoch  69, time=531.9ms/ 13.2ms | Train: loss=1.565 | Valid: loss=1.565 | *\n",
      "Batch: 448/500 | Epoch  70, time=527.4ms/ 15.5ms | Train: loss=1.560 | Valid: loss=1.560 | *\n",
      "Batch: 448/500 | Epoch  71, time=530.8ms/ 14.0ms | Train: loss=1.556 | Valid: loss=1.556 | *\n",
      "Batch: 448/500 | Epoch  72, time=613.7ms/ 13.1ms | Train: loss=1.553 | Valid: loss=1.553 | *\n",
      "Batch: 448/500 | Epoch  73, time=539.9ms/ 13.1ms | Train: loss=1.550 | Valid: loss=1.550 | *\n",
      "Batch: 448/500 | Epoch  74, time=535.3ms/ 13.4ms | Train: loss=1.548 | Valid: loss=1.548 | *\n",
      "Batch: 448/500 | Epoch  75, time=547.5ms/ 14.9ms | Train: loss=1.546 | Valid: loss=1.546 | *\n",
      "Batch: 448/500 | Epoch  76, time=537.9ms/ 13.3ms | Train: loss=1.544 | Valid: loss=1.544 | *\n",
      "Batch: 448/500 | Epoch  77, time=572.5ms/ 13.6ms | Train: loss=1.541 | Valid: loss=1.541 | *\n",
      "Batch: 448/500 | Epoch  78, time=528.6ms/ 13.1ms | Train: loss=1.540 | Valid: loss=1.540 | *\n",
      "Batch: 448/500 | Epoch  79, time=568.4ms/ 13.0ms | Train: loss=1.538 | Valid: loss=1.538 | *\n",
      "Batch: 448/500 | Epoch  80, time=559.8ms/ 14.3ms | Train: loss=1.537 | Valid: loss=1.537 | *\n",
      "Batch: 448/500 | Epoch  81, time=530.1ms/ 13.1ms | Train: loss=1.536 | Valid: loss=1.536 | *\n",
      "Batch: 448/500 | Epoch  82, time=551.1ms/ 13.1ms | Train: loss=1.534 | Valid: loss=1.534 | *\n",
      "Batch: 448/500 | Epoch  83, time=563.8ms/ 13.0ms | Train: loss=1.533 | Valid: loss=1.533 | *\n",
      "Batch: 448/500 | Epoch  84, time=575.0ms/ 13.1ms | Train: loss=1.533 | Valid: loss=1.533 | *\n",
      "Batch: 448/500 | Epoch  85, time=532.5ms/ 15.0ms | Train: loss=1.532 | Valid: loss=1.532 | *\n",
      "Batch: 448/500 | Epoch  86, time=568.9ms/ 13.8ms | Train: loss=1.531 | Valid: loss=1.531 | *\n",
      "Batch: 448/500 | Epoch  87, time=539.8ms/ 12.9ms | Train: loss=1.531 | Valid: loss=1.531 | *\n",
      "Batch: 448/500 | Epoch  88, time=563.6ms/ 13.9ms | Train: loss=1.530 | Valid: loss=1.530 | *\n",
      "Batch: 448/500 | Epoch  89, time=555.1ms/ 13.2ms | Train: loss=1.529 | Valid: loss=1.529 | *\n",
      "Batch: 448/500 | Epoch  90, time=542.4ms/ 13.6ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch  91, time=585.4ms/ 13.0ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch  92, time=595.1ms/ 12.9ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch  93, time=590.6ms/ 13.0ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch  94, time=575.8ms/ 12.9ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch  95, time=602.7ms/ 12.9ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch  96, time=567.9ms/ 13.3ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch  97, time=550.6ms/ 13.3ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch  98, time=536.6ms/ 16.8ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch  99, time=551.8ms/ 13.4ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "Batch: 448/500 | Epoch 100, time=577.7ms/ 14.8ms | Train: loss=1.530 | Valid: loss=1.530 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.897\n",
      "Test on task  1 - Mopping the floor: loss=2.157\n",
      "Test on task  2 - Carry warm food: loss=1.874\n",
      "Test on task  3 - Carry cold food: loss=2.436\n",
      "Test on task  4 - Carry drinks   : loss=1.677\n",
      "Test on task  5 - Carry small objects (plates, toys): loss=2.151\n",
      "Test on task  6 - Carry big objects (tables, chairs): loss=1.630\n",
      "Test on task  7 - Cleaning (Picking up stuff): loss=1.644\n",
      "Test on task  8 - Vacuum cleaning: loss=2.454\n",
      "Test on task  9 - Mopping the floor: loss=1.615\n",
      "Test on task 10 - Carry warm food: loss=1.631\n",
      "Test on task 11 - Carry cold food: loss=1.611\n",
      "Test on task 12 - Carry drinks   : loss=1.443\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task 13 (Carry small objects (plates, toys))\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  13\n",
      "Batch: 448/500 | Epoch   1, time=524.2ms/ 13.7ms | Train: loss=5.853 | Valid: loss=5.853 | *\n",
      "Batch: 448/500 | Epoch   2, time=521.6ms/ 16.3ms | Train: loss=4.821 | Valid: loss=4.821 | *\n",
      "Batch: 448/500 | Epoch   3, time=581.3ms/ 13.1ms | Train: loss=4.248 | Valid: loss=4.248 | *\n",
      "Batch: 448/500 | Epoch   4, time=533.5ms/ 12.8ms | Train: loss=3.804 | Valid: loss=3.804 | *\n",
      "Batch: 448/500 | Epoch   5, time=541.6ms/ 16.3ms | Train: loss=3.529 | Valid: loss=3.529 | *\n",
      "Batch: 448/500 | Epoch   6, time=560.0ms/ 13.0ms | Train: loss=3.303 | Valid: loss=3.303 | *\n",
      "Batch: 448/500 | Epoch   7, time=574.9ms/ 12.9ms | Train: loss=3.066 | Valid: loss=3.066 | *\n",
      "Batch: 448/500 | Epoch   8, time=561.5ms/ 13.2ms | Train: loss=2.847 | Valid: loss=2.847 | *\n",
      "Batch: 448/500 | Epoch   9, time=578.6ms/ 13.2ms | Train: loss=2.698 | Valid: loss=2.698 | *\n",
      "Batch: 448/500 | Epoch  10, time=572.5ms/ 12.9ms | Train: loss=2.580 | Valid: loss=2.580 | *\n",
      "Batch: 448/500 | Epoch  11, time=586.5ms/ 14.2ms | Train: loss=2.530 | Valid: loss=2.530 | *\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  12, time=551.2ms/ 12.9ms | Train: loss=2.452 | Valid: loss=2.452 | *\n",
      "Batch: 448/500 | Epoch  13, time=554.8ms/ 13.1ms | Train: loss=2.389 | Valid: loss=2.389 | *\n",
      "Batch: 448/500 | Epoch  14, time=538.7ms/ 13.3ms | Train: loss=2.326 | Valid: loss=2.326 | *\n",
      "Batch: 448/500 | Epoch  15, time=582.8ms/ 13.2ms | Train: loss=2.266 | Valid: loss=2.266 | *\n",
      "Batch: 448/500 | Epoch  16, time=575.2ms/ 14.8ms | Train: loss=2.217 | Valid: loss=2.217 | *\n",
      "Batch: 448/500 | Epoch  17, time=563.7ms/ 13.0ms | Train: loss=2.175 | Valid: loss=2.175 | *\n",
      "Batch: 448/500 | Epoch  18, time=557.1ms/ 13.1ms | Train: loss=2.135 | Valid: loss=2.135 | *\n",
      "Batch: 448/500 | Epoch  19, time=585.0ms/ 13.2ms | Train: loss=2.086 | Valid: loss=2.086 | *\n",
      "Batch: 448/500 | Epoch  20, time=590.8ms/ 13.8ms | Train: loss=2.046 | Valid: loss=2.046 | *\n",
      "Batch: 448/500 | Epoch  21, time=546.6ms/ 16.6ms | Train: loss=2.018 | Valid: loss=2.018 | *\n",
      "Batch: 448/500 | Epoch  22, time=547.6ms/ 16.5ms | Train: loss=1.988 | Valid: loss=1.988 | *\n",
      "Batch: 448/500 | Epoch  23, time=592.1ms/ 12.8ms | Train: loss=1.961 | Valid: loss=1.961 | *\n",
      "Batch: 448/500 | Epoch  24, time=572.7ms/ 13.2ms | Train: loss=1.937 | Valid: loss=1.937 | *\n",
      "Batch: 448/500 | Epoch  25, time=550.2ms/ 13.2ms | Train: loss=1.912 | Valid: loss=1.912 | *\n",
      "Batch: 448/500 | Epoch  26, time=548.0ms/ 13.0ms | Train: loss=1.892 | Valid: loss=1.892 | *\n",
      "Batch: 448/500 | Epoch  27, time=530.0ms/ 13.2ms | Train: loss=1.870 | Valid: loss=1.870 | *\n",
      "Batch: 448/500 | Epoch  28, time=572.6ms/ 13.0ms | Train: loss=1.849 | Valid: loss=1.849 | *\n",
      "Batch: 448/500 | Epoch  29, time=579.4ms/ 13.0ms | Train: loss=1.826 | Valid: loss=1.826 | *\n",
      "Batch: 448/500 | Epoch  30, time=567.3ms/ 13.0ms | Train: loss=1.807 | Valid: loss=1.807 | *\n",
      "Batch: 448/500 | Epoch  31, time=577.2ms/ 13.2ms | Train: loss=1.792 | Valid: loss=1.792 | *\n",
      "Batch: 448/500 | Epoch  32, time=575.2ms/ 13.6ms | Train: loss=1.774 | Valid: loss=1.774 | *\n",
      "Batch: 448/500 | Epoch  33, time=571.7ms/ 13.0ms | Train: loss=1.756 | Valid: loss=1.756 | *\n",
      "Batch: 448/500 | Epoch  34, time=574.9ms/ 12.9ms | Train: loss=1.743 | Valid: loss=1.743 | *\n",
      "Batch: 448/500 | Epoch  35, time=550.1ms/ 12.9ms | Train: loss=1.729 | Valid: loss=1.729 | *\n",
      "Batch: 448/500 | Epoch  36, time=546.3ms/ 13.0ms | Train: loss=1.714 | Valid: loss=1.714 | *\n",
      "Batch: 448/500 | Epoch  37, time=560.0ms/ 16.4ms | Train: loss=1.701 | Valid: loss=1.701 | *\n",
      "Batch: 448/500 | Epoch  38, time=558.4ms/ 13.3ms | Train: loss=1.691 | Valid: loss=1.691 | *\n",
      "Batch: 448/500 | Epoch  39, time=545.8ms/ 13.4ms | Train: loss=1.676 | Valid: loss=1.676 | *\n",
      "Batch: 448/500 | Epoch  40, time=567.9ms/ 13.2ms | Train: loss=1.665 | Valid: loss=1.665 | *\n",
      "Batch: 448/500 | Epoch  41, time=599.3ms/ 13.5ms | Train: loss=1.655 | Valid: loss=1.655 | *\n",
      "Batch: 448/500 | Epoch  42, time=545.8ms/ 17.4ms | Train: loss=1.647 | Valid: loss=1.647 | *\n",
      "Batch: 448/500 | Epoch  43, time=552.1ms/ 13.7ms | Train: loss=1.636 | Valid: loss=1.636 | *\n",
      "Batch: 448/500 | Epoch  44, time=585.9ms/ 13.2ms | Train: loss=1.623 | Valid: loss=1.623 | *\n",
      "Batch: 448/500 | Epoch  45, time=575.2ms/ 13.1ms | Train: loss=1.613 | Valid: loss=1.613 | *\n",
      "Batch: 448/500 | Epoch  46, time=553.1ms/ 13.2ms | Train: loss=1.600 | Valid: loss=1.600 | *\n",
      "Batch: 448/500 | Epoch  47, time=551.5ms/ 13.2ms | Train: loss=1.592 | Valid: loss=1.592 | *\n",
      "Batch: 448/500 | Epoch  48, time=548.7ms/ 13.1ms | Train: loss=1.584 | Valid: loss=1.584 | *\n",
      "Batch: 448/500 | Epoch  49, time=578.0ms/ 14.0ms | Train: loss=1.576 | Valid: loss=1.576 | *\n",
      "Batch: 448/500 | Epoch  50, time=549.0ms/ 12.9ms | Train: loss=1.571 | Valid: loss=1.571 | *\n",
      "Batch: 448/500 | Epoch  51, time=565.1ms/ 13.2ms | Train: loss=1.565 | Valid: loss=1.565 | *\n",
      "Batch: 448/500 | Epoch  52, time=591.4ms/ 13.5ms | Train: loss=1.560 | Valid: loss=1.560 | *\n",
      "Batch: 448/500 | Epoch  53, time=613.5ms/ 13.3ms | Train: loss=1.554 | Valid: loss=1.554 | *\n",
      "Batch: 448/500 | Epoch  54, time=549.3ms/ 13.0ms | Train: loss=1.550 | Valid: loss=1.550 | *\n",
      "Batch: 448/500 | Epoch  55, time=549.9ms/ 13.3ms | Train: loss=1.544 | Valid: loss=1.544 | *\n",
      "Batch: 448/500 | Epoch  56, time=551.0ms/ 13.4ms | Train: loss=1.538 | Valid: loss=1.538 | *\n",
      "Batch: 448/500 | Epoch  57, time=652.4ms/ 13.3ms | Train: loss=1.535 | Valid: loss=1.535 | *\n",
      "Batch: 448/500 | Epoch  58, time=532.0ms/ 14.5ms | Train: loss=1.532 | Valid: loss=1.532 | *\n",
      "Batch: 448/500 | Epoch  59, time=586.6ms/ 13.0ms | Train: loss=1.528 | Valid: loss=1.528 | *\n",
      "Batch: 448/500 | Epoch  60, time=605.4ms/ 13.2ms | Train: loss=1.525 | Valid: loss=1.525 | *\n",
      "Batch: 448/500 | Epoch  61, time=585.4ms/ 14.7ms | Train: loss=1.521 | Valid: loss=1.521 | *\n",
      "Batch: 448/500 | Epoch  62, time=590.9ms/ 12.9ms | Train: loss=1.516 | Valid: loss=1.516 | *\n",
      "Batch: 448/500 | Epoch  63, time=558.8ms/ 13.3ms | Train: loss=1.513 | Valid: loss=1.513 | *\n",
      "Batch: 448/500 | Epoch  64, time=568.7ms/ 16.1ms | Train: loss=1.510 | Valid: loss=1.510 | *\n",
      "Batch: 448/500 | Epoch  65, time=545.8ms/ 13.4ms | Train: loss=1.509 | Valid: loss=1.509 | *\n",
      "Batch: 448/500 | Epoch  66, time=562.1ms/ 13.0ms | Train: loss=1.506 | Valid: loss=1.506 | *\n",
      "Batch: 448/500 | Epoch  67, time=565.6ms/ 13.0ms | Train: loss=1.504 | Valid: loss=1.504 | *\n",
      "Batch: 448/500 | Epoch  68, time=573.8ms/ 13.2ms | Train: loss=1.501 | Valid: loss=1.501 | *\n",
      "Batch: 448/500 | Epoch  69, time=559.0ms/ 13.0ms | Train: loss=1.498 | Valid: loss=1.498 | *\n",
      "Batch: 448/500 | Epoch  70, time=526.5ms/ 13.1ms | Train: loss=1.496 | Valid: loss=1.496 | *\n",
      "Batch: 448/500 | Epoch  71, time=543.3ms/ 13.4ms | Train: loss=1.494 | Valid: loss=1.494 | *\n",
      "Batch: 448/500 | Epoch  72, time=598.5ms/ 13.8ms | Train: loss=1.492 | Valid: loss=1.492 | *\n",
      "Batch: 448/500 | Epoch  73, time=574.5ms/ 13.3ms | Train: loss=1.490 | Valid: loss=1.490 | *\n",
      "Batch: 448/500 | Epoch  74, time=580.2ms/ 15.1ms | Train: loss=1.488 | Valid: loss=1.488 | *\n",
      "Batch: 448/500 | Epoch  75, time=553.4ms/ 13.3ms | Train: loss=1.485 | Valid: loss=1.485 | *\n",
      "Batch: 448/500 | Epoch  76, time=613.3ms/ 16.4ms | Train: loss=1.484 | Valid: loss=1.484 | *\n",
      "Batch: 448/500 | Epoch  77, time=582.7ms/ 14.4ms | Train: loss=1.483 | Valid: loss=1.483 | *\n",
      "Batch: 448/500 | Epoch  78, time=567.5ms/ 13.2ms | Train: loss=1.481 | Valid: loss=1.481 | *\n",
      "Batch: 448/500 | Epoch  79, time=596.9ms/ 13.1ms | Train: loss=1.479 | Valid: loss=1.479 | *\n",
      "Batch: 448/500 | Epoch  80, time=581.8ms/ 16.3ms | Train: loss=1.476 | Valid: loss=1.476 | *\n",
      "Batch: 448/500 | Epoch  81, time=575.1ms/ 13.1ms | Train: loss=1.473 | Valid: loss=1.473 | *\n",
      "Batch: 448/500 | Epoch  82, time=542.9ms/ 13.2ms | Train: loss=1.471 | Valid: loss=1.471 | *\n",
      "Batch: 448/500 | Epoch  83, time=600.3ms/ 13.3ms | Train: loss=1.470 | Valid: loss=1.470 | *\n",
      "Batch: 448/500 | Epoch  84, time=576.2ms/ 13.2ms | Train: loss=1.469 | Valid: loss=1.469 | *\n",
      "Batch: 448/500 | Epoch  85, time=581.7ms/ 13.0ms | Train: loss=1.467 | Valid: loss=1.467 | *\n",
      "Batch: 448/500 | Epoch  86, time=582.6ms/ 16.2ms | Train: loss=1.465 | Valid: loss=1.465 | *\n",
      "Batch: 448/500 | Epoch  87, time=560.5ms/ 12.9ms | Train: loss=1.464 | Valid: loss=1.464 | *\n",
      "Batch: 448/500 | Epoch  88, time=548.8ms/ 13.2ms | Train: loss=1.461 | Valid: loss=1.461 | *\n",
      "Batch: 448/500 | Epoch  89, time=568.0ms/ 16.7ms | Train: loss=1.460 | Valid: loss=1.460 | *\n",
      "Batch: 448/500 | Epoch  90, time=537.8ms/ 13.1ms | Train: loss=1.458 | Valid: loss=1.458 | *\n",
      "Batch: 448/500 | Epoch  91, time=556.1ms/ 13.1ms | Train: loss=1.456 | Valid: loss=1.456 | *\n",
      "Batch: 448/500 | Epoch  92, time=569.7ms/ 16.3ms | Train: loss=1.455 | Valid: loss=1.455 | *\n",
      "Batch: 448/500 | Epoch  93, time=585.5ms/ 12.9ms | Train: loss=1.453 | Valid: loss=1.453 | *\n",
      "Batch: 448/500 | Epoch  94, time=536.9ms/ 13.0ms | Train: loss=1.453 | Valid: loss=1.453 | *\n",
      "Batch: 448/500 | Epoch  95, time=531.2ms/ 13.1ms | Train: loss=1.452 | Valid: loss=1.452 | *\n",
      "Batch: 448/500 | Epoch  96, time=566.7ms/ 13.1ms | Train: loss=1.450 | Valid: loss=1.450 | *\n",
      "Batch: 448/500 | Epoch  97, time=552.1ms/ 13.0ms | Train: loss=1.448 | Valid: loss=1.448 | *\n",
      "Batch: 448/500 | Epoch  98, time=578.7ms/ 14.2ms | Train: loss=1.448 | Valid: loss=1.448 | *\n",
      "Batch: 448/500 | Epoch  99, time=573.0ms/ 13.0ms | Train: loss=1.446 | Valid: loss=1.446 | *\n",
      "Batch: 448/500 | Epoch 100, time=557.2ms/ 12.9ms | Train: loss=1.446 | Valid: loss=1.446 | *\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.983\n",
      "Test on task  1 - Mopping the floor: loss=2.004\n",
      "Test on task  2 - Carry warm food: loss=1.952\n",
      "Test on task  3 - Carry cold food: loss=2.477\n",
      "Test on task  4 - Carry drinks   : loss=1.621\n",
      "Test on task  5 - Carry small objects (plates, toys): loss=2.185\n",
      "Test on task  6 - Carry big objects (tables, chairs): loss=1.632\n",
      "Test on task  7 - Cleaning (Picking up stuff): loss=1.736\n",
      "Test on task  8 - Vacuum cleaning: loss=2.286\n",
      "Test on task  9 - Mopping the floor: loss=1.616\n",
      "Test on task 10 - Carry warm food: loss=1.620\n",
      "Test on task 11 - Carry cold food: loss=1.576\n",
      "Test on task 12 - Carry drinks   : loss=1.431\n",
      "Test on task 13 - Carry small objects (plates, toys): loss=1.349\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task 14 (Carry big objects (tables, chairs))\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  14\n",
      "Batch: 448/500 | Epoch   1, time=567.1ms/ 13.1ms | Train: loss=2.994 | Valid: loss=2.994 | *\n",
      "Batch: 448/500 | Epoch   2, time=530.0ms/ 13.4ms | Train: loss=2.943 | Valid: loss=2.943 | *\n",
      "Batch: 448/500 | Epoch   3, time=536.9ms/ 13.0ms | Train: loss=2.898 | Valid: loss=2.898 | *\n",
      "Batch: 448/500 | Epoch   4, time=548.5ms/ 13.3ms | Train: loss=2.856 | Valid: loss=2.856 | *\n",
      "Batch: 448/500 | Epoch   5, time=566.1ms/ 13.0ms | Train: loss=2.817 | Valid: loss=2.817 | *\n",
      "Batch: 448/500 | Epoch   6, time=562.9ms/ 13.3ms | Train: loss=2.781 | Valid: loss=2.781 | *\n",
      "Batch: 448/500 | Epoch   7, time=570.3ms/ 13.0ms | Train: loss=2.744 | Valid: loss=2.744 | *\n",
      "Batch: 448/500 | Epoch   8, time=569.5ms/ 13.0ms | Train: loss=2.713 | Valid: loss=2.713 | *\n",
      "Batch: 448/500 | Epoch   9, time=571.8ms/ 13.5ms | Train: loss=2.689 | Valid: loss=2.689 | *\n",
      "Batch: 448/500 | Epoch  10, time=571.5ms/ 13.4ms | Train: loss=2.647 | Valid: loss=2.647 | *\n",
      "Batch: 448/500 | Epoch  11, time=571.3ms/ 12.9ms | Train: loss=2.602 | Valid: loss=2.602 | *\n",
      "Batch: 448/500 | Epoch  12, time=533.3ms/ 13.2ms | Train: loss=2.568 | Valid: loss=2.568 | *\n",
      "Batch: 448/500 | Epoch  13, time=536.1ms/ 16.3ms | Train: loss=2.533 | Valid: loss=2.533 | *\n",
      "Batch: 448/500 | Epoch  14, time=578.3ms/ 13.7ms | Train: loss=2.496 | Valid: loss=2.496 | *\n",
      "Batch: 448/500 | Epoch  15, time=582.5ms/ 14.5ms | Train: loss=2.449 | Valid: loss=2.449 | *\n",
      "Batch: 448/500 | Epoch  16, time=581.7ms/ 12.8ms | Train: loss=2.414 | Valid: loss=2.414 | *\n",
      "Batch: 448/500 | Epoch  17, time=595.9ms/ 13.4ms | Train: loss=2.392 | Valid: loss=2.392 | *\n",
      "Batch: 448/500 | Epoch  18, time=532.5ms/ 13.0ms | Train: loss=2.364 | Valid: loss=2.364 | *\n",
      "Batch: 448/500 | Epoch  19, time=526.4ms/ 13.0ms | Train: loss=2.337 | Valid: loss=2.337 | *\n",
      "Batch: 448/500 | Epoch  20, time=524.8ms/ 13.2ms | Train: loss=2.307 | Valid: loss=2.307 | *\n",
      "Batch: 448/500 | Epoch  21, time=552.5ms/ 13.0ms | Train: loss=2.280 | Valid: loss=2.280 | *\n",
      "Batch: 448/500 | Epoch  22, time=593.0ms/ 16.9ms | Train: loss=2.240 | Valid: loss=2.240 | *\n",
      "Batch: 448/500 | Epoch  23, time=601.8ms/ 13.0ms | Train: loss=2.206 | Valid: loss=2.206 | *\n",
      "Batch: 448/500 | Epoch  24, time=585.0ms/ 13.3ms | Train: loss=2.193 | Valid: loss=2.193 | *\n",
      "Batch: 448/500 | Epoch  25, time=620.1ms/ 13.4ms | Train: loss=2.170 | Valid: loss=2.170 | *\n",
      "Batch: 448/500 | Epoch  26, time=585.3ms/ 12.8ms | Train: loss=2.146 | Valid: loss=2.146 | *\n",
      "Batch: 448/500 | Epoch  27, time=588.6ms/ 13.4ms | Train: loss=2.121 | Valid: loss=2.121 | *\n",
      "Batch: 448/500 | Epoch  28, time=605.4ms/ 13.3ms | Train: loss=2.097 | Valid: loss=2.097 | *\n",
      "Batch: 448/500 | Epoch  29, time=542.1ms/ 13.3ms | Train: loss=2.069 | Valid: loss=2.069 | *\n",
      "Batch: 448/500 | Epoch  30, time=543.1ms/ 13.0ms | Train: loss=2.047 | Valid: loss=2.047 | *\n",
      "Batch: 448/500 | Epoch  31, time=611.1ms/ 13.1ms | Train: loss=2.030 | Valid: loss=2.030 | *\n",
      "Batch: 448/500 | Epoch  32, time=555.7ms/ 13.4ms | Train: loss=2.018 | Valid: loss=2.018 | *\n",
      "Batch: 448/500 | Epoch  33, time=591.5ms/ 13.6ms | Train: loss=1.999 | Valid: loss=1.999 | *\n",
      "Batch: 448/500 | Epoch  34, time=562.1ms/ 13.1ms | Train: loss=1.979 | Valid: loss=1.979 | *\n",
      "Batch: 448/500 | Epoch  35, time=534.5ms/ 13.1ms | Train: loss=1.964 | Valid: loss=1.964 | *\n",
      "Batch: 448/500 | Epoch  36, time=542.4ms/ 13.1ms | Train: loss=1.950 | Valid: loss=1.950 | *\n",
      "Batch: 448/500 | Epoch  37, time=565.6ms/ 13.2ms | Train: loss=1.935 | Valid: loss=1.935 | *\n",
      "Batch: 448/500 | Epoch  38, time=598.0ms/ 13.1ms | Train: loss=1.920 | Valid: loss=1.920 | *\n",
      "Batch: 448/500 | Epoch  39, time=583.1ms/ 13.1ms | Train: loss=1.912 | Valid: loss=1.912 | *\n",
      "Batch: 448/500 | Epoch  40, time=575.0ms/ 12.8ms | Train: loss=1.884 | Valid: loss=1.884 | *\n",
      "Batch: 448/500 | Epoch  41, time=532.5ms/ 13.6ms | Train: loss=1.874 | Valid: loss=1.874 | *\n",
      "Batch: 448/500 | Epoch  42, time=594.3ms/ 12.9ms | Train: loss=1.863 | Valid: loss=1.863 | *\n",
      "Batch: 448/500 | Epoch  43, time=567.4ms/ 13.3ms | Train: loss=1.849 | Valid: loss=1.849 | *\n",
      "Batch: 448/500 | Epoch  44, time=541.8ms/ 13.3ms | Train: loss=1.829 | Valid: loss=1.829 | *\n",
      "Batch: 448/500 | Epoch  45, time=532.9ms/ 13.1ms | Train: loss=1.818 | Valid: loss=1.818 | *\n",
      "Batch: 448/500 | Epoch  46, time=550.9ms/ 12.9ms | Train: loss=1.813 | Valid: loss=1.813 | *\n",
      "Batch: 448/500 | Epoch  47, time=578.1ms/ 13.8ms | Train: loss=1.811 | Valid: loss=1.811 | *\n",
      "Batch: 448/500 | Epoch  48, time=540.4ms/ 12.8ms | Train: loss=1.809 | Valid: loss=1.809 | *\n",
      "Batch: 448/500 | Epoch  71, time=560.4ms/ 13.4ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  72, time=604.0ms/ 16.6ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  73, time=598.6ms/ 16.3ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  74, time=576.4ms/ 13.5ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  75, time=566.4ms/ 13.2ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  76, time=541.0ms/ 12.9ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  77, time=605.1ms/ 13.5ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  78, time=526.0ms/ 12.9ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  79, time=528.7ms/ 16.3ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  80, time=559.3ms/ 12.9ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  81, time=580.7ms/ 16.8ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  82, time=577.7ms/ 13.6ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  83, time=585.3ms/ 13.7ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  84, time=624.8ms/ 13.2ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  85, time=590.4ms/ 16.3ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  86, time=559.4ms/ 13.2ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  87, time=578.4ms/ 13.0ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  88, time=588.6ms/ 13.2ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  89, time=568.4ms/ 13.1ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  90, time=575.5ms/ 13.2ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  91, time=566.1ms/ 12.9ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  92, time=559.1ms/ 13.0ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  93, time=542.1ms/ 13.1ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  94, time=577.1ms/ 12.9ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  95, time=579.0ms/ 13.8ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  96, time=573.1ms/ 13.1ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  97, time=598.8ms/ 13.3ms | Train: loss=1.736 | Valid: loss=1.736 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  98, time=552.2ms/ 13.6ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch  99, time=557.3ms/ 13.2ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "Batch: 448/500 | Epoch 100, time=586.9ms/ 16.4ms | Train: loss=1.736 | Valid: loss=1.736 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=2.039\n",
      "Test on task  1 - Mopping the floor: loss=2.180\n",
      "Test on task  2 - Carry warm food: loss=2.110\n",
      "Test on task  3 - Carry cold food: loss=2.557\n",
      "Test on task  4 - Carry drinks   : loss=1.734\n",
      "Test on task  5 - Carry small objects (plates, toys): loss=2.145\n",
      "Test on task  6 - Carry big objects (tables, chairs): loss=1.741\n",
      "Test on task  7 - Cleaning (Picking up stuff): loss=1.639\n",
      "Test on task  8 - Vacuum cleaning: loss=2.127\n",
      "Test on task  9 - Mopping the floor: loss=1.620\n",
      "Test on task 10 - Carry warm food: loss=1.588\n",
      "Test on task 11 - Carry cold food: loss=1.569\n",
      "Test on task 12 - Carry drinks   : loss=1.456\n",
      "Test on task 13 - Carry small objects (plates, toys): loss=1.376\n",
      "Test on task 14 - Carry big objects (tables, chairs): loss=1.793\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n",
      "****************************************************************************************************\n",
      "Task 15 (Starting conversation)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  15\n",
      "Batch: 448/500 | Epoch   1, time=577.2ms/ 13.0ms | Train: loss=8.589 | Valid: loss=8.589 | *\n",
      "Batch: 448/500 | Epoch   2, time=580.5ms/ 13.2ms | Train: loss=5.145 | Valid: loss=5.145 | *\n",
      "Batch: 448/500 | Epoch   3, time=532.3ms/ 13.4ms | Train: loss=3.767 | Valid: loss=3.767 | *\n",
      "Batch: 448/500 | Epoch   4, time=538.2ms/ 13.0ms | Train: loss=3.020 | Valid: loss=3.020 | *\n",
      "Batch: 448/500 | Epoch   5, time=538.9ms/ 12.9ms | Train: loss=2.716 | Valid: loss=2.716 | *\n",
      "Batch: 448/500 | Epoch   6, time=551.0ms/ 13.3ms | Train: loss=2.569 | Valid: loss=2.569 | *\n",
      "Batch: 448/500 | Epoch   7, time=596.5ms/ 12.9ms | Train: loss=2.415 | Valid: loss=2.415 | *\n",
      "Batch: 448/500 | Epoch   8, time=527.6ms/ 12.9ms | Train: loss=2.343 | Valid: loss=2.343 | *\n",
      "Batch: 448/500 | Epoch   9, time=626.9ms/ 12.9ms | Train: loss=2.281 | Valid: loss=2.281 | *\n",
      "Batch: 448/500 | Epoch  10, time=572.9ms/ 13.4ms | Train: loss=2.239 | Valid: loss=2.239 | *\n",
      "Batch: 448/500 | Epoch  11, time=560.1ms/ 16.3ms | Train: loss=2.209 | Valid: loss=2.209 | *\n",
      "Batch: 448/500 | Epoch  12, time=572.2ms/ 12.9ms | Train: loss=2.196 | Valid: loss=2.196 | *\n",
      "Batch: 448/500 | Epoch  13, time=579.6ms/ 13.3ms | Train: loss=2.183 | Valid: loss=2.183 | *\n",
      "Batch: 448/500 | Epoch  14, time=579.0ms/ 13.3ms | Train: loss=2.180 | Valid: loss=2.180 | *\n",
      "Batch: 448/500 | Epoch  15, time=557.5ms/ 13.6ms | Train: loss=2.170 | Valid: loss=2.170 | *\n",
      "Batch: 448/500 | Epoch  16, time=590.1ms/ 13.6ms | Train: loss=2.161 | Valid: loss=2.161 | *\n",
      "Batch: 448/500 | Epoch  17, time=574.3ms/ 13.5ms | Train: loss=2.153 | Valid: loss=2.153 | *\n",
      "Batch: 448/500 | Epoch  18, time=572.2ms/ 13.5ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  19, time=562.9ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  20, time=565.3ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  21, time=557.8ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  22, time=556.1ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  23, time=555.8ms/ 13.7ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  24, time=569.9ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  25, time=585.8ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  26, time=597.4ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  27, time=568.7ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  28, time=582.6ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  29, time=594.4ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  30, time=590.8ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  31, time=561.4ms/ 13.8ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  32, time=538.4ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  33, time=575.2ms/ 13.4ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  34, time=561.7ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  35, time=576.7ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  36, time=580.0ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  37, time=576.4ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  38, time=589.2ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  39, time=563.8ms/ 13.4ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  40, time=575.8ms/ 16.5ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  41, time=597.5ms/ 15.3ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  42, time=582.8ms/ 13.4ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  43, time=574.6ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  44, time=572.8ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  45, time=578.7ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  46, time=581.3ms/ 13.4ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  47, time=564.2ms/ 13.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  48, time=526.8ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  49, time=577.4ms/ 13.5ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  50, time=570.0ms/ 16.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  51, time=591.8ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  52, time=561.0ms/ 13.5ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  53, time=574.8ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  54, time=566.1ms/ 13.3ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  55, time=538.3ms/ 16.6ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  56, time=582.1ms/ 13.5ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  57, time=530.6ms/ 13.8ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  58, time=521.2ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  59, time=578.7ms/ 13.7ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  60, time=568.5ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  61, time=590.8ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  62, time=525.2ms/ 14.7ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  63, time=569.1ms/ 13.8ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  64, time=532.5ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  65, time=519.9ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  66, time=542.4ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  67, time=547.0ms/ 13.4ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  68, time=537.1ms/ 13.3ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  69, time=560.0ms/ 13.8ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  70, time=556.8ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  71, time=550.5ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  72, time=545.3ms/ 13.5ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  73, time=568.7ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  74, time=524.7ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 448/500 | Epoch  75, time=537.4ms/ 13.6ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  76, time=531.6ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  77, time=549.8ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  78, time=562.4ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  79, time=550.3ms/ 13.4ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  80, time=551.7ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  81, time=538.1ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  82, time=555.2ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  83, time=574.9ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  84, time=546.2ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  85, time=556.9ms/ 12.9ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  86, time=543.9ms/ 13.5ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  87, time=525.1ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  88, time=570.0ms/ 16.5ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  89, time=554.1ms/ 16.3ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  90, time=561.3ms/ 13.3ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  91, time=538.1ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  92, time=554.0ms/ 13.6ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  93, time=578.5ms/ 13.1ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  94, time=578.0ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  95, time=568.4ms/ 13.2ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  96, time=578.5ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  97, time=587.6ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  98, time=591.0ms/ 14.8ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch  99, time=572.0ms/ 14.4ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "Batch: 448/500 | Epoch 100, time=572.5ms/ 13.0ms | Train: loss=2.156 | Valid: loss=2.156 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Vacuum cleaning: loss=1.902\n",
      "Test on task  1 - Mopping the floor: loss=2.187\n",
      "Test on task  2 - Carry warm food: loss=2.045\n",
      "Test on task  3 - Carry cold food: loss=2.493\n",
      "Test on task  4 - Carry drinks   : loss=1.509\n",
      "Test on task  5 - Carry small objects (plates, toys): loss=2.016\n",
      "Test on task  6 - Carry big objects (tables, chairs): loss=1.909\n",
      "Test on task  7 - Cleaning (Picking up stuff): loss=1.611\n",
      "Test on task  8 - Vacuum cleaning: loss=2.469\n",
      "Test on task  9 - Mopping the floor: loss=1.682\n",
      "Test on task 10 - Carry warm food: loss=1.804\n",
      "Test on task 11 - Carry cold food: loss=1.641\n",
      "Test on task 12 - Carry drinks   : loss=1.438\n",
      "Test on task 13 - Carry small objects (plates, toys): loss=1.344\n",
      "Test on task 14 - Carry big objects (tables, chairs): loss=1.761\n",
      "Test on task 15 - Starting conversation: loss=1.969\n",
      "Saving at ../checkpoints_16_tasks/16_task_groups_PUGCL\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the two tasks:\n",
    "loss = np.zeros((len(task_outputs), len(task_outputs)), dtype=np.float32)\n",
    "for task, n_class in task_outputs[args.sti:]:\n",
    "    print('*'*100)\n",
    "    print('Task {:2d} ({:s})'.format(task, data[task]['name']))\n",
    "    print('*'*100)\n",
    "\n",
    "    # Get data:\n",
    "    xtrain = data[task]['train']['x'][:,1:].type(torch.float32).to(args.device)\n",
    "    ytrain = data[task]['train']['y'].type(torch.float32).to(args.device)\n",
    "    xvalid = data[task]['valid']['x'][:,1:].type(torch.float32).to(args.device)\n",
    "    yvalid = data[task]['valid']['y'].type(torch.float32).to(args.device)\n",
    "\n",
    "    # Start training\n",
    "    print(\"Starting training for the tasks in group: \", task)\n",
    "    approach.train(task, xtrain, ytrain, xvalid, yvalid)\n",
    "    print('_'*100)\n",
    "\n",
    "    # Test for this task group:\n",
    "    for u in range(task+1):\n",
    "        xtest = data[u]['test']['x'][:,1:].type(torch.float32).to(args.device)\n",
    "        ytest = data[u]['test']['y'].type(torch.float32).to(args.device)\n",
    "        test_loss = approach.eval(u, xtest, ytest, debug=True)\n",
    "        print(\"Test on task {:2d} - {:15s}: loss={:.3f}\".format(u, data[u]['name'], test_loss))\n",
    "        loss[task, u] = test_loss\n",
    "\n",
    "    # Save\n",
    "    print(\"Saving at \" + args.checkpoint)\n",
    "    np.savetxt(os.path.join(args.checkpoint, '{}_{}_{}.txt'.format(args.experiment, \"Lul\", args.seed)), loss, '%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
