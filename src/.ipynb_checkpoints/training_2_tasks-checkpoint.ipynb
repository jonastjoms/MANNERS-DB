{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys,os,argparse,time\n",
    "import numpy as np\n",
    "import torch\n",
    "import utils\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "tstart=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Arguments =\n",
      "\tseed: 0\n",
      "\tdevice: cuda:0\n",
      "\texperiment: 2_task_groups\n",
      "\tapproach: PUGCL\n",
      "\tdata_path: data_cleaning/data.csv\n",
      "\toutput: \n",
      "\tcheckpoint_dir: ../checkpoints_2_tasks\n",
      "\tn_epochs: 100\n",
      "\tbatch_size: 64\n",
      "\tlr: 0.001\n",
      "\thidden_size: 800\n",
      "\tparameter: \n",
      "\tMC_samples: 10\n",
      "\trho: -3.0\n",
      "\tsigma1: 0.0\n",
      "\tsigma2: 6.0\n",
      "\tpi: 0.25\n",
      "\tresume: no\n",
      "\tsti: 1\n",
      "\tfff: /root/.local/share/jupyter/runtime/kernel-41031bfb-80a6-4fe7-9b8d-094d0c8a50cd.json\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Arguments\n",
    "parser=argparse.ArgumentParser(description='xxx')\n",
    "parser.add_argument('--seed',               default=0,              type=int,     help='(default=%(default)d)')\n",
    "parser.add_argument('--device',             default='cuda:0',          type=str,     help='gpu id')\n",
    "parser.add_argument('--experiment',         default='2_task_groups',       type =str,    help='Mnist or dissertation')\n",
    "parser.add_argument('--approach',           default='PUGCL',          type =str,    help='Method, always Lifelong Uncertainty-aware learning')\n",
    "parser.add_argument('--data_path',          default='data/data.csv',     type=str,     help='gpu id')\n",
    "\n",
    "# Training parameters\n",
    "parser.add_argument('--output',             default='',             type=str,     help='')\n",
    "parser.add_argument('--checkpoint_dir',     default='../checkpoints_2_tasks',    type=str,   help='')\n",
    "parser.add_argument('--n_epochs',           default=100,              type=int,     help='')\n",
    "parser.add_argument('--batch_size',         default=64,             type=int,     help='')\n",
    "parser.add_argument('--lr',                 default=0.03,           type=float,   help='')\n",
    "parser.add_argument('--hidden_size',        default=800,           type=int,     help='')\n",
    "parser.add_argument('--parameter',          default='',             type=str,     help='')\n",
    "\n",
    "# UCB HYPER-PARAMETERS\n",
    "parser.add_argument('--MC_samples',         default='10',           type=int,     help='Number of Monte Carlo samples')\n",
    "parser.add_argument('--rho',                default='-3',           type=float,   help='Initial rho')\n",
    "parser.add_argument('--sigma1',             default='0.0',          type=float,   help='STD foor the 1st prior pdf in scaled mixture Gaussian')\n",
    "parser.add_argument('--sigma2',             default='6.0',          type=float,   help='STD foor the 2nd prior pdf in scaled mixture Gaussian')\n",
    "parser.add_argument('--pi',                 default='0.25',         type=float,   help='weighting factor for prior')\n",
    "\n",
    "parser.add_argument('--resume',             default='no',           type=str,     help='resume?')\n",
    "parser.add_argument('--sti',                default=1,              type=int,     help='starting task?')\n",
    "\n",
    "parser.add_argument(\"-f\", \"--fff\", help=\"a dummy argument to fool ipython\", default=\"1\")\n",
    "\n",
    "args=parser.parse_args()\n",
    "utils.print_arguments(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Results will be saved in  ../checkpoints_2_tasks/2_task_groups_PUGCL\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set seed for stable results\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Check if Cuda is available\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "print(\"Using device:\", args.device)\n",
    "\n",
    "# Checkpoint\n",
    "checkpoint = utils.make_directories(args)\n",
    "args.checkpoint = checkpoint\n",
    "print()\n",
    "\n",
    "# PUGCL with two tasks:\n",
    "from data import dataloader_2_tasks as dataloader\n",
    "\n",
    "# Import Lifelong Uncertainty-aware Learning approach:\n",
    "#from bayesian_model.lul import Lul\n",
    "from training_method import PUGCL\n",
    "\n",
    "# Import model used:\n",
    "#from bayesian_model.bayesian_network import BayesianNetwork\n",
    "from bayesian_model.bayesian_network import BayesianNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting this session on: \n",
      "2020-05-12 09:25\n",
      "Loading data...\n",
      "Input size = [1, 29] \n",
      "Task info = [(0, 16), (1, 16)]\n",
      "Number of data samples:  4400\n",
      "Initializing network...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
      "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize Lifelong Uncertainty-aware Learning\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(\"Starting this session on: \")\n",
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n",
    "\n",
    "# Load data:\n",
    "print(\"Loading data...\")\n",
    "data, task_outputs, input_size = dataloader.get(data_path=args.data_path)\n",
    "print(\"Input size =\", input_size, \"\\nTask info =\", task_outputs)\n",
    "print(\"Number of data samples: \", len(data[0]['train']['x']))\n",
    "args.num_tasks = len(task_outputs)\n",
    "args.input_size = input_size\n",
    "args.task_outputs = task_outputs\n",
    "pickle.dump(data, open( \"data/data.p\", \"wb\" ))\n",
    "\n",
    "# Initialize Bayesian network\n",
    "print(\"Initializing network...\")\n",
    "model = BayesianNetwork(args).to(args.device)\n",
    "\n",
    "# Initialize Lul approach\n",
    "print(\"Initialize Lifelong Uncertainty-aware Learning\")\n",
    "approach = PUGCL(model, args=args)\n",
    "print(\"-\"*100)\n",
    "\n",
    "# Check wether resuming:\n",
    "if args.resume == \"yes\":\n",
    "    checkpoint = torch.load(os.path.join(args.checkpoint, 'model_{}.pth.tar'.format(args.sti)))\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device=args.device)\n",
    "else:\n",
    "    args.sti = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************************************************************************\n",
      "Task  0 (Circle)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/torch/csrc/utils/python_arg_parser.cpp:749: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Epoch   1, time=194.7ms/  3.6ms | Train: loss=2.118 | Valid: loss=2.118 | *\n",
      "| Epoch   2, time=199.6ms/  3.6ms | Train: loss=1.604 | Valid: loss=1.604 | *\n",
      "| Epoch   3, time=192.8ms/  3.6ms | Train: loss=1.482 | Valid: loss=1.482 | *\n",
      "| Epoch   4, time=201.6ms/  3.7ms | Train: loss=1.444 | Valid: loss=1.444 | *\n",
      "| Epoch   5, time=197.6ms/  3.6ms | Train: loss=1.416 | Valid: loss=1.416 | *\n",
      "| Epoch   6, time=199.9ms/  4.5ms | Train: loss=1.401 | Valid: loss=1.401 | *\n",
      "| Epoch   7, time=202.9ms/  3.6ms | Train: loss=1.383 | Valid: loss=1.383 | *\n",
      "| Epoch   8, time=196.1ms/  3.7ms | Train: loss=1.371 | Valid: loss=1.371 | *\n",
      "| Epoch   9, time=198.6ms/  3.5ms | Train: loss=1.365 | Valid: loss=1.365 | *\n",
      "| Epoch  10, time=195.5ms/  3.6ms | Train: loss=1.349 | Valid: loss=1.349 | *\n",
      "| Epoch  11, time=197.7ms/  3.6ms | Train: loss=1.344 | Valid: loss=1.344 | *\n",
      "| Epoch  12, time=193.8ms/  3.6ms | Train: loss=1.337 | Valid: loss=1.337 | *\n",
      "| Epoch  13, time=203.0ms/  3.5ms | Train: loss=1.334 | Valid: loss=1.334 | *\n",
      "| Epoch  14, time=192.4ms/  3.6ms | Train: loss=1.325 | Valid: loss=1.325 | *\n",
      "| Epoch  15, time=205.2ms/  4.3ms | Train: loss=1.326 | Valid: loss=1.326 |\n",
      "| Epoch  16, time=198.6ms/  3.8ms | Train: loss=1.323 | Valid: loss=1.323 | *\n",
      "| Epoch  17, time=195.8ms/  3.7ms | Train: loss=1.313 | Valid: loss=1.313 | *\n",
      "| Epoch  18, time=196.7ms/  3.7ms | Train: loss=1.307 | Valid: loss=1.307 | *\n",
      "| Epoch  19, time=197.6ms/  3.6ms | Train: loss=1.307 | Valid: loss=1.307 | *\n",
      "| Epoch  20, time=198.9ms/  3.5ms | Train: loss=1.309 | Valid: loss=1.309 |\n",
      "| Epoch  21, time=197.4ms/  3.5ms | Train: loss=1.306 | Valid: loss=1.306 | *\n",
      "| Epoch  22, time=195.6ms/  3.6ms | Train: loss=1.301 | Valid: loss=1.301 | *\n",
      "| Epoch  23, time=197.1ms/  3.7ms | Train: loss=1.295 | Valid: loss=1.295 | *\n",
      "| Epoch  24, time=196.5ms/  4.2ms | Train: loss=1.298 | Valid: loss=1.298 |\n",
      "| Epoch  25, time=202.9ms/  3.7ms | Train: loss=1.293 | Valid: loss=1.293 | *\n",
      "| Epoch  26, time=201.6ms/  3.7ms | Train: loss=1.292 | Valid: loss=1.292 | *\n",
      "| Epoch  27, time=209.6ms/  3.6ms | Train: loss=1.293 | Valid: loss=1.293 |\n",
      "| Epoch  28, time=198.5ms/  4.5ms | Train: loss=1.289 | Valid: loss=1.289 | *\n",
      "| Epoch  29, time=198.8ms/  3.7ms | Train: loss=1.289 | Valid: loss=1.289 |\n",
      "| Epoch  30, time=190.2ms/  3.5ms | Train: loss=1.291 | Valid: loss=1.291 |\n",
      "| Epoch  31, time=194.6ms/  3.7ms | Train: loss=1.293 | Valid: loss=1.293 |\n",
      "| Epoch  32, time=194.1ms/  3.7ms | Train: loss=1.288 | Valid: loss=1.288 | *\n",
      "| Epoch  33, time=196.4ms/  3.6ms | Train: loss=1.282 | Valid: loss=1.282 | *\n",
      "| Epoch  34, time=193.4ms/  4.1ms | Train: loss=1.281 | Valid: loss=1.281 | *\n",
      "| Epoch  35, time=197.9ms/  3.6ms | Train: loss=1.275 | Valid: loss=1.275 | *\n",
      "| Epoch  36, time=195.0ms/  3.6ms | Train: loss=1.280 | Valid: loss=1.280 |\n",
      "| Epoch  37, time=195.8ms/  3.6ms | Train: loss=1.280 | Valid: loss=1.280 |\n",
      "| Epoch  38, time=198.3ms/  3.6ms | Train: loss=1.279 | Valid: loss=1.279 |\n",
      "| Epoch  39, time=198.6ms/  3.5ms | Train: loss=1.274 | Valid: loss=1.274 | *\n",
      "| Epoch  40, time=192.1ms/  3.6ms | Train: loss=1.272 | Valid: loss=1.272 | *\n",
      "| Epoch  41, time=192.1ms/  3.6ms | Train: loss=1.269 | Valid: loss=1.269 | *\n",
      "| Epoch  42, time=199.1ms/  3.6ms | Train: loss=1.276 | Valid: loss=1.276 |\n",
      "| Epoch  43, time=193.6ms/  3.6ms | Train: loss=1.277 | Valid: loss=1.277 |\n",
      "| Epoch  44, time=203.5ms/  3.6ms | Train: loss=1.271 | Valid: loss=1.271 |\n",
      "| Epoch  45, time=197.9ms/  3.7ms | Train: loss=1.269 | Valid: loss=1.269 |\n",
      "| Epoch  46, time=218.5ms/  3.4ms | Train: loss=1.271 | Valid: loss=1.271 |\n",
      "| Epoch  47, time=196.8ms/  3.6ms | Train: loss=1.271 | Valid: loss=1.271 |\n",
      "| Epoch  48, time=217.8ms/  4.5ms | Train: loss=1.272 | Valid: loss=1.272 |\n",
      "| Epoch  49, time=193.8ms/  4.0ms | Train: loss=1.267 | Valid: loss=1.267 | *\n",
      "| Epoch  50, time=198.6ms/  3.5ms | Train: loss=1.272 | Valid: loss=1.272 |\n",
      "| Epoch  51, time=198.5ms/  3.6ms | Train: loss=1.269 | Valid: loss=1.269 |\n",
      "| Epoch  52, time=193.4ms/  4.5ms | Train: loss=1.272 | Valid: loss=1.272 |\n",
      "| Epoch  53, time=201.4ms/  3.6ms | Train: loss=1.268 | Valid: loss=1.268 |\n",
      "| Epoch  54, time=196.1ms/  3.6ms | Train: loss=1.264 | Valid: loss=1.264 | *\n",
      "| Epoch  55, time=191.5ms/  3.6ms | Train: loss=1.269 | Valid: loss=1.269 |\n",
      "| Epoch  56, time=201.3ms/  3.6ms | Train: loss=1.268 | Valid: loss=1.268 |\n",
      "| Epoch  57, time=197.7ms/  3.5ms | Train: loss=1.272 | Valid: loss=1.272 |\n",
      "| Epoch  58, time=205.4ms/  4.4ms | Train: loss=1.270 | Valid: loss=1.270 |\n",
      "| Epoch  59, time=272.2ms/  3.8ms | Train: loss=1.271 | Valid: loss=1.271 |\n",
      "| Epoch  60, time=257.6ms/  3.6ms | Train: loss=1.258 | Valid: loss=1.258 | *\n",
      "| Epoch  61, time=267.8ms/  3.7ms | Train: loss=1.263 | Valid: loss=1.263 |\n",
      "| Epoch  62, time=265.6ms/  3.7ms | Train: loss=1.258 | Valid: loss=1.258 | *\n",
      "| Epoch  63, time=265.9ms/  3.8ms | Train: loss=1.258 | Valid: loss=1.258 |\n",
      "| Epoch  64, time=254.5ms/  3.7ms | Train: loss=1.258 | Valid: loss=1.258 |\n",
      "| Epoch  65, time=264.6ms/  4.1ms | Train: loss=1.259 | Valid: loss=1.259 |\n",
      "| Epoch  66, time=254.1ms/  4.2ms | Train: loss=1.264 | Valid: loss=1.264 |\n",
      "| Epoch  67, time=274.5ms/  3.8ms | Train: loss=1.265 | Valid: loss=1.265 |\n",
      "| Epoch  68, time=245.7ms/  3.8ms | Train: loss=1.260 | Valid: loss=1.260 |\n",
      "| Epoch  69, time=255.2ms/  3.8ms | Train: loss=1.262 | Valid: loss=1.262 |\n",
      "| Epoch  70, time=264.6ms/  3.7ms | Train: loss=1.262 | Valid: loss=1.262 |\n",
      "| Epoch  71, time=267.0ms/  3.7ms | Train: loss=1.263 | Valid: loss=1.263 |\n",
      "| Epoch  72, time=260.4ms/  3.7ms | Train: loss=1.258 | Valid: loss=1.258 | *\n",
      "| Epoch  73, time=245.6ms/  3.7ms | Train: loss=1.261 | Valid: loss=1.261 |\n",
      "| Epoch  74, time=263.4ms/  3.9ms | Train: loss=1.256 | Valid: loss=1.256 | *\n",
      "| Epoch  75, time=250.3ms/  4.6ms | Train: loss=1.256 | Valid: loss=1.256 |\n",
      "| Epoch  76, time=273.6ms/  3.7ms | Train: loss=1.255 | Valid: loss=1.255 | *\n",
      "| Epoch  77, time=269.9ms/  3.7ms | Train: loss=1.256 | Valid: loss=1.256 |\n",
      "| Epoch  78, time=246.3ms/  4.1ms | Train: loss=1.259 | Valid: loss=1.259 |\n",
      "| Epoch  79, time=274.3ms/  3.7ms | Train: loss=1.256 | Valid: loss=1.256 |\n",
      "| Epoch  80, time=252.1ms/  3.9ms | Train: loss=1.255 | Valid: loss=1.255 | *\n",
      "| Epoch  81, time=250.7ms/  3.7ms | Train: loss=1.259 | Valid: loss=1.259 |\n",
      "| Epoch  82, time=275.1ms/  4.0ms | Train: loss=1.256 | Valid: loss=1.256 |\n",
      "| Epoch  83, time=259.6ms/  3.7ms | Train: loss=1.261 | Valid: loss=1.261 |\n",
      "| Epoch  84, time=239.2ms/  3.7ms | Train: loss=1.259 | Valid: loss=1.259 |\n",
      "| Epoch  85, time=253.7ms/  3.7ms | Train: loss=1.254 | Valid: loss=1.254 | *\n",
      "| Epoch  86, time=268.1ms/  3.9ms | Train: loss=1.255 | Valid: loss=1.255 |\n",
      "| Epoch  87, time=251.4ms/  3.7ms | Train: loss=1.256 | Valid: loss=1.256 |\n",
      "| Epoch  88, time=251.4ms/  3.8ms | Train: loss=1.257 | Valid: loss=1.257 |\n",
      "| Epoch  89, time=245.7ms/  3.8ms | Train: loss=1.257 | Valid: loss=1.257 |\n",
      "| Epoch  90, time=263.4ms/  3.9ms | Train: loss=1.259 | Valid: loss=1.259 |\n",
      "| Epoch  91, time=263.2ms/  4.0ms | Train: loss=1.259 | Valid: loss=1.259 |\n",
      "| Epoch  92, time=260.2ms/  3.7ms | Train: loss=1.255 | Valid: loss=1.255 |\n",
      "| Epoch  93, time=250.6ms/  4.0ms | Train: loss=1.259 | Valid: loss=1.259 |\n",
      "| Epoch  94, time=254.8ms/  4.0ms | Train: loss=1.257 | Valid: loss=1.257 |\n",
      "| Epoch  95, time=248.9ms/  4.5ms | Train: loss=1.255 | Valid: loss=1.255 |\n",
      "| Epoch  96, time=241.2ms/  4.0ms | Train: loss=1.257 | Valid: loss=1.257 |\n",
      "| Epoch  97, time=263.4ms/  3.7ms | Train: loss=1.257 | Valid: loss=1.257 |\n",
      "| Epoch  98, time=271.8ms/  3.8ms | Train: loss=1.257 | Valid: loss=1.257 |\n",
      "| Epoch  99, time=259.3ms/  3.7ms | Train: loss=1.257 | Valid: loss=1.257 |\n",
      "| Epoch 100, time=242.8ms/  4.5ms | Train: loss=1.259 | Valid: loss=1.259 |\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Circle         : loss=1.273\n",
      "Saving at ../checkpoints_2_tasks/2 task groups_lul\n",
      "****************************************************************************************************\n",
      "Task  1 (Arrow)\n",
      "****************************************************************************************************\n",
      "Starting training for the tasks in group:  1\n",
      "| Epoch   1, time=258.1ms/  3.9ms | Train: loss=7.218 | Valid: loss=7.218 | *\n",
      "| Epoch   2, time=260.5ms/  3.7ms | Train: loss=5.706 | Valid: loss=5.706 | *\n",
      "| Epoch   3, time=262.9ms/  4.7ms | Train: loss=4.897 | Valid: loss=4.897 | *\n",
      "| Epoch   4, time=258.4ms/  3.8ms | Train: loss=4.414 | Valid: loss=4.414 | *\n",
      "| Epoch   5, time=253.6ms/  4.2ms | Train: loss=4.107 | Valid: loss=4.107 | *\n",
      "| Epoch   6, time=245.6ms/  3.8ms | Train: loss=3.885 | Valid: loss=3.885 | *\n",
      "| Epoch   7, time=268.2ms/  3.7ms | Train: loss=3.727 | Valid: loss=3.727 | *\n",
      "| Epoch   8, time=255.7ms/  3.7ms | Train: loss=3.606 | Valid: loss=3.606 | *\n",
      "| Epoch   9, time=266.6ms/  3.7ms | Train: loss=3.512 | Valid: loss=3.512 | *\n",
      "| Epoch  10, time=244.9ms/  3.7ms | Train: loss=3.433 | Valid: loss=3.433 | *\n",
      "| Epoch  11, time=265.1ms/  3.8ms | Train: loss=3.370 | Valid: loss=3.370 | *\n",
      "| Epoch  12, time=277.7ms/  3.7ms | Train: loss=3.311 | Valid: loss=3.311 | *\n",
      "| Epoch  13, time=244.8ms/  3.9ms | Train: loss=3.262 | Valid: loss=3.262 | *\n",
      "| Epoch  14, time=244.2ms/  4.3ms | Train: loss=3.219 | Valid: loss=3.219 | *\n",
      "| Epoch  15, time=242.8ms/  3.7ms | Train: loss=3.178 | Valid: loss=3.178 | *\n",
      "| Epoch  16, time=227.4ms/  3.6ms | Train: loss=3.141 | Valid: loss=3.141 | *\n",
      "| Epoch  17, time=196.1ms/  3.5ms | Train: loss=3.107 | Valid: loss=3.107 | *\n",
      "| Epoch  18, time=198.7ms/  3.7ms | Train: loss=3.074 | Valid: loss=3.074 | *\n",
      "| Epoch  19, time=198.1ms/  4.4ms | Train: loss=3.044 | Valid: loss=3.044 | *\n",
      "| Epoch  20, time=199.9ms/  3.6ms | Train: loss=3.014 | Valid: loss=3.014 | *\n",
      "| Epoch  21, time=196.4ms/  3.6ms | Train: loss=2.984 | Valid: loss=2.984 | *\n",
      "| Epoch  22, time=196.2ms/  3.6ms | Train: loss=2.956 | Valid: loss=2.956 | *\n",
      "| Epoch  23, time=196.2ms/  3.7ms | Train: loss=2.928 | Valid: loss=2.928 | *\n",
      "| Epoch  24, time=203.0ms/  3.5ms | Train: loss=2.901 | Valid: loss=2.901 | *\n",
      "| Epoch  25, time=194.8ms/  3.6ms | Train: loss=2.876 | Valid: loss=2.876 | *\n",
      "| Epoch  26, time=191.8ms/  3.6ms | Train: loss=2.850 | Valid: loss=2.850 | *\n",
      "| Epoch  27, time=196.8ms/  3.6ms | Train: loss=2.825 | Valid: loss=2.825 | *\n",
      "| Epoch  28, time=246.4ms/  3.8ms | Train: loss=2.801 | Valid: loss=2.801 | *\n",
      "| Epoch  29, time=251.2ms/  3.8ms | Train: loss=2.776 | Valid: loss=2.776 | *\n",
      "| Epoch  30, time=260.8ms/  3.7ms | Train: loss=2.753 | Valid: loss=2.753 | *\n",
      "| Epoch  31, time=221.8ms/  3.5ms | Train: loss=2.729 | Valid: loss=2.729 | *\n",
      "| Epoch  32, time=194.3ms/  3.5ms | Train: loss=2.706 | Valid: loss=2.706 | *\n",
      "| Epoch  33, time=196.8ms/  3.6ms | Train: loss=2.683 | Valid: loss=2.683 | *\n",
      "| Epoch  34, time=194.8ms/  3.9ms | Train: loss=2.660 | Valid: loss=2.660 | *\n",
      "| Epoch  35, time=198.2ms/  4.4ms | Train: loss=2.639 | Valid: loss=2.639 | *\n",
      "| Epoch  36, time=197.3ms/  3.5ms | Train: loss=2.618 | Valid: loss=2.618 | *\n",
      "| Epoch  37, time=197.1ms/  3.6ms | Train: loss=2.598 | Valid: loss=2.598 | *\n",
      "| Epoch  38, time=194.1ms/  3.5ms | Train: loss=2.577 | Valid: loss=2.577 | *\n",
      "| Epoch  39, time=196.1ms/  4.5ms | Train: loss=2.556 | Valid: loss=2.556 | *\n",
      "| Epoch  40, time=199.2ms/  3.6ms | Train: loss=2.535 | Valid: loss=2.535 | *\n",
      "| Epoch  41, time=199.8ms/  3.6ms | Train: loss=2.516 | Valid: loss=2.516 | *\n",
      "| Epoch  42, time=195.9ms/  3.5ms | Train: loss=2.495 | Valid: loss=2.495 | *\n",
      "| Epoch  43, time=191.9ms/  3.6ms | Train: loss=2.475 | Valid: loss=2.475 | *\n",
      "| Epoch  44, time=196.3ms/  3.6ms | Train: loss=2.456 | Valid: loss=2.456 | *\n",
      "| Epoch  45, time=197.6ms/  3.6ms | Train: loss=2.435 | Valid: loss=2.435 | *\n",
      "| Epoch  46, time=196.3ms/  3.6ms | Train: loss=2.416 | Valid: loss=2.416 | *\n",
      "| Epoch  47, time=190.6ms/  3.6ms | Train: loss=2.398 | Valid: loss=2.398 | *\n",
      "| Epoch  48, time=188.6ms/  3.7ms | Train: loss=2.379 | Valid: loss=2.379 | *\n",
      "| Epoch  49, time=198.0ms/  3.5ms | Train: loss=2.360 | Valid: loss=2.360 | *\n",
      "| Epoch  50, time=195.8ms/  3.7ms | Train: loss=2.342 | Valid: loss=2.342 | *\n",
      "| Epoch  51, time=200.4ms/  3.6ms | Train: loss=2.325 | Valid: loss=2.325 | *\n",
      "| Epoch  52, time=196.5ms/  3.6ms | Train: loss=2.308 | Valid: loss=2.308 | *\n",
      "| Epoch  53, time=193.5ms/  3.5ms | Train: loss=2.291 | Valid: loss=2.291 | *\n",
      "| Epoch  54, time=200.3ms/  3.5ms | Train: loss=2.273 | Valid: loss=2.273 | *\n",
      "| Epoch  55, time=193.0ms/  3.5ms | Train: loss=2.257 | Valid: loss=2.257 | *\n",
      "| Epoch  56, time=201.0ms/  3.7ms | Train: loss=2.241 | Valid: loss=2.241 | *\n",
      "| Epoch  57, time=197.2ms/  3.6ms | Train: loss=2.224 | Valid: loss=2.224 | *\n",
      "| Epoch  58, time=198.0ms/  3.5ms | Train: loss=2.207 | Valid: loss=2.207 | *\n",
      "| Epoch  59, time=195.0ms/  3.5ms | Train: loss=2.191 | Valid: loss=2.191 | *\n",
      "| Epoch  60, time=192.9ms/  3.6ms | Train: loss=2.175 | Valid: loss=2.175 | *\n",
      "| Epoch  61, time=192.1ms/  3.6ms | Train: loss=2.160 | Valid: loss=2.160 | *\n",
      "| Epoch  62, time=193.7ms/  3.6ms | Train: loss=2.145 | Valid: loss=2.145 | *\n",
      "| Epoch  63, time=201.0ms/  4.2ms | Train: loss=2.131 | Valid: loss=2.131 | *\n",
      "| Epoch  64, time=192.2ms/  3.5ms | Train: loss=2.117 | Valid: loss=2.117 | *\n",
      "| Epoch  65, time=195.0ms/  3.6ms | Train: loss=2.103 | Valid: loss=2.103 | *\n",
      "| Epoch  66, time=199.1ms/  4.4ms | Train: loss=2.089 | Valid: loss=2.089 | *\n",
      "| Epoch  67, time=199.7ms/  3.6ms | Train: loss=2.074 | Valid: loss=2.074 | *\n",
      "| Epoch  68, time=199.5ms/  3.5ms | Train: loss=2.060 | Valid: loss=2.060 | *\n",
      "| Epoch  69, time=201.1ms/  3.7ms | Train: loss=2.046 | Valid: loss=2.046 | *\n",
      "| Epoch  70, time=192.7ms/  3.6ms | Train: loss=2.033 | Valid: loss=2.033 | *\n",
      "| Epoch  71, time=195.6ms/  3.6ms | Train: loss=2.020 | Valid: loss=2.020 | *\n",
      "| Epoch  72, time=195.4ms/  3.6ms | Train: loss=2.007 | Valid: loss=2.007 | *\n",
      "| Epoch  73, time=196.7ms/  3.6ms | Train: loss=1.995 | Valid: loss=1.995 | *\n",
      "| Epoch  74, time=202.4ms/  3.6ms | Train: loss=1.982 | Valid: loss=1.982 | *\n",
      "| Epoch  75, time=214.7ms/  4.4ms | Train: loss=1.970 | Valid: loss=1.970 | *\n",
      "| Epoch  76, time=197.6ms/  4.2ms | Train: loss=1.958 | Valid: loss=1.958 | *\n",
      "| Epoch  77, time=199.7ms/  3.7ms | Train: loss=1.947 | Valid: loss=1.947 | *\n",
      "| Epoch  78, time=195.9ms/  4.2ms | Train: loss=1.935 | Valid: loss=1.935 | *\n",
      "| Epoch  79, time=199.7ms/  4.5ms | Train: loss=1.923 | Valid: loss=1.923 | *\n",
      "| Epoch  80, time=195.0ms/  3.5ms | Train: loss=1.912 | Valid: loss=1.912 | *\n",
      "| Epoch  81, time=193.5ms/  3.6ms | Train: loss=1.901 | Valid: loss=1.901 | *\n",
      "| Epoch  82, time=193.2ms/  3.5ms | Train: loss=1.890 | Valid: loss=1.890 | *\n",
      "| Epoch  83, time=191.8ms/  3.6ms | Train: loss=1.880 | Valid: loss=1.880 | *\n",
      "| Epoch  84, time=196.1ms/  3.7ms | Train: loss=1.870 | Valid: loss=1.870 | *\n",
      "| Epoch  85, time=194.0ms/  3.5ms | Train: loss=1.859 | Valid: loss=1.859 | *\n",
      "| Epoch  86, time=196.3ms/  3.6ms | Train: loss=1.849 | Valid: loss=1.849 | *\n",
      "| Epoch  87, time=195.7ms/  4.0ms | Train: loss=1.839 | Valid: loss=1.839 | *\n",
      "| Epoch  88, time=204.3ms/  3.6ms | Train: loss=1.829 | Valid: loss=1.829 | *\n",
      "| Epoch  89, time=205.3ms/  3.5ms | Train: loss=1.820 | Valid: loss=1.820 | *\n",
      "| Epoch  90, time=196.7ms/  4.1ms | Train: loss=1.810 | Valid: loss=1.810 | *\n",
      "| Epoch  91, time=194.5ms/  3.6ms | Train: loss=1.801 | Valid: loss=1.801 | *\n",
      "| Epoch  92, time=195.9ms/  3.5ms | Train: loss=1.791 | Valid: loss=1.791 | *\n",
      "| Epoch  93, time=192.2ms/  3.6ms | Train: loss=1.782 | Valid: loss=1.782 | *\n",
      "| Epoch  94, time=200.3ms/  3.7ms | Train: loss=1.773 | Valid: loss=1.773 | *\n",
      "| Epoch  95, time=193.1ms/  3.5ms | Train: loss=1.765 | Valid: loss=1.765 | *\n",
      "| Epoch  96, time=191.0ms/  3.6ms | Train: loss=1.757 | Valid: loss=1.757 | *\n",
      "| Epoch  97, time=194.4ms/  3.6ms | Train: loss=1.749 | Valid: loss=1.749 | *\n",
      "| Epoch  98, time=198.1ms/  4.4ms | Train: loss=1.741 | Valid: loss=1.741 | *\n",
      "| Epoch  99, time=194.3ms/  3.6ms | Train: loss=1.733 | Valid: loss=1.733 | *\n",
      "| Epoch 100, time=194.8ms/  3.5ms | Train: loss=1.725 | Valid: loss=1.725 | *\n",
      "____________________________________________________________________________________________________\n",
      "Test on task  0 - Circle         : loss=1.404\n",
      "Test on task  1 - Arrow          : loss=1.750\n",
      "Saving at ../checkpoints_2_tasks/2 task groups_lul\n"
     ]
    }
   ],
   "source": [
    "# Iterate over the two tasks:\n",
    "loss = np.zeros((len(task_outputs), len(task_outputs)), dtype=np.float32)\n",
    "for task, n_class in task_outputs[args.sti:]:\n",
    "    print('*'*100)\n",
    "    print('Task {:2d} ({:s})'.format(task, data[task]['name']))\n",
    "    print('*'*100)\n",
    "\n",
    "    # Get data:\n",
    "    xtrain = data[task]['train']['x'][:,1:].type(torch.float32).to(args.device)\n",
    "    ytrain = data[task]['train']['y'].type(torch.float32).to(args.device)\n",
    "\n",
    "    # Start training\n",
    "    print(\"Starting training for the tasks in group: \", task)\n",
    "    approach.train(task, xtrain, ytrain)\n",
    "    print('_'*100)\n",
    "\n",
    "    # Test for this task group:\n",
    "    for u in range(task+1):\n",
    "        xtest = data[u]['test']['x'][:,1:].type(torch.float32).to(args.device)\n",
    "        ytest = data[u]['test']['y'].type(torch.float32).to(args.device)\n",
    "        test_loss = approach.eval(u, xtest, ytest, debug=True)\n",
    "        print(\"Test on task {:2d} - {:15s}: loss={:.3f}\".format(u, data[u]['name'], test_loss))\n",
    "        loss[task, u] = test_loss\n",
    "\n",
    "    # Save\n",
    "    print(\"Saving at \" + args.checkpoint)\n",
    "    np.savetxt(os.path.join(args.checkpoint, '{}_{}_{}.txt'.format(args.experiment, \"Lul\", args.seed)), loss, '%.5f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
